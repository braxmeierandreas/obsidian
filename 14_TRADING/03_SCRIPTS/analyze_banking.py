# -*- coding: utf-8 -*-
"""
Analyze Banking - Enterprise Edition
Author: Gemini
Date: 2026-01-18
Version: 2.0.0
"""

import pandas as pd
import os
import datetime
import json
import logging

# Paths
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
BASE_DIR = os.path.dirname(SCRIPT_DIR) # 14_TRADING
SPARKASSE_FILE = os.path.join(BASE_DIR, "02_DATA", "Sparkasse.csv")
REVOLUT_FILE = os.path.join(BASE_DIR, "02_DATA", "Revolut.csv")
HISTORY_FILE = os.path.join(BASE_DIR, "02_DATA", "net_worth_history.csv")
DASHBOARD_FILE = os.path.join(BASE_DIR, "04_DASHBOARDS", "All_Finance_Dashboard.md")
APP_JSON_FILE = os.path.join(BASE_DIR, "02_DATA", "banking_snapshot.json")
PORTFOLIO_JSON = os.path.join(BASE_DIR, "02_DATA", "portfolio_snapshot.json")

# Rules
CATEGORY_RULES = {
    "Lebensmittel": ["rewe", "aldi", "lidl", "kaufland", "edeka", "netto", "dm-drogerie", "rossmann"],
    "Transport": ["shell", "aral", "esso", "jet", "tankstelle", "db vertrieb", "deutsche bahn", "uber", "bolt"],
    "Wohnen": ["stadtwerke", "miete", "rundfunk", "strom", "gas", "internet", "vodafone", "telekom"],
    "Abos & Dienste": ["spotify", "netflix", "amazon prime", "youtube", "apple", "google", "adobe", "chatgpt", "hetzner"],
    "Shopping": ["amazon", "paypal", "zalando", "ebay", "mediamarkt", "saturn"],
    "Finanzen": ["trading 212", "trade republic", "scalable", "sparkasse", "revolut"],
}

def get_t212_values():
    """Reads T212 values from the JSON generated by fetch_t212_data.py"""
    invested = 0.0
    free = 0.0
    try:
        with open(PORTFOLIO_JSON, "r", encoding="utf-8") as f:
            data = json.load(f)
            invested = data.get("cash", {}).get("total", 0.0) # Actually total
            free = data.get("cash", {}).get("free", 0.0)
    except:
        pass
    return invested, free

def categorize(row):
    text = (str(row.get("Payee", "")) + " " + str(row.get("Description", ""))).lower()
    for cat, keywords in CATEGORY_RULES.items():
        if any(k in text for k in keywords): return cat
    return "Sonstiges"

def is_internal(row):
    text = (str(row.get("Payee", "")) + " " + str(row.get("Description", ""))).lower()
    keywords = ["andreas braxmeier", "notgroschen", "pocket", "vault", "trading 212", "revolut top-up", "Ã¼bertrag"]
    return any(k in text for k in keywords)

def load_data():
    dfs = []
    # Sparkasse
    if os.path.exists(SPARKASSE_FILE):
        try:
            df = pd.read_csv(SPARKASSE_FILE, sep=";", decimal=",", encoding="latin1")
            df = df.rename(columns={"Buchungstag": "Date", "Beguenstigter/Zahlungspflichtiger": "Payee", "Verwendungszweck": "Description", "Betrag": "Amount"})
            df["Date"] = pd.to_datetime(df["Date"], format="%d.%m.%Y", errors='coerce')
            df["Source"] = "Sparkasse"
            dfs.append(df[["Date", "Payee", "Description", "Amount", "Source"]])
        except Exception as e: print(f"Error loading Sparkasse: {e}")

    # Revolut
    if os.path.exists(REVOLUT_FILE):
        try:
            df = pd.read_csv(REVOLUT_FILE, sep=",", decimal=".")
            df = df.rename(columns={"Datum des Beginns": "Date", "Beschreibung": "Description", "Betrag": "Amount"})
            df["Date"] = pd.to_datetime(df["Date"]).dt.normalize()
            df["Source"] = "Revolut"
            df["Payee"] = df["Description"]
            dfs.append(df[["Date", "Payee", "Description", "Amount", "Source"]])
        except Exception as e: print(f"Error loading Revolut: {e}")
        
    if not dfs: return pd.DataFrame()
    return pd.concat(dfs, ignore_index=True).sort_values("Date", ascending=False)

def update_history(net_worth, t212_val, bank_val):
    today = datetime.date.today().strftime("%Y-%m-%d")
    df = pd.DataFrame(columns=["Date", "T212_Value", "Bank_Cash", "Total_Net_Worth"])
    if os.path.exists(HISTORY_FILE):
        df = pd.read_csv(HISTORY_FILE)
    
    # Upsert
    row = {"Date": today, "T212_Value": t212_val, "Bank_Cash": bank_val, "Total_Net_Worth": net_worth}
    if today in df["Date"].values:
        df.loc[df["Date"] == today, ["T212_Value", "Bank_Cash", "Total_Net_Worth"]] = [t212_val, bank_val, net_worth]
    else:
        df = pd.concat([df, pd.DataFrame([row])], ignore_index=True)
        
    df.to_csv(HISTORY_FILE, index=False)
    return df

def create_markdown(df, t212_total, t212_free, history):
    now = datetime.datetime.now().strftime("%d.%m.%Y %H:%M")
    
    # Balances
    sparkasse = df[df["Source"] == "Sparkasse"]["Amount"].sum()
    revolut = df[df["Source"] == "Revolut"]["Amount"].sum()
    bank_total = sparkasse + revolut
    net_worth = t212_total + bank_total
    
    # Analysis
    df["Internal"] = df.apply(is_internal, axis=1)
    df["Category"] = df.apply(categorize, axis=1)
    real_tx = df[~df["Internal"]].copy()
    
    # 30 Days Expenses
    cutoff = datetime.datetime.now() - datetime.timedelta(days=30)
    recent = real_tx[(real_tx["Date"] > cutoff) & (real_tx["Amount"] < 0)]
    cats = recent.groupby("Category")["Amount"].sum().sort_values()
    
    # Subs Detection
    expenses = real_tx[real_tx["Amount"] < 0].copy()
    expenses["PayeeClean"] = expenses["Payee"].fillna("").astype(str).str.lower().str.strip()
    expenses["AmountRound"] = expenses["Amount"].round(2)
    counts = expenses.groupby(["PayeeClean", "AmountRound"]).size()
    subs = counts[counts >= 3].reset_index() # At least 3 occurrences
    
    # Markdown
    md = f"# ğŸ° Master Finance Dashboard\n> **Update:** {now}\n\n"
    
    # Net Worth
    md += f"## ğŸ† Net Worth: `{net_worth:,.2f} â‚¬`\n"
    md += f"| Asset | Wert |\n| :--- | :--- |\n"
    md += f"| ğŸ“ˆ T212 Invest | `{t212_total - t212_free:,.2f} â‚¬` |\n"
    md += f"| ğŸ’µ T212 Cash | `{t212_free:,.2f} â‚¬` |\n"
    md += f"| ğŸ”´ Sparkasse | `{sparkasse:,.2f} â‚¬` |\n"
    md += f"| ğŸ”µ Revolut | `{revolut:,.2f} â‚¬` |\n\n"
    
    # Chart
    if not history.empty:
        md += "## ğŸ“ˆ Verlauf\n```mermaid\nxychart-beta\n    title \"Net Worth\"\n"
        hist_tail = history.tail(15)
        dates = [d[5:] for d in hist_tail["Date"]]
        vals = [int(v) for v in hist_tail["Total_Net_Worth"]]
        md += f"    x-axis [{', '.join(dates)}]\n    y-axis \"Euro\"\n    line [{', '.join(map(str, vals))}]\n```\n\n"
        
    # Subs
    md += "## ğŸ”„ Fixkosten (Est.)\n"
    subs_total = 0
    if not subs.empty:
        md += "| Payee | Amount |\n| :--- | :--- |\n"
        for _, row in subs.iterrows():
            amt = row["AmountRound"]
            subs_total += amt
            md += f"| {row['PayeeClean'][:20]} | {amt:,.2f} â‚¬ |\n"
        md += f"**Total: {subs_total:,.2f} â‚¬**\n\n"
    else: md += "*Keine Abos erkannt*\n\n"
    
    # Cats
    md += "## ğŸ›ï¸ Ausgaben (30d)\n```mermaid\npie title Kategorien\n"
    for c, v in cats.items():
        md += f'    \"{c}\" : {abs(v):.2f}\n'
    md += "```\n"
    
    return md, {"sparkasse": sparkasse, "revolut": revolut, "cats": cats.to_dict(), "subs_total": subs_total}

if __name__ == "__main__":
    print("ğŸ¦ Starting Banking Analysis (Enterprise v2.0)...")
    df = load_data()
    
    if not df.empty:
        t212_total, t212_free = get_t212_values()
        
        # Calc Totals for History
        bank_total = df["Amount"].sum() # Simplified, assumes CSV contains full history or current balance logic
        history = update_history(t212_total + bank_total, t212_total, bank_total)
        
        md, json_data = create_markdown(df, t212_total, t212_free, history)
        
        with open(DASHBOARD_FILE, "w", encoding="utf-8") as f:
            f.write(md)
            
        # JSON for App
        app_json = {
            "sparkasse_balance": json_data["sparkasse"],
            "revolut_balance": json_data["revolut"],
            "net_worth_history": history.to_dict(orient="records"),
            "categories": {k: abs(v) for k,v in json_data["cats"].items()},
            "subs_total": json_data["subs_total"]
        }
        with open(APP_JSON_FILE, "w", encoding="utf-8") as f:
            json.dump(app_json, f, indent=2)
            
        print("âœ… Banking Analysis Complete.")
    else:
        print("âš ï¸ No banking data found.")
