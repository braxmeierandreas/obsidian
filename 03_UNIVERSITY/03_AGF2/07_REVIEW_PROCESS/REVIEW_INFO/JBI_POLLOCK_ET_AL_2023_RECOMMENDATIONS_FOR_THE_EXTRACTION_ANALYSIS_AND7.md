### METHODOLOGY

## Recommendations for the extraction, analysis, and presentation of results in scoping reviews

Danielle Pollock [1][ �] Micah D.J. Peters [2,3,4][ �] Hanan Khalil [5][ �] Patricia McInerney [6][ �] Lyndsay Alexander [7,8][ �]
Andrea C. Tricco [9,10,11][ �] Catrin Evans [12][ �] Érica Brandão de Moraes [13,14][ �] Christina M. Godfrey [11][ �]
Dawid Pieper [15,16][ �] Ashrita Saran [17,18][ �] Cindy Stern [1][ �] Zachary Munn [1]


1JBI, School of Public Health, Faculty of Health and Medical Sciences, The University of Adelaide, Adelaide, SA, Australia, 2University of South
Australia, UniSA Clinical and Health Sciences, Rosemary Bryant AO Research Centre, Adelaide, SA, Australia, [3] Adelaide Nursing School, Faculty of
Health and Medical Sciences, The University of Adelaide, Adelaide, SA, Australia, [4] The Centre for Evidence-based Practice South Australia (CEPSA):
A JBI Centre of Excellence, [5] School of Psychology and Public Health, Department of Public Health, La Trobe University, Melbourne, VIC, Australia,
6The Wits-JBI Centre for Evidence-based Practice: A JBI Centre of Excellence, University of the Witwatersrand, Johannesburg, South Africa, 7School
of Health Sciences, Robert Gordon University, Aberdeen, UK, [8] The Scottish Centre for Evidence-based, Multi-professional Practice: A JBI Centre of
Excellence, Robert Gordon University, Aberdeen, UK, [9] Li Ka Shing Knowledge Institute, St. Michael’s Hospital, Unity Health Toronto, Toronto, ON,
Canada, [10] Epidemiology Division and Institute of Health Policy, Management, and Evaluation, Dalla Lana School of Public Health, University of
Toronto, Toronto, ON, Canada, [11] Queen’s Collaboration for Health Care Quality: A JBI Centre of Excellence, Queen’s University School of Nursing,
Kingston, ON, Canada, [12] The Nottingham Centre for Evidence-based Healthcare: A JBI Centre of Excellence, School of Health Sciences, University
of Nottingham, Nottingham, UK, [13] Department of Nursing Fundamentals and Administration, Nursing School, Federal Fluminense University,
Rio de Janeiro, Brazil, [14] The Brazilian Centre of Evidence-based Healthcare: A JBI Centre of Excellence, Universidade de São Paulo, São Paulo,
Brazil, [15] Faculty of Health Sciences Brandenburg, Brandenburg Medical School (Theodor Fontane), Institute for Health Services and Health
System Research, Rüdersdorf, Germany, [16] Center for Health Services Research, Brandenburg Medical School (Theodor Fontane), Rüdersdorf,
Germany, [17] International Development Coordinating Group (IDCG), The Campbell Collaboration New Delhi, India, and [18] The Campbell and
Cochrane Equity Methods Group, New Delhi, India

|Col1|A B S T R A C T|
|---|---|
|||



Scoping reviewers often face challenges in the extraction, analysis, and presentation of scoping review results.
Using best-practice examples and drawing on the expertise of the JBI Scoping Review Methodology Group and an
editor of a journal that publishes scoping reviews, this paper expands on existing JBI scoping review guidance. The
aim of this article is to clarify the process of extracting data from different sources of evidence; discuss what data
should be extracted (and what should not); outline how to analyze extracted data, including an explanation of basic
qualitative content analysis; and offer suggestions for the presentation of results in scoping reviews.


Keywords: evidence synthesis; methodology; methods; scoping reviews


JBI Evid Synth 2023; 21(3):520–532.



Introduction


coping reviews have been defined as a “type of
evidence synthesis that aims to systematically
# S
identify and map the breadth of evidence available



on a particular topic, field, concept, or issue, often
irrespective of source (ie, primary research, reviews,
non-empirical evidence) within or across particular
contexts.” [1][(p.950)] Scoping reviews can clarify key
concepts/definitions in the literature and identify
key characteristics or factors related to a concept,
including those related to methodological research. [2]



Correspondence: Danielle Pollock,
[danielle.pollock@adelaide.edu.au](mailto:danielle.pollock@adelaide.edu.au)



Scoping reviews can also identify gaps in the litera
DP, CS, and ZM are paid employees of JBI, The University of Adelaide.
DP, MDJP, HK, PM, LA, ACT, CE, EBdM, CMG, DP, AS, and ZM are ture and be precursors to systematic reviews. While
members of the JBI Scoping Review Methodology Group. ACT is a scoping reviews share common elements and steps
member of the editorial advisory board, CE is an associate editor, and in their conduct with systematic reviews and
CS is a senior associate editor of JBI Evidence Synthesis. No authors
were involved in the editorial processing of this manuscript. other types of evidence syntheses, [2,3] scoping reviews

DOI: 10.11124/JBIES-22-00123 are able to address broader research questions in



DP, CS, and ZM are paid employees of JBI, The University of Adelaide.
DP, MDJP, HK, PM, LA, ACT, CE, EBdM, CMG, DP, AS, and ZM are
members of the JBI Scoping Review Methodology Group. ACT is a
member of the editorial advisory board, CE is an associate editor, and
CS is a senior associate editor of JBI Evidence Synthesis. No authors
were involved in the editorial processing of this manuscript.



JBI Evidence Synthesis - 2023 JBI 520


METHODOLOGY D. Pollock et al.



comparison to the more precise, targeted questions
of feasibility, appropriateness, meaningfulness, or
effectiveness of a particular issue more suitable for
systematic reviews. For example, a scoping review
may look at what outcomes are being reported and
how these outcomes are being measured for children
who have grommet insertion due to chronic ear infections (ie, how is hearing measured?), whereas a
systematic review will assess the effectiveness of
grommets on reported outcomes, such as hearing,
speech, and language development. [2] Beyond the
kinds of questions that should be addressed by
scoping reviews, a key difference between scoping
and systematic reviews is the approach to the extraction, analysis, and presentation of data and
results. [2]

The process of extraction, analysis, and presentation of results in scoping reviews has been noted to be
challenging for scoping review authors. [4] Inconsistencies and inappropriateness in the analytical approaches undertaken in the analysis and presentation
of the data within scoping reviews have been recurrent issues. [5] In part, this may be due to scoping review
guidance being unclear and not describing a practical
approach to how to extract, analyze, and present data
within scoping reviews. Additionally, scoping reviews
can include a variety of evidence sources, such as
peer-reviewed primary research, and gray literature,
such as guidelines, organizational reports, policies,
government documents, and blogs. [6]

Seminal scoping review guidance referred to the
process of extraction, analysis, and presentation as
“data charting,” [7,8] and this terminology is used in
the Preferred Reporting Items for Systematic Reviews and Meta-Analyses extension for Scoping Reviews (PRISMA-ScR). [9] The term “charting” is seen
as a higher level of extraction, which is theoretically
appropriate for scoping reviews, and was used to
differentiate from the term “extraction.” Extraction
may suggest that review authors always extract the
study outcome results; however, guidance from JBI
states that, to be consistent with other evidence
synthesis approaches, the term “extraction” is most
appropriate, and will be used throughout this guidance. Arksey and O’Malley [7] suggested that, for
scoping reviews, an analytical framework, “basic
numerical analysis,” be used in conjunction with
“thematic constructions.” However, Arksey and
O’Malley [7] were clear that scoping reviews do not
synthesize evidence or “aggregate findings.” Levac



et al. [8] agreed with Arksey and O’Malley [7] on the
importance of a descriptive numerical summary
analysis; however, they argued that there was a need
for more guidance on the methodological approach
to thematic presentation of data. Levac et al. [8] proposed the use of qualitative content analysis. JBI
guidance recommends the use of frequency counts,
tabular/graphical presentation and, where appropriate, “basic” qualitative content analysis; however, to
date, the methodological approach has not been
thoroughly described for scoping reviews. Therefore,
the JBI Scoping Review Methodology Group has
developed guidance using best-practice examples of
scoping reviews to provide clarity on the following:


i) data extraction process: what type of data
should be extracted from the included evidence
sources and the level of detail required during
extraction
ii) data analysis: how to analyze the data collected
from evidence sources, including a detailed approach of how to conduct basic qualitative
content analysis
iii) data presentation: suggestions for the presentation of results in scoping reviews.


Using a team approach


As with many other rigorous evidence syntheses,
best-practice recommends that scoping reviews use
a team approach. [10] The team should meet regularly
throughout the entirety of the review process, including data extraction, analysis, and presentation.
Team check-ins, either through face-to-face meetings
or email, during the extraction and analysis phases
are particularly important to discuss the process,
issues encountered during data extraction, if there
are any changes to tools used to guide the extraction
of data (extraction forms or tables), and any other
review issues and results that are encountered.
Knowledge users are those who have a vested interest in the research and its outcomes and impacts, and
can also be a part of the review team and included in
all stages of the review process. [11] Knowledge users
are people who are most likely to be directly impacted by the research and its outcomes, and may
include those with lived experience (eg, patients,
clients, consumers, public), other researchers, health
care providers, or policy decision-makers. [11] Review
teams can include knowledge users at all stages to
inform the analysis plan; review the completed



JBI Evidence Synthesis - 2023 JBI 521


METHODOLOGY D. Pollock et al.



extractions, categories, and subcategories; and offer
insight into the results. [12]


Principles of data extraction


As in systematic reviews, scoping review authors
should only extract data items that are relevant to
the scoping review questions. The PCC framework
(population, concept, and context) is recommended
as a guide to construct clear and meaningful objectives and eligibility criteria for a scoping review. [6]

Therefore, potential data items of interest can be
structured around the PCC framework. Further items
for data extraction will depend on the purpose and
reasoning behind conducting the review. For example, the individual items could be related to the
study design, such as whether it was a randomized
controlled trial (RCT), the methods used for conduct,
and outcome measurement approaches. Alternatively, items for extraction could include definitions,



statements, or arguments surrounding a concept.
Data items could also include interventions studied,
their application, dose, duration, and frequency. Data
extraction, analysis, and presentation are all dependent on each other and require prior planning to
ensure consistency. There are broad principles of data
extraction that should be followed within a scoping
review to ensure its conduct is transparent and rigorous. These principles are as follows:

- Create a standardized data extraction form and
guidance for the form, which describes each
point that will be extracted (see Table 1 for a
sample extraction form). The development of the
initial data extraction form is guided by the review question and usually includes the population, concept, and context. It is recommended
that an extraction guidance form (see Table 2
for an example) be developed and accompany
the extraction form detailing each item to be
extracted and shared with each scoping reviewer.



Table 1: Example of a data extraction table in a scoping review



















|Author<br>Year|Crawshaw<br>201012|Levy et al.<br>200913|
|---|---|---|
|Country|UK|UK|
|Aim|To compare the effectiveness of subacromial corticosteroid<br>injection combined with timely exercise and manual therapy<br>(injection plus exercise) or exercise and manual therapy alone<br>(exercise only) in patients with subacromial impingement<br>syndrome|To investigate recreational participants’ experiences of<br>adhering to a sport injury rehabilitation program|
|Study type/source|RCT – 2 arm|Qualitative|
|Population|Aged 40 and older, have unilateral shoulder pain, subjectively<br>rate their pain as moderate or severe on a 3-point scale (mild/<br>moderate/severe), and have a non-capsular pattern of<br>restriction|Recreational sport participants, tendonitis-related overuse<br>injury|
|Sample size|Total (n = 232): injection + exercise (n = 115)<br>Exercise only (n = 117)|6|
|Age (yrs)|Injection + exercise = M (57.2), SD (10.3)<br>Exercise only = M (54.9), SD (10)|Range 24–38|
|Gender|Injection + exercise = 57% F, Exercise only = 52% F|4M, 2 F|
|Other demographics|Median weeks of shoulder pain, started after injury, employed,<br>diabetic|Reason for injury|
|Setting|Clinic|Mixed|
|Concept – Ex type|Flexibility: stretching, Flexibility: PNF, Strength: isometric,<br>Other: scapular stabilisation or motor control, Strength:<br>progressive resistance exercise|Group exercise class and social dancing class|
|Ex adherence|Treatment logs|Lack of motivation and confidence had negative effect on<br>home ex; ineffective coping strategies, over support and<br>pain affected clinic adherence|
|Outcomes (health<br>domain)|SPADI (Disability); GROC (Participant/patient rating overall<br>condition)|NA|
|Results|Disability and GROC: short-term benefit from injection, but no<br>difference at 12 or 24 weeks|5 themes: motivation, confidence, coping, social support,<br>and pain|


JBI Evidence Synthesis - 2023 JBI 522


METHODOLOGY D. Pollock et al.


Table 2: Example extraction guidance sheet for a scoping review


|Author|Eg, Smith; Smith & Hunt; Smith et al. (for more than 2 authors)|
|---|---|
|Title of source|What is the title of this article, guideline, etc? Write the full title (eg, The experience of<br>mothers and fathers in cases of stillbirth in Spain: a qualitative study)|
|Publication|Where was this article published (eg, Midwifery; Birth; Women and Birth). If it is an<br>organization guideline, write the organization (eg, American College of Obstetrics and<br>Gynaecology). Where there may be multiple dates on an article (eg, preprints or an article<br>made available online before it then gets published), use the date on the article that you<br>have.|
|Year|The year the article was published.|
|Date data were collected|The article may have collected data at another time point prior to publication. In this section<br>write the time period (eg, 1990–2000) data were collected. If this date was not stated or no<br>data were collected (eg, discussion paper), then write NA.|
|Type of evidence source (primary research/evidence<br>synthesis/conference abstract/discussion article)|• Primary research: peer-reviewed research articles<br>• Epidemiology: articles that have used population-level datasets<br>• Evidence syntheses: narrative reviews, systematic reviews, scoping reviews, rapid reviews,<br>etc.<br>• Conference abstracts: abstracts presented within conferences<br>• Discussion articles<br>• Editorials<br>• Theses|




- Describe the planned data extraction approach in
an a priori protocol and include a draft data
extraction form. This draft extraction form is
usually formatted as a table and should be developed specifically for the review topic at hand, be
detailed, and include more than a basic plan (ie,
more than just the population, concept, and context) for the items that will be extracted.

- Best practice is to have at least 2 scoping review
authors extracting data independently from each
evidence source. However, if this is not possible,
1 scoping reviewer per evidence source with another person reviewing either all or a proportion
of the extraction to ensure it is accurate and
complete can be considered. [13]

- Pilot-test the data extraction form on each type
of evidence source, such as primary research
articles, evidence syntheses, guidelines, policy
statements, or blog posts, included in the review. Aim for each scoping reviewer to independently complete at least 2 to 3 items per
evidence source type; however, this will depend
on the complexity of the topic and the variety of
evidence sources. During pilot-testing, scoping
review authors should reflect on the following
questions:

   - Was there anything missing from the extraction form?

   - Was there anything redundant included in the
extraction form?




   - Was there anything on the extraction form
that you did not understand or that could be
further clarified?

   - Was there any unclear information in the
accompanying guidance form?

  - How long did it take you to extract the
necessary information? This information will
help guide further time allocation.

- Have a review group discussion with all scoping
review authors after piloting to agree on all aspects of the tool, data to be extracted, and reach
agreement on queries or conflicts.

- Only extract data that are relevant to the stated
review questions of the scoping review.

- If scoping review authors need any additional
information or to clarify doubts about some of
the study’s information, the authors of the evidence sources should be contacted as soon as
possible. Further follow-up of these authors may
be necessary.

- Ensure and plan for regular team meetings and/
or communication during the extraction process
to discuss progress and assess if the data extraction form is capturing the necessary information
to answer the review questions.


Data extraction as an iterative process
Given the breadth of scoping review questions and
the varied sources of evidence that can be included,
additional relevant data items may be identified by



JBI Evidence Synthesis - 2023 JBI 523


METHODOLOGY D. Pollock et al.



scoping review authors during the process of extraction from included sources. This means that data
extraction can evolve to capture new and different
data items, requiring an iterative approach; for example, if collecting data on education courses, details on assessment methods used may not have been
considered initially, but may then be deemed important throughout the process. It is not uncommon to
add additional items to the data extraction form
during the process. If additional items are extracted
that were not prespecified, it should be made clear in
the final report that there was a deviation from the
protocol and a rationale provided as to why it
occurred.


Identifying the relevant information in the
evidence source
In systematic reviews that analyze primary research
articles, data are typically extracted from the methods and results of included sources. This may not be
strictly the case for scoping reviews. This is due to
the varied types of data included within scoping
reviews. Scoping reviews do not typically pose
analytical questions where extracting the results of
primary research (such as effect sizes or qualitative results) is necessary. [2] Hence, authors may be
required to examine other sections of a source,
including the introduction, discussion, conclusions,
and even supplementary information. For example,
a scoping review might be conducted to identify and
report on the methodological approaches that have
been used to investigate a particular topic, and in
this case, the methods section would be the primary
place where extraction will occur. In the review by
Khalil and Huang, [14] the authors extracted both the
methodology and methods associated with each
study as part of their review to map the work that
has been undertaken in the area of medication adverse events in primary care. In another scoping
review, Hoppe et al. [15] mapped the research addressing prescription drug monitoring programs and
extracted from the discussion section of primary
research articles to determine what they perceived
their results to be, as well as the gaps and areas in
need of further research.
Depending on the purpose and review questions
posed, scoping review authors may or may not aim
to extract the results of primary studies. For example, in a scoping review addressing medication safety
programs, the authors extracted information about



the types of programs, the personnel involved in the
programs, and the outcome measures used to measure the efficacy of the programs. Despite extracting
some results information, the authors did not
gather information about the effectiveness of the
programs. [16]

Scoping reviews that serve as precursors to
systematic reviews could, with clear rationale and
justification, focus on the extraction of results, as
seen in a scoping review performed to inform the
feasibility and appropriateness of a health technology assessment. [17] In scoping reviews exploring
barriers and facilitators, reviewers may extract from
the results of qualitative primary studies and then
subsequently categorize these as barriers or facilitators. [18,19] However, in each of these cases, we suggest
that scoping review authors be explicit regarding the
inability to draw conclusions regarding the effectiveness (or prevalence, meaningfulness, accuracy, or
costs) of a practice or phenomenon due to the
absence of a risk of bias assessment or advanced
data synthesis techniques, such as meta-analysis or
meta-synthesis. Scoping review authors can, however, recommend that subsequent specific systematic
reviews be undertaken based on the results of their
scoping review.
We advocate for extreme caution in cases where a
scoping reviewer would want to extract the results
of evidence sources. In most instances, a systematic
review approach will be the more suitable methodology for dealing with review questions that require
the extraction of the results (eg, effect measures
and variance, meaning of phenomena) of included
sources. Systematic reviews typically include
methodological quality assessment and utilize,
where appropriate, formal methods of data synthesis
or aggregation.
Extracting and presenting results (for example, a
relative risk with associated confidence intervals
and P values or themes from a qualitative thematic
analysis) may lead to misplaced conclusions regarding the effectiveness (or not) of an intervention, the
prevalence of a condition, the accuracy of a test, or
the experience of a condition/phenomenon. This is
due to the included sources of evidence not having
undergone a process of critical appraisal (or risk of
bias appraisal) and, also, not having undergone a
process of pooling or aggregation that considers the
combination of all study results. Without this assessment of methodological quality and pooling or



JBI Evidence Synthesis - 2023 JBI 524


METHODOLOGY D. Pollock et al.



aggregation, authors and readers may be susceptible
to making false assumptions based on a naïve or
incomplete reading of the results and be more
inclined to apply vote counting of results. In this
instance, a systematic review is likely the more
suitable methodology for dealing with review questions that require the extraction of the results (eg,
effect measures and variance) of included sources.


Analysis in scoping reviews


Scoping review authors should present the intended
analytical approach that will be used within their
scoping review in the protocol. Scoping review
authors should clearly articulate how they intend
to analyze and present each review question, as this
may vary. The detail provided by authors should be
more than a general statement that they will undertake descriptive statistics, tables, and a narrative
summary. Rather, there should be a comprehensive
description of the analyses undertaken in order to
address each individual review question/objective.
Scoping review authors may be tempted to perform more advanced statistical or qualitative analysis
within a scoping review. [6] The intention of synthesis
methods, such as meta-analysis, meta-ethnography,
thematic analysis, realist synthesis, or meta-aggregation, among others, is to answer questions or inform
understandings regarding the feasibility, appropriateness, meaningfulness, and effectiveness of a particular
intervention or phenomenon. [6] Therefore, for these
questions, the most appropriate review type is a systematic review where the findings/results have undergone critical appraisal, and approaches to establish
certainty of those results have been applied to generate conclusions that can inform practice and policy
recommendations.
Scoping reviews do not address questions of feasibility, appropriateness, meaningfulness, or effectiveness, and, as such, will not and should not apply
advanced analysis methods. If scoping review
authors feel that they are unable to answer their
review question without the use of a meta-analysis,
for example, then the question they are asking is
possibly best suited for a quantitative systematic
review. [2]

Most scoping reviews will analyze data items by
quantifying text and doing frequency counts of data
extraction items. These are relatively easy to manage, and should only require the use of descriptive



statistics, such as percentages/proportions. For example, common frequencies seen in scoping reviews
are the number of evidence sources that used a
particular method (eg, numbers of RCTs, surveys,
or evidence syntheses) or the location/country/context where the evidence source was conducted.
Furthermore, scoping review authors can extract
relevant information aligning to a framework with
single-word responses such as “yes,” “no,” or
“unsure,” or even through the use of a Likert scale.
For example, in a recent scoping review, the authors
mapped exercise interventions to the Template for
Intervention Description and Replication (TIDieR)
checklist. [20] For the 9 items on the checklist, reviewers classified each as either fully reported, partially reported, or not reported for each included
evidence source. [21]


Using basic qualitative content analysis


In scoping reviews that include qualitative evidence,
it is not uncommon for authors to use qualitative
synthesis approaches that go beyond the scope of a
scoping review, such as thematic synthesis or a metaaggregative approach. These approaches are not
appropriate within a scoping review, as they are
better suited to examining questions of experiences
and meaningfulness, and require a level of interpretation, which would align more appropriately with a
systematic review. Synthesis approaches that aim to
reinterpret evidence are not consistent with the purposes of a scoping review. Scoping reviews are
descriptive in nature; they aim to map the available
evidence or identify characteristics or factors. For
the most part, there will be no need for scoping
review authors to go beyond basic descriptive analysis. However, there may be times when it would be
appropriate to use a basic qualitative content analysis, such as if the scoping review is identifying key
characteristics or factors related to a concept. This
may be necessary when a scoping review has the
objective of informing the development of a conceptual framework or theory.
When performing basic qualitative content analysis,
categorization is required to map the results to aid
their simplification to address the scoping review question. For example, in a scoping review by Hoppe
et al., [22] the authors mapped the evidence associated
with community pharmacists’ views toward drug
misuse management, categorizing the results into



JBI Evidence Synthesis - 2023 JBI 525


METHODOLOGY D. Pollock et al.



pharmacists’ knowledge, training and education, attitudes, and practice strategies. [22]

JBI scoping review guidance recommends using
basic qualitative content analysis, [6] which is a
descriptive approach to analysis and involves a
process of open coding to allocate concepts or characteristics into overall categories. This can be
applied to any evidence source or study design in
any scoping review; it is not limited to primary
qualitative studies. In previous guidance, including
from JBI, there has been no definitive description of
what basic qualitative content analysis involves, and
it is acknowledged that there are many different
analytical approaches that could be undertaken.
However, the present paper describes one approach
that could be undertaken by scoping review authors.


A basic qualitative content analysis approach for
scoping reviews
Elo and Kyngäs [23] describe 3 phases of qualitative
content analysis for the results of primary qualitative
research: i) preparation, ii) organizing, and iii) reporting. These phases could also be used to describe
a basic process of qualitative analysis within scoping
reviews. A fourth “abstraction” phase is also described by Elo and Kyngäs [23] ; however, this technique would be beyond the realm of a scoping review,
in which we do not seek to synthesize or reinterpret
evidence. Figure 1 shows the process of conducting
the analyses of qualitative data within a scoping
review.


Preparation phase
Scoping review authors should first determine if
there is a need to conduct a basic qualitative content
analysis during the protocol stage of their scoping
review. If the aim of the review were to explore
experiences or the meaningfulness of an issue, then
a qualitative systematic review would be more appropriate. [2] If a basic qualitative content analysis
approach is deemed necessary (eg, as the characteristics of a particular issue or definitions of a concept
are being mapped), then it would be appropriate to
use this method within scoping reviews.
Depending on the research question and the field
of research, an inductive or deductive approach will
need to be chosen by the scoping review team during
the protocol development stage and subsequently
reported within the protocol. These terms will be
familiar to qualitative researchers. An inductive



approach may be useful where there is a dearth of
evidence on the topic, or the goal is to develop or
inform a conceptual framework or theory. [23] The
deductive approach is typically used to map the data
to an established framework or theory within the
literature. [23] There may be times, however, when a
deductive approach is chosen without using a preexisting framework (eg, when no suitable framework or theory can be found). In such situations,
the review team needs to select a framework during


Figure 1: The process of conducting the analyses
of qualitative data within a scoping review



JBI Evidence Synthesis - 2023 JBI 526


METHODOLOGY D. Pollock et al.



the protocol stage and, ideally, will have consulted
on the suitability of the framework.


Organizing phase
The organizing phase during qualitative data analysis
within scoping reviews will differ depending on
whether the scoping review is following an inductive
or deductive approach. [23] The first step in the organization stage is for the review authors to familiarize
themselves with the data. This includes reading and
comprehending all the included evidence sources and
understanding how the data are relevant to the objective and questions of the scoping review. [23]


Inductive approach
When the authors have become familiar with the
sources of evidence and relevant data, review
authors can then carry out open coding of the data.
A code can be described as a label and can be an
initial descriptor that is a few words long. The process of open coding involves reviewing the evidence
sources again and listing initial thoughts, possible
categories, or notes that help describe what is occurring within the data, which explains the objective
and review question. During this stage, there are no
limitations as to how many high-level categories can
be listed. This is an initial process that will be refined. Once the open coding process has occurred,
the coding framework can be developed. This will
involve gathering all the information in the previous
stage to develop a coding framework to help describe and answer the review questions and allow
the organization of extracted data.
At this stage, the coding framework may include
higher order categories or subcategories. It is also
beneficial to provide a definition of these categories
and subcategories to help extractors, as well as to
show transparency in the decision-making that has
occurred throughout this process. The coding framework should be reviewed by all members of the
review team. Once the coding framework has been
reviewed, extractors are then able to go through
the included evidence sources, extract the relevant
information, and organize it within the coding
framework. Categorization involves exploring the
organized extractions and assessing whether the initial coding framework adequately answers the review question. It is common for the categories and
subcategories within the initial coding framework to
be changed during this stage to accommodate new



understandings of what was stated within the evidence sources. These categories can form a conceptual framework or theory.


Case study of inductive qualitative data extraction

and analysis
A scoping review was undertaken to assess the available literature that documents or utilizes patient
journey mapping methodologies and examine their
reporting processes. [24] After an extensive searching
and selection process, there were 81 included evidence sources within this scoping review. The scoping
review authors chose to extract information about
why primary authors would use patient journey mapping. The scoping review authors extracted 76 justifications. During the analysis stage, the scoping
review team met several times to examine each of
these justifications. The process of analysis included
listing initial thoughts, possible categories, or notes
(which help describe what is occurring within the
data), with the eventual goal to make a smaller list
of common justifications of why researchers choose
patient journey mapping. After meeting several times
as a group, 10 categories were identified, including
comprehensiveness of care, how people were navigating the system, patient satisfaction with services, and
comparing patient experiences with standards of
practice. An example of this process of developing
categories is presented in Figure 2; however, this is
not a linear process and it may be necessary to reexamine the categories and establish whether they
could be further refined.
Once the framework had been developed, 2 scoping review authors individually went through the
extracted data and assigned it to a category. These
review authors then came together and assessed if
there were any discrepancies. All discrepancies were
discussed and consensus was achieved; however, a
third reviewer had agreed to manage any discrepancies that could not be resolved through discussion.


Deductive approach
As described above, in the deductive approach, the
framework has already been developed during the
protocol stage. Therefore, the review authors can
extract data according to that framework by extracting the verbatim text, which maps to the decided
framework and answers the proposed questions.
Once this is completed, the extractions should then
be reviewed by the members of the review team to



JBI Evidence Synthesis - 2023 JBI 527


METHODOLOGY D. Pollock et al.


Figure 2: Example of the process of inductive analysis



ensure that they reflect the understanding of the
framework. There may be a scenario where scoping
review authors initially utilize a deductive framework and then recognize that this would not be
the best fit for the extracted data and its ability to
provide a descriptive map of the available evidence.
Therefore, the scoping review authors can switch to
an inductive approach during the extraction and
analytical steps of a scoping review and document
this deviation from the protocol in the final review.


Case study of deductive qualitative data extraction

and analysis
A scoping review was conducted to identify barriers
and facilitators in the prevention of type 2 diabetes
mellitus and gestational diabetes in vulnerable
groups. [2] After searching several databases, 125 evidence sources were included. A preexisting framework had been developed prior to the extraction of
the data, which included 8 categories: i) language, ii)
economic factors, iii) family and friends, iv) work, v)
social support, vi) religion, vii) culture, and viii)
knowledge. During extraction, scoping review
authors extracted barriers and facilitators and then
sorted them into prearranged categories. Other barriers that did not fit into these prearranged categories were found, and they included insufficient
time, problems with traveling, and insufficient motivation; however, these were minimal and the framework did not change. [25]


Including other forms of evidence synthesis
and the issue of double counting


An issue seen within systematic reviews is ensuring
that the same data set is not counted across multiple
studies. Double counting issues can arise in scoping
reviews for numerous reasons, such as when evidence



synthesis and primary articles are included (ie, there is
the potential for overlap). There may also be a
scenario where multiple evidence synthesis sources
are included in the scoping review and the primary
article is included within them all or there are several
reports of the same primary study. This may become
problematic if, for example, the review question is
attempting to determine the type and frequency of
outcomes being used within a particular field of
work, as scoping review authors may count the same
outcome from both the original study and any
evidence synthesis source that also included the
original study, thus skewing the prominence.
While there is no formal guidance on how to
manage this issue, scoping review authors should
be aware of the risk and make efforts to avoid
counting the same data items multiple times from
different sources. Authors may decide to still include the evidence synthesis within the scoping
review to be able to map the available evidence
and to report the number of evidence syntheses
mapped. Guidance for systematic reviews and
overviews (reviews of reviews/umbrella reviews) [26]

might also apply. However, scoping review authors
should clearly report which other included sources
of primary evidence were included within that evidence synthesis. The final scoping review report
should clearly state how other types of evidence
synthesis were handled in the review and what data
were extracted from them and from the primary
studies (if appropriate).


Presentation of data


There are a multitude of ways that scoping reviews
can present data and answer the proposed review
questions. Scoping reviews commonly include tables
that present the available data. Although tables are



JBI Evidence Synthesis - 2023 JBI 528


METHODOLOGY D. Pollock et al.


Figure 3: Example of data presentation in a scoping review: world heat map showing the number of
included studies conducted in each country



useful, as they can summarize a large amount of
information and show how extraction has occurred,
authors should also consider how to communicate
the results of the scoping review to the wider community. Further, scoping review results with many
included sources may result in tables that are too
large to easily present in the standard fashion of a
journal article. There are many creative approaches
that scoping reviews can include to convey results to
the reader in an understandable way. For example,
Tricco and Lillie [5] visualized the different terminology of scoping reviews through a word cloud.
Kynoch and Ramis [27] used a honeycomb to visualize
the outcomes in the included evidence sources and
the number of relevant studies. The author team,
using Power BI (Microsoft, Redmond, USA), developed 4 further examples of how scoping review
results can be visualized. In Figure 3, the authors
have created a world heat map with the size of the
circle indicating how many evidence sources were
conducted in that country. Figure 4 is a tree graph
indicating the illness categories seen within the included evidence. Figure 5 uses iconography to represent the different types and number of populations



included within the evidence sources. Finally,
Figure 6 uses waffle charts to indicate the type of
methodology used by the evidence sources included
within a scoping review.
Alongside any visual presentation, a supporting
narrative must be provided describing the results. A
further option for the presentation of scoping review
results is the use of interactive resources. An example
of this is the searchable interactive map of outcome
tools and International Scientific Tendinopathy Symposium Consensus health domains relative to tendinopathy types presented as supplementary files in a
scoping review of exercise for tendinopathy. [21]


Reporting scoping reviews


PRISMA-ScR provides a checklist for reporting a
scoping review. It has clear guidance on how to
report the extraction (called “data charting” within
PRISMA-ScR), analysis (called “data synthesis”),
and presentation of data. Items 10, 11, 14, 17, 18,
20, and 21 are applicable for these sections and
should be referred to while writing the scoping review report to ensure a transparent and rigorous



JBI Evidence Synthesis - 2023 JBI 529


METHODOLOGY D. Pollock et al.


Figure 4: Example of data presentation in a scoping review: tree graph of illness categories identified
within the included evidence sources



process. A completed PRISMA-ScR checklist that
documents page numbers where each of these actions have been addressed should also be included as
a supplementary file to the scoping review report.
Because the checklist requires authors to indicate the
page numbers, authors should ensure that these page
numbers are accurate in the final proofs of your
scoping review if it is to be published, otherwise they
will not match up.


Figure 5: Example of data presentation in a
scoping review: a visual representation of the
different types of populations included within the
evidence sources



PRISMA-ScR also provides an appendix (PRISMA
extension for Scoping Reviews explanation and elaboration) that describes each section, details which
sections need to be reported within a scoping review,
and provides a written example of how this can be
achieved within a report.


Software


There are many software programs that can be used
to assist in the extraction, analysis, and presentation
of scoping review data. These include Google Sheets
(Alphabet Inc., California, USA), as this allows for
real-time editing and can manage version control
issues; however, Microsoft Excel (Redmond, Washington, USA) is also appropriate for data extraction and can facilitate basic descriptive analyses.
NVivo (QSR International, United Kingdom) is also
often used in the extraction, analysis, and presentation of qualitative information. Further, data visualization programs can include Microsoft Power BI or
Tableau (Salesforce, California, USA). For mapping,
EPPI-Mapper (Digital Solution Foundry and EPPICentre, London, UK) and EndNote (Clarivate
Analytics, PA, USA) are useful tools, among others.



JBI Evidence Synthesis - 2023 JBI 530


METHODOLOGY D. Pollock et al.


Figure 6: Example of data presentation in a scoping review: waffle chart of the methodology used
within the included evidence sources



Author familiarity with the software and its application helps facilitate the data extraction, analysis, and
presentation of results.


Conclusion


Scoping reviews aim to systematically identify and
map the breadth of evidence available on a particular topic, field, concept, or issue within or across
particular contexts, and this requires a different
analytical approach from systematic reviews. The
extraction, analysis, and presentation of results
within a scoping review can be challenging due to
the variety of evidence sources that scoping reviews
can include and the absence of specific guidance for
reviewers. This article has partially addressed this
gap by providing guidance on how to extract,
analyze, and present data within scoping reviews.
It is hoped that scoping review authors will be able
to use this guidance to improve the quality and
clarity of published scoping reviews and to make
conducting and reporting scoping reviews easier.


Funding


ACT is funded by a Tier 2 Canada Research
Chair in Knowledge Synthesis. ZM is supported by
an NHMRC Investigator Grant, APP1195676. The
funding bodies did not have any input into the paper.


References

1. Munn Z, Pollock D, Khalil H, Alexander L, McInerney P,
Godfrey CM, et al. What are scoping reviews? Providing a
formal definition of scoping reviews as a type of evidence
synthesis. JBI Evid Synth. 2022;20(4):950–2.



2. Munn Z, Peters MDJ, Stern C, Tufanaru C, McArthur A,
Aromataris E. Systematic review or scoping review? Guidance for authors when choosing between a systematic or
scoping review approach. BMC Med Res Methodol 2018;18
(1):143.

3. Peters MDJ, Godfrey C, McInerney P, Khalil H, Larsen P,
Marnie C, et al. Best practice guidance and reporting items
for the development of scoping review protocols. JBI Evid
Synth 2022;20(4):953–8.
4. Khalil H, Peters MDJ, Tricco AC, Pollock D, Alexander L,
McInerney P, et al. Conducting high quality scoping reviews-challenges and solutions. J Clin Epidemiol 2021;
130:156–60.
5. Tricco AC, Lillie E, Zarin W, O’Brien K, Colquhoun H,
Kastner M, et al. A scoping review on the conduct and
reporting of scoping reviews. BMC Med Res Methodol
2016;16(1):15.
6. Peters MDJ, Marnie C, Tricco AC, Pollock D, Munn Z, Alexander
L, et al. Updated methodological guidance for the conduct of
scoping reviews. JBI Evid Implement 2021;19(1):3–10.
7. Arksey H, O’Malley L. Scoping studies: towards a methodological framework. Int J Social Res Methodol 2005;8(1):
19–32.
8. Levac D, Colquhoun H, O’Brien KK. Scoping studies: advancing the methodology. Implement Sci 2010;5(1):69.
9. Tricco AC, Lillie E, Zarin W, O’Brien KK, Colquhoun H, Levac
D, et al. PRISMA extension for Scoping Reviews (PRISMAScR): checklist and explanation. Ann Intern Med 2018;169
(7):467–73.
10. Tricco AC, Tetzlaff J, Moher D. The art and science of
knowledge synthesis. J Clin Epidemiol 2011;64(1):11–20.
11. Jull JE, Davidson L, Dungan R, Nguyen T, Woodward KP,
Graham ID. A review and synthesis of frameworks for
engagement in health research to identify concepts of
knowledge user engagement. BMC Med Res Methodol
2019;19(1):211.



JBI Evidence Synthesis - 2023 JBI 531


METHODOLOGY D. Pollock et al.



12. Pollock D, Alexander L, Munn Z, Peters MDJ, Khalil H, Godfrey CM, et al. Moving from consultation to co-creation with
knowledge users in scoping reviews: guidance from the JBI
Scoping Review Methodology Group. JBI Evid Synth 2022;20
(4):969–79.
13. Robson RC, Pham B, Hwee J, Thomas SM, Rios P, Page MJ,
et al. Few studies exist examining methods for selecting
studies, abstracting data, and appraising quality in a
systematic review. J Clin Epidemiol 2019;106:121–35.
14. Khalil H, Huang C. Adverse drug reactions in primary
care: a scoping review. BMC Health Serv Res 2020;20
(1):5.
15. Hoppe D, Karimi L, Khalil H. Mapping the research addressing prescription drug monitoring programs: a scoping
review. Drug Alcohol Rev 2022;41(4):803–17.
16. Khalil H, Shahid M, Roughead L. Medication safety programs in primary care: a scoping review. JBI Database
System Rev Implement Rep 2017;15(10):2512–26.
17. Prediger B, Mathes T, Probst C, Pieper D. Elective removal
vs. retaining of hardware after osteosynthesis in asymptomatic patients—a scoping review. Syst Rev 2020;9(1):
225.
18. Tricco AC, Cardoso R, Thomas SM, Motiwala S, Sullivan S,
Kealey MR, et al. Barriers and facilitators to uptake of
systematic reviews by policy makers and health care managers: a scoping review. Implement Sci 2016;11:4.
19. Tricco AC, Zarin W, Rios P, Nincic V, Khan PA, Ghassemi M,
et al. Engaging policy-makers, health system managers,
and policy analysts in the knowledge synthesis process: a
scoping review. Implement Sci 2018;13(1):31.



20. Hoffmann TC, Glasziou PP, Boutron I, Milne R, Perera R,
Moher D, et al. Better reporting of interventions: template
for intervention description and replication (TIDieR) checklist and guide. BMJ 2014;348:g1687.
21. Alexander LA, Harrison I, Moss RA, Greig L, Shim J,
Pavlova AV, et al. Exercise therapy for tendinopathy: a scoping review mapping interventions and outcomes. SportRXiv
2021.
22. Hoppe D, Ristevski E, Khalil H. The attitudes and practice
strategies of community pharmacists towards drug misuse
management: a scoping review. J Clin Pharm Therapeut
2020;45(3):430–52.
23. Elo S, Kyngäs H. The qualitative content analysis process.
J Adv Nurs 2008;62(1):107–15.
24. Davies EL, Pollock D, Graham A, Laing RE, Langton V, Bulto
L, et al. Reporting of patient journey mapping in current
literature: a scoping review protocol. JBI Evid Synth 2022;20
(5):1361–8.
25. Breuing J, Pieper D, Neuhaus AL, Heß S, Lütkemeier L, Haas
F, et al. Barriers and facilitating factors in the prevention
of diabetes type 2 and gestational diabetes in vulnerable
groups: a scoping review. PLoS One 2020;15(5):e0232250.
26. Lunny C, Pieper D, Thabet P, Kanji S. Managing overlap of
primary study results across systematic reviews: practical
considerations for authors of overviews of reviews. BMC
Med Res Methodol 2021;21(1):140.
27. Kynoch K, Ramis M-A, Crowe L, Cabilan CJ, McArdle A.
Information needs and information seeking behaviors of
patients and families in acute healthcare settings: a scoping review. JBI Evid Synth 2019;17(6):1130–53.



JBI Evidence Synthesis - 2023 JBI 532


