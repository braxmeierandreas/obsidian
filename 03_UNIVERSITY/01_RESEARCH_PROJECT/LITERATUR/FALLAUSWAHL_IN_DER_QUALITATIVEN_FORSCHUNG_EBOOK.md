utb 6521


Eine Arbeitsgemeinschaft der Verlage


Brill | Schöningh – Fink · Paderborn
Brill | Vandenhoeck & Ruprecht · Göttingen – Böhlau · Wien · Köln
Verlag Barbara Budrich · Opladen · Toronto
facultas · Wien
Haupt Verlag · Bern
Verlag Julius Klinkhardt · Bad Heilbrunn
Mohr Siebeck · Tübingen
Narr Francke Attempto Verlag – expert verlag · Tübingen
Psychiatrie Verlag · Köln
Psychosozial-Verlag · Gießen
Ernst Reinhardt Verlag · München
transcript Verlag · Bielefeld
Verlag Eugen Ulmer · Stuttgart
UVK Verlag · München
Waxmann · Münster · New York
wbv Publikation · Bielefeld
Wochenschau Verlag · Frankfurt am Main


Margrit Schreier
Nicole Weydmann

### **Fallauswahl in der** **qualitativen Forschung**


Ein Leitfaden für Studium
und Methodenpraxis

###### Verlag Barbara Budrich Opladen & Toronto 2025


**Die Autorinnen:**


**Margrit Schreier**, Constructor University Bremen
**Nicole Weydmann**, Hochschule Furtwangen


Bibliografische Information der Deutschen Nationalbibliothek
Die Deutsche Nationalbibliothek verzeichnet diese Publikation in der Deutschen
National­bibliografie; detaillierte bibliografische Daten sind im Internet über
[https://portal.dnb.de abrufbar.](https://portal.dnb.de)


Gedruckt auf FSC®-zertifiziertem Papier, CO2-kompensierte Produktion.
[Mehr Informationen unter https://budrich.de/nachhaltigkeit/. Printed in Europe.](https://budrich.de/nachhaltigkeit/)


Alle Rechte vorbehalten.
© 2025 Verlag Barbara Budrich GmbH, Opladen & Toronto
[Stauffenbergstr. 7 | D-51379 Leverkusen | info@budrich.de | www.budrich.de](mailto:info@budrich.de)


**utb-Bandnr.** **6521**
**utb-ISBN** **978-3-8252-6521-2**
**utb-e-ISBN** **978-3-8385-6521-7 (PDF)**
**DOI** **10.36198/9783838565217**


Das Werk einschließlich aller seiner Teile ist urheberrechtlich geschützt. Jede
Verwertung außerhalb der engen Grenzen des Urheberrechtsgesetzes ist ohne
Zustimmung des Verlages unzulässig und strafbar. Das gilt insbesondere für Vervielfältigungen, Übersetzungen, Mikroverfilmungen und die Einspeicherung und Verarbeitung in elektronischen Systemen.


Online-Angebote oder elektronische Ausgaben sind erhältlich unter
[https://www.utb.de/.](https://www.utb.de/)


Druck: Elanders Waiblingen GmbH, Waiblingen
[Satz: Linda Kutzki, Berlin – www.textsalz.de](http://www.textsalz.de)
Umschlaggestaltung: siegel konzeption | gestaltung
Titelbildnachweis: Michael Peter Ancher, En strandpromenade (1896);
Skagens Museum, Inventarnummer SKM1245; via Wikimedia Commons


#### **Inhaltsverzeichnis**

**Abbildungsverzeichnis** 7
**Vorwort** 9
**Eine Einladung** 10


**1 Fallauswahl in der qualitativen Forschung: Grundlagen** 13
1.1 Grundbegriffe: Grundgesamtheit, Stichprobe, Fallauswahl 14
1.2 Formen der Stichprobenziehung 17
1.3 Das Wann und Wo absichtsvoller Fallauswahl 21
1.4 Gesichtspunkte bei der qualitativen Fallauswahl 24
1.5 Wie viele Fälle sind genug? 29
Weiterführende Literatur 33


**2 Strategien absichtsvoller Fallauswahl** 34
2.1 Kriterienorientierte Fallauswahl 34
2.2 Qualitativer Stichprobenplan und Maximum-Variation-Sampling 36
2.3 Theoretical Sampling 39
2.3.1 Erste Phase: Die selektive Fallauswahl 41
2.3.2 Zweite Phase: Die relationale Fallauswahl 42
2.3.3 Dritte Phase: Die theoretische Fallauswahl 46
2.4 Gezielte Auswahl bestimmter Arten von Fällen 48
2.5 Sampling Schemes: Das Vorgehen bei der konkreten Auswahl

von Untersuchungseinheiten 51
2.5.1 Das Schneeballverfahren 51
2.5.2 Die Ad-Hoc-Fallauswahl 55
2.5.3 Die Zufallsauswahl 56
Weiterführende Literatur 58


**3 Fallauswahl im Kontext qualitativer Ansätze** 59
3.1 Gegenstandsbegründete Theoriebildung 59
3.1.1 Theoretische Sensibilität 62
3.1.2 Kontrastives Vorgehen 63
3.1.3 Kodieren 65


5


Inhaltsverzeichnis


3.1.4 Memos Schreiben 67
3.1.5 Theoretische Sättigung 67
3.2 Fallstudie 69
3.3 Ethnografie 74
3.4 Phänomenologie 79
3.5 Diskursforschung und Diskursanalyse 81
3.6 Der qualitative Survey 84
Weiterführende Literatur 87


**4 Fallauswahl im Kontext qualitativer Daten** 88
4.1 Interviews 88
4.1.1 Fallauswahl beim Leitfadeninterview: Das Konzept der Sättigung 88
4.1.2 Fallauswahl beim Experten- und beim narrativen Interview 93
4.2 Fokusgruppen 94
4.3 Beobachtung 100
4.4 Auswahl aus Dokumenten 103
4.4.1 Auswahl von textbasierten öffentlichen Dokumenten 104
4.4.2 Auswahl von visuellem Material 107
4.5 Auswahl aus digitalen Daten 109
4.5.1 Auswahl von Internetbasierten Daten 110
4.5.2 Auswahl von Daten aus sozialen Medien 114
Weiterführende Literatur 116


**5 Verallgemeinerung** 117
5.1 Hintergrund: Verallgemeinerung in der quantitativen Forschung 118
5.2 Die empirische Verallgemeinerung in der qualitativen Forschung 120
5.2.1 Verallgemeinerung auf der Grundlage einer typischen Stichprobe 121
5.2.2 Verallgemeinerung auf Existenzsätze 124
5.2.3 Moderatum-Verallgemeinerung 125
5.3 Übertragbarkeit als Alternative zur empirischen Verallgemeinerung 127
5.4 Analytische Verallgemeinerung 128
5.5 Interne Verallgemeinerung 133
Weiterführende Literatur 134


**Schluss** 135
**Literaturverzeichnis** 136


6


#### **Abbildungsverzeichnis**

Abb. 2.1: Zentrale Phasen des Theoretical Sampling 40
Abb. 3.1: Die Entstehungsgeschichte der Grounded-Theory-Methodologie 60
Abb. 3.2: Der iterative Forschungsprozess der GTM 61


7


#### **Vorwort**

Wir beide, Margrit Schreier und Nicole Weydmann, beraten seit vielen Jahren Studierende bei der Durchführung qualitativer Forschungsarbeiten, von Praktika während
des Studiums bis hin zu Dissertationen. Eine der häufigsten Fragen über alle Qualifikationsphasen hinweg betrifft die Fallanzahl: Wie viele Interviews „reichen aus“? Und
sind zehn Interviews besser als sieben? Obwohl der Gesichtspunkt der Fallauswahl eng
mit dem Untersuchungsdesign verbunden ist, wird er oft erst im Laufe der Datenerhebung oder -auswertung bedacht. Und auch in der Methodenliteratur wird das Thema
nur punktuell aufgegriffen.

In diesem kompakten Lehrbuch möchten wir uns systematisch mit dem Thema der
Fallauswahl in der qualitativen Forschung befassen und die verschiedenen Gesichtspunkte zusammenbringen, unter denen das Thema methodologisch diskutiert wird.
Wir können und wollen dabei keine konkreten Vorgaben machen, sondern möchten
qualitativ Forschenden Anhaltspunkte geben, an Hand derer sie informierte Entscheidungen über eine angemessene Fallanzahl treffen können.

Die methodologischen Überlegungen werden durch eine Vielzahl an Forschungsbeispielen ergänzt. Außerdem unterstützen wir den Leseprozess durch Kursivsetzung
derjenigen Begriffe, die in einem Abschnitt von zentraler Bedeutung sind, und die
Zusammenfassung von Kernpunkten in Boxen. Außerdem sind solche Begriffe, die in
einer Forschungstradition methodologisch besonders relevant und ausgearbeitet sind
(wie etwa: Theoretical Sampling in der Grounded-Theory-Methodologie) durch Großschreibung gekennzeichnet. Weiterhin stehen im Rahmen der Online-Materialien für
jedes Kapitel Lernziele sowie Fragen zur Überprüfung des eigenen Verständnisses zur
Verfügung.

Wir danken allen Studierenden, die mit ihren Forschungsprojekten und Fragen im
Laufe der Jahre zum Entstehen dieses Bandes beigetragen haben. Dazu zählen wesentlich auch die Teilnehmer:innen an unseren Workshops und Forschungswerkstätten,
die wir seit bald acht Jahren gemeinsam im Rahmen des Berliner Methodentreffens
durchführen. Den Organisator:innen des Methodentreffens, insbesondere Günter
Mey, Katja Mruck und Rubina Vock, gilt ebenfalls unser Dank. Bedanken möchten wir
uns auch bei unseren akademischen Lehrer:innen und Wegbegleiter:innen, vor allem
bei Franz Breuer und Norbert Groeben. Und schließlich – last, aber keineswegs least –
geht unser Dank an den Verlag Barbara Budrich für die ausgesprochen konstruktive
und unterstützende Zusammenarbeit, insbesondere an Herrn Philip Bergstermann,
der sich von unserer chronischen Arbeitsüberlastung nicht hat entmutigen lassen und
immer wieder freundlich nachgehakt hat, und an Frau Budrich für unser CoachingGespräch, das immer noch als Empowerment in uns nachwirkt.


Margrit Schreier, Bremen
Nicole Weydmann, Freiburg
Mai 2025

9


#### **Eine Einladung**

_Nicht alles, was zählt, kann gezählt werden,_
_und nicht alles, was gezählt werden kann, zählt._
_(Albert Einstein)_


Eine neue Studie beginnen, Daten erheben – das ist immer auch ein Schritt in eine bis
dahin unbekannte Welt. Als Forschenden geht es uns hier ähnlich wie einer Künstlerin, die mit dem Pinsel in der Hand vor einer leeren und unberührten Leinwand steht.
Quantitativ Forschende machen sich vorab einen Plan: Sie überlegen, wie das Bild am
Ende aussehen soll, unterteilen die Leinwand in abgegrenzte Bereiche und entscheiden, wo genau sie mit dem Pinsel dieses Braun und jenes Blau auftragen. Sie sehen das
Bild schon vor sich, bevor sie noch den ersten Pinselstrich ausgeführt haben.

Ganz anders stellt sich die Situation für qualitativ Forschende dar: Für sie ist die
unberührte Leinwand eine Welt unendlicher Möglichkeiten, und das endgültige Bild
entsteht erst im Verlauf des künstlerischen Prozesses. Und auch wenn die Sonne ihre
Lichtmuster auf die Leinwand wirft und versucht, sie zu inspirieren, stehen sie vor der
Wahl der Pinsel und vor der Fülle an Farbtuben und -nuancen. Jede einzelne Farbe will
sorgfältig ausgewählt sein, denn mit jedem neuen Pinselstrich kommt immer beides
zum Ausdruck: die äußere Welt, die es darzustellen gilt, und die innere Welt, die Wahrheit der Künstler:innen.

Als qualitativ Forschende müssen wir, ähnlich einer Künstlerin, die sorgfältig ihre
Farben und Werkzeuge aussucht, mit Bedacht diejenigen Fälle auswählen, die in der
Lage sind, unser persönliches Bild von Wirklichkeit klar und vielschichtig wiederzugeben. Denn neben der Wahl der Farbe wird spätestens beim zweiten Pinselstrich auch
die Frage aufkommen, welche Perspektiven und welcher Fokus in unsere Bemühungen
einfließen sollen. Wen beziehen wir ein, welche Gruppen und Milieus sind ausschlaggebend für unseren Fokus? Wir können nicht alles Wahrnehmbare in unserer einen
Studie abbilden – nicht ein ganzes Meer, sondern vielleicht nur einen Regentropfen.
Aber dieser eine Regentropfen kann tiefe Einsichten vermitteln, die im gesamten Meer
vielleicht gar nicht in den Blick kommen und so untergehen würden.

Und genau darin liegt die Kunst der absichtsvollen Entscheidungen: die Welt in
ihrer überwältigenden Komplexität, der Vielzahl von Momenten und flüchtigen Eindrücke im Rahmen unserer begrenzten Mittel zu verstehen, zu ordnen und schließlich
nachvollziehbar darzustellen. Deshalb ist die absichtsvolle Fallauswahl für uns nicht
nur ein schlichtes methodisches Werkzeug, sondern auch ein systematisches Nachdenken über unsere eigenen Entscheidungen und die damit verbundenen Herausforderungen. Es geht darum, angesichts der unendlichen Möglichkeiten der unberührten


10


Einladung


Leinwand bewusste Entscheidungen zu treffen; zu akzeptieren, dass mit dem Fokus
auf die eine Perspektive notwendig der Verzicht auf andere Perspektiven verbunden
ist; uns zu begrenzen; und diese Entscheidungen auch nach außen zu vertreten.

Allerdings sind auch qualitativ Forschende vor der Leinwand ihrer Studie nicht auf
sich allein gestellt. Sie mögen noch keine klare Vorstellung davon haben, wie ihr Bild
am Ende aussehen wird und wo sie welchen Farbton aufbringen müssen. Aber natürlich
können auch sie auf eine reiche Tradition zurückgreifen. So wie Künstler:innen über
Wissen zu Kompositionsformen, Bildaufteilung, Perspektive oder Blickführung verfügen müssen, sollten qualitativ Forschende bestimmte Grundbegriffe kennen. Ebenso
sollten sie sich darüber im Klaren sein, welche Entscheidungen bei der Fallauswahl
anstehen und wie diese sich über den gesamten Forschungsprozess hinweg erstrecken.
Und nicht zuletzt sollten sie sich Gedanken darüber machen, wann sie ihre Datenerhebung beenden. Denn genauso, wie ein Bild nicht unbedingt gewinnt, wenn die Künstlerin immer noch weiter verändert und neue Akzente setzt, kommt auch in einer qualitativen Studie irgendwann der Punkt, an dem weiteres Material keinen Erkenntnisgewinn
mehr bringt. An diese Grundbegriffe führen wir die Leser:innen im ersten Kapitel heran
und zeigen auf, welche Vorgehensweisen sich bisher bewährt haben.

Für Künstler:innen ebenso wie qualitativ Forschende stellt sich als nächstes die
Frage: Was will ich überhaupt abbilden, was soll mein Bild, meine Studie zeigen? Will
ich beispielsweise ein buntes Gewimmel von Eisläufer:innen darstellen, mit Mützen
und Handschuhen in vielen verschiedenen Farben? Oder will ich mich auf die Pirouette einer einzelnen Läuferin konzentrieren? Und wieviel von der Bildgestaltung will
ich vorab festlegen – oder soll das Bild ganz aus sich heraus im Gestaltungsprozess entstehen? Diese verschiedenen Vorgehensweisen entsprechen verschiedenen Strategien
der Fallauswahl, die qualitativ Forschenden zur Verfügung stehen. Im zweiten Kapitel
stellen wir die wichtigsten dieser Strategien dar und erläutern, wo ihre Stärken liegen.

Wenn einmal die Entscheidung gefallen ist, was in dem Bild dargestellt, was in der
Studie fokussiert werden soll, dann ist damit noch nichts darüber ausgesagt, wie diese
Entscheidung im Einzelnen umgesetzt wird. Eine Künstlerin hat beispielsweise die
Wahl, ob sie ihr Bild abstrakt oder realistisch gestalten will. Vielleicht neigt sie zum
Impressionismus oder zum Surrealismus. Vergleichbar stehen qualitativ Forschenden
ganz unterschiedliche Forschungstraditionen zur Verfügung, innerhalb derer sie ihre
Studie verorten und anlegen können, beispielsweise die Grounded-Theory-Methodologie, die Phänomenologie oder die Fallstudie. In Kapitel 3 gehen wir auf einige dieser
Ansätze genauer ein, die in der qualitativen Forschung über verschiedene Disziplinen
hinweg besonders oft angewandt werden, und zwar insbesondere unter dem Gesichtspunkt der Fallauswahl.

Angenommen, eine Künstlerin möchte eine einzelne Eiskunstläuferin in einer ganz
ungewöhnlichen Drehung im expressionistischen Stil darstellen. Nun muss sie noch
entscheiden, in welchem Medium sie das umsetzen möchte. Möchte sie in Öl oder lieber mit Kreide arbeiten? Auch qualitativ Forschende müssen eine Entscheidung über


11


Einladung


ihr Medium treffen bzw. über die Art der Daten, die sie erheben möchten, und über
die Erhebungsmethode. Sollen Daten aktiv erhoben werden, etwa im Interview? Oder
wäre eine Auswahl aus Blogbeiträgen angemessener? Handelt es sich um verbale, um
visuelle oder vielleicht um multimodale Daten? In Kapitel 4 stellen wir verschiedene
Methoden der Datenerhebung und verschiedene Datenarten im Hinblick auf ihre Konsequenzen für die Fallauswahl dar. Wir zeigen auf, welche Arten der Fallauswahl für
welche Datenarten und Erhebungsmethoden besonders geeignet sind. Auch dabei
mussten wir selbst wieder Entscheidungen treffen und uns auf ausgewählte Datenarten und Methoden begrenzen.

Ein Gemälde steht einerseits für sich selbst; es vermittelt einen intensiven und
unmittelbaren Eindruck. Zugleich bringt es aber in der Regel auch etwas Übergreifendes, Allgemeingültiges zum Ausdruck – im Bild der Eiskunstläuferin in ihrer kunstvollen Drehung ist dies vielleicht eine ganz bestimmte Kombination von Leichtigkeit
und Grazie einerseits und einer ungeheuren Anstrengung nach Jahren des Trainings
andererseits. Dies trifft ebenso auf die qualitative Forschung zu. Eine qualitative Studie ist einerseits aus sich selbst heraus von Interesse. Zugleich führen Forschende ihre
Studien jedoch nicht nur um ihrer selbst willen durch. Ihre Ergebnisse und Schlussfolgerungen sollen auch etwas über die einbezogenen Fälle und Daten hinaus aussagen.
Dabei geht es in der qualitativen Forschung mit ihrer bewussten Beschränkung auf
eher wenige ausgewählte Fälle meist nicht darum, von diesen Fällen auf eine umfassende Grundgesamtheit zu schließen. Entsprechend wurden in der qualitativen Forschung andere Formen der Verallgemeinerung entwickelt, auf die wir im fünften Kapitel eingehen. Wir zeigen auf, welche Möglichkeiten qualitativ Forschende haben, über
ihre Daten hinaus etwas auszusagen, was sie aussagen können und was sie dabei im
Forschungsprozess beachten müssen.

Und damit laden wir Sie ein, mutig die ersten Farbtupfer auf die Leinwand Ihrer
Studie zu setzen.


12


#### **1 Fallauswahl in der qualitativen Forschung:** **Grundlagen**

In der empirischen Forschung – egal, ob qualitativ oder quantitativ – ist es in der Regel
nicht möglich, alle interessierenden Fälle oder Einheiten in die Untersuchung einzubeziehen. Auch in der qualitativen Forschung ist es somit erforderlich, aus einer größeren Gruppe potenziell relevanter Fälle oder Einheiten eine Auswahl zu treffen, für die
dann konkret Daten erhoben werden. Diese Auswahl erfolgt aber meist mit anderen
Zielsetzungen, nach anderen Prinzipien und unter Anwendung anderer Strategien als
in der quantitativen Forschung. Dies wollen wir zunächst an einer Studie beispielhaft
verdeutlichen, bevor wir genauer auf die Grundlagen der Fallauswahl in der qualitativen Forschung eingehen.


Die Fallauswahl in der qualitativen Forschung erfolgt mit anderen Zielsetzungen, nach anderen
Prinzipien und unter Anwendung anderer Strategien als in der quantitativen Forschung.


**Untersuchungsbeispiel: Problematische Erfahrungen beim Meditieren**


Meditation wird in der Literatur teilweise als universell anwendbare Entspannungsmethode propagiert. Dabei wird nicht berücksichtigt, dass Meditation durchaus auch unangenehme Erfahrungen
mit sich bringen kann. Ziel von Jared Lindahl und Kolleg:innen (2017) war es, das Spektrum solcher potenziell problematischer Erfahrungen zu erkunden und abzubilden. Genau genommen handelt es sich um eine Mixed-Methods-Studie, wobei wir hier nur auf den qualitativen Teil eingehen.
Die Forschenden führten Interviews mit 60 Personen, die sämtlich unangenehme Erfahrungen
beim Meditieren gemacht hatten. Die Teilnehmer:innen wurden so ausgewählt, dass sie drei wichtige Traditionen von Meditation repräsentierten: Theravada, Zen und tibetische Meditation; weiterhin waren je zehn Personen aus jeder Tradition Männer und je zehn Personen Frauen. Nach den
ersten 30 Interviews prüften die Forschenden, inwieweit weitere Interviews noch neue Informationen erbrachten. Eine vergleichbare Prüfung nahmen sie nach 60 Interviews vor.
Die teilstandardisierten Interviews wurden inhaltsanalytisch ausgewertet. Auf dieser Grundlage
identifizierten die Forschenden insgesamt 59 verschiedene Formen problematischen Erlebens
beim Meditieren, die sie in sieben Gruppen unterteilten (kognitiv, wahrnehmungsbezogen, affektiv, somatisch, verhaltensbezogen, Gefühl für das eigene Selbst, sozial).


13


1 Fallauswahl in der qualitativen Forschung: Grundlagen


Diese Untersuchung verdeutlicht einige zentrale Merkmale der Fallauswahl in der qualitativen Forschung. Zunächst ging es Lindahl et al. darum, das Phänomen der problematischen Erfahrungen beim Meditieren in seiner ganzen Breite aufzuzeigen – und
nicht beispielsweise darum, die Häufigkeit bestimmter Formen problematischer Erfahrungen beim Meditieren auf die Bevölkerung zu verallgemeinern. Allerdings konnten
die Forschenden dazu nicht alle Personen befragen, die je problematische Erfahrungen
beim Meditieren gemacht haben – eine solche Grundgesamtheit wäre auch schwer einzugrenzen und zu bestimmen. Sie mussten also eine Auswahl treffen, und diese Auswahl erfolgte anhand von drei Kriterien: Erstens mussten die Teilnehmer:innen selbst
bereits problematische Meditationserfahrungen gemacht haben; sie mussten also der
Grundgesamtheit angehören. Zweitens gingen die Forschenden davon aus, dass die Art
der problematischen Erfahrungen möglicherweise mit der Form der Meditationspraxis
in Zusammenhang steht. Folglich wählten sie zu je gleichen Teilen Personen aus, die
in den drei wichtigsten kontemporären Traditionen praktizierten. Drittens vermuteten
sie, dass auch das Geschlecht der Praktizierenden mit der Art der Meditationserfahrung zusammenhängen könnte, weshalb sie außerdem zu gleichen Teilen Frauen und
Männer in die Untersuchung einbezogen. Die Auswahl der Teilnehmer:innen erfolgte
also gezielt nach den genannten Kriterien und somit absichtsvoll. Um konkret Untersuchungsteilnehmer:innen zu gewinnen, sprachen sie gezielt Personen an, von denen sie
wussten, dass sie diese Kriterien erfüllten. Außerdem wandten sie das Schneeballprinzip an, um weitere Teilnehmer:innen zu identifizieren, d. h., sie baten Personen, die
bereits an der Studie teilgenommen hatten, darum, ihnen weitere in Frage kommende
Personen zu nennen. Schließlich führten sie nach den ersten 30 einige wenige weitere
Interviews durch, mit dem Ziel zu überprüfen, inwieweit ihre Stichprobe bereits gesättigt war bzw. inwieweit weitere Interviews neue Informationen ergaben. Da weitere
Interviews noch neue Informationen beinhalteten, führten sie die Datenerhebung fort.
Die schlussendliche Zahl von 60 Interviewpartner:innen dürfte nicht zuletzt darauf
zurückgehen, dass die Forschenden gleiche Anteile von Personen aus den verschiedenen Meditationstraditionen und je gleiche Anteile von Männern und von Frauen in der
Stichprobe anstrebten.

Im Folgenden gehen wir genauer auf zentrale Grundbegriffe und -gedanken der
Fallauswahl in der qualitativen Forschung ein. Dazu gehören insbesondere eine
Begriffsbestimmung der absichtsvollen Fallauswahl, Überlegungen zur Zusammensetzung der Stichprobe, zur Vorgehensweise bei der Auswahl sowie eine Diskussion des
gerade genannten Kriteriums der Sättigung.


1.1 Grundbegriffe: Grundgesamtheit, Stichprobe, Fallauswahl


Der Begriff der _Grundgesamtheit_ (bedeutungsgleich auch: Population) bezeichnet in
der quantitativen Forschung das Gesamt aller Einheiten, für die die Untersuchungs

14


1.1 Grundbegriffe: Grundgesamtheit, Stichprobe, Fallauswahl


ergebnisse Gültigkeit haben sollen, auf die sie also verallgemeinerbar sein sollen.
Wenn beispielsweise Befragungen dazu durchgeführt werden, wen die Befragten wählen würden, wenn am kommenden Sonntag Bundestagswahl wäre, dann stellt die
Gesamtheit aller wahlberechtigen Personen in Deutschland die Grundgesamtheit dar.
Ziel ist es, von der Verteilung der Stimmen auf die Parteien in der Stichprobe auf deren
Verteilung in der Grundgesamtheit zu schließen.

Es liegt nahe, in der qualitativen Forschung eine ähnliche Terminologie zu verwenden – bezogen auf die Untersuchung von Lindahl et al. beispielsweise, sämtliche
Menschen, die Meditation praktizieren und schon einmal problematische Erfahrungen dabei gemacht haben, als Grundgesamtheit zu betrachten. In manchen qualitativen Untersuchungen ist eine solche Sichtweise durchaus gerechtfertigt: Peter Reniers
und Kolleg:innen (2022) führten beispielsweise Interviews mit fünf älteren Menschen
zu ihren Erfahrungen mit Haustieren während der Covid-Pandemie durch. Hier handelt es sich potenziell durchaus um eine Stichprobe aus einer Grundgesamtheit von
älteren Menschen, die während der Pandemie mit Haustieren zusammenlebten und
ihre Anwesenheit in dieser schwierigen Zeit als Unterstützung empfanden. Bei der Studie von Lindahl et al. ist die Situation komplexer. Denn ihnen ging es darum, das Phänomen der problematischen Erfahrungen beim Meditieren differenziert und in seiner ganzen Breite zu erfassen. Die Grundgesamtheit ist hier also genau genommen
das Phänomen der problematischen Erfahrungen; die Interviewpartner:innen stellen
lediglich die Datenquellen dar, über die die Forschenden Zugang zu den verschiedenen Facetten des Phänomens erhalten. Die sogenannte Grundgesamtheit in der qualitativen Forschung kann also auch vom Phänomen her gedacht und somit ganz anders
konzipiert sein als in der quantitativen Forschung. Man kann den Begriff aber trotzdem verwenden und er kann auch durchaus angemessen sein. Allerdings ist es wichtig,
sich darüber im Klaren zu sein, was genau damit gemeint ist. Ob man von der jeweiligen Stichprobe dann auch auf diese Grundgesamtheit verallgemeinern kann, ist noch
einmal eine andere Frage (s. u. Kap. 5).


In der qualitativen Forschung bezieht der Begriff der Grundgesamtheit sich nicht notwendig auf Fälle.

Die verschiedenen Ausprägungen eines Phänomens können ebenfalls eine Grundgesamtheit darstellen.


Der zweite zentrale Begriff, den wir oben auch wiederholt verwendet haben, ist der der
_Stichprobe_ . Unter diesem Begriff, der aus der quantitativen Forschung stammt, versteht
man diejenigen Mitglieder der Grundgesamtheit, die in die empirische Untersuchung
einbezogen und für die konkret Daten erhoben werden. Um zu entscheiden, welche
Mitglieder der Grundgesamtheit einbezogen werden sollen, stehen verschiedene Strategien zur Verfügung. In der quantitativen Forschung ist das häufig die Zufallsstichprobe, und in der qualitativen Forschung ist oft von absichtsvoller Auswahl die Rede.


15


1 Fallauswahl in der qualitativen Forschung: Grundlagen


Im Grunde handelt es sich bei der Auswahl von Personen, Institutionen, Daten aus
sozialen Netzwerken usw. in der qualitativen Forschung ebenfalls um die Auswahl einer
Stichprobe aus einer Grundgesamtheit. Allerdings ist der Begriff der Stichprobenziehung stark mit der quantitativen Forschungstradition assoziiert, so dass manche qualitativ Forschenden den Begriff der _Fallauswahl_ vorziehen. Dieser Begriff stammt aus
dem Untersuchungsdesign der Fallstudie (Yin, 2017). Unter einem Fall versteht man
dabei eine bestimmte Art von Untersuchungseinheit: komplex, holistisch und umfassend, wie etwa eine Organisation, ein Land mit einer bestimmten Regierungsform oder
ein Event (s. u. 3.2). Die Rede von der Fallauswahl im Zusammenhang mit der Fallstudie bezieht sich also auf eine ganz bestimmte Art von (komplexem) Fall. Wenn der
Begriff der Fallauswahl dagegen synonym mit _Stichprobenziehung_ verwendet wird,
ist damit die Auswahl von Fällen im Sinne von Untersuchungseinheiten gemeint, also
beispielsweise Personen für eine Interviewstudie. Wir verwenden im Folgenden die
Begriffe _Fallauswahl_ und _Stichprobenziehung_ synonym – es sei denn, es geht speziell
um die Fallauswahl im Kontext der Fallstudie. In diesem – und nur in diesem – Kontext
bezieht sich _Fallauswahl_ auf die Auswahl komplexer Fälle wie etwa Organisationen.


Die Begriffe der Stichprobenziehung und der Fallauswahl bezeichnen den Prozess der Auswahl von
Mitgliedern aus einer Grundgesamtheit, für die im Folgenden Daten erhoben werden.


Ein dritter Begriff in diesem Zusammenhang ist _Untersuchungseinheit_, manchmal in
der Literatur auch als _Beobachtungseinheit_ bezeichnet (z. B. Akremi, 2019a). Dieser
Begriff war ursprünglich in erster Linie im Zusammenhang mit der Konzeptualisierung von Fällen als komplexen Einheiten relevant. Wenn beispielsweise eine Organisation den untersuchten Fall darstellt, wird nicht die Organisation befragt, sondern es
werden Personen interviewt, die in der Organisation tätig sind. Zur Differenzierung
zwischen diesen verschiedenen Ebenen ist es sinnvoll, von den Fällen als übergeordneter Einheit zu sprechen und von den Untersuchungseinheiten als denjenigen Einheiten, für die dann tatsächlich Daten erhoben werden. Allerdings wird auch diese Unterscheidung in der Literatur nicht immer konsequent gehandhabt, und manchmal ist
von Untersuchungs- oder Beobachtungseinheiten auch außerhalb von Fallstudien die
Rede. Auch in den folgenden Abschnitten wird es uns nicht immer gelingen, terminologisch konsequent zwischen (komplexen) Fällen einerseits und einfacheren Untersuchungseinheiten andererseits zu unterscheiden.

Viertens wollen wir hier den Begriff der _Datenquelle_ einführen. Eine Datenquelle
ist diejenige Einheit, von der Daten erhoben werden. In vielen Untersuchungen sind
Untersuchungseinheit und Datenquelle identisch. In der oben erwähnten Untersuchung von Reniers et al. (2022) zum Erleben älterer Menschen mit Haustieren während der Corona-Pandemie ist dies beispielsweise der Fall: Untersuchungseinheiten


16


1.2 Formen der Stichprobenziehung


sind die älteren Menschen; zugleich sind sie auch die Datenquelle, also die Entitäten,
mit denen Interviews durchgeführt werden. Anders würde es aussehen, wenn man
eine Untersuchung zur Struktur von Träumen durchführen wollte: Untersuchungseinheit wären hier die Träume, und Datenquelle wären die Personen, die von ihren Träumen erzählen oder sie aufschreiben. Jede Datenquelle generiert hier also potenziell
mehrere Untersuchungseinheiten; die Datenquelle ist der Untersuchungseinheit sozusagen übergeordnet.


Datenquellen sind die Einheiten, für die Daten erhoben werden. Untersuchungseinheiten und
Datenquellen können, müssen aber nicht identisch sein.


Bevor man eine Untersuchung beginnt, sollte man sich überlegen, was eigentlich genau
die Grundgesamtheit ist, über die man etwas aussagen will, welches die Fälle oder
Untersuchungseinheiten darstellen und ob sie mit den Datenquellen identisch sind.


1.2 Formen der Stichprobenziehung


Wie im vorigen Abschnitt erwähnt, wird der Begriff der Stichprobenziehung häufig mit
der quantitativen Forschung und mit dem Konzept der Zufallsstichprobe assoziiert. In
der qualitativen Forschung wird aber meist eine andere Form der Auswahl angewendet, nämlich die absichtsvolle Fallauswahl bzw. Stichprobenziehung.

Die _Zufallsstichprobe_ ist darüber definiert, dass alle Mitglieder der Grundgesamtheit
dieselbe Chance haben, in die Stichprobe aufgenommen zu werden. Dies wird sichergestellt, indem erstens alle Mitglieder der Grundgesamtheit in einer sogenannten
Urliste aufgeführt sind (alle Einwohner:innen einer Gemeinde beispielsweise im Melderegister des Einwohnermeldeamts). Zweitens werden die Untersuchungseinheiten
aus dieser Liste mittels eines echten Zufallsverfahrens ausgewählt, beispielsweise mittels eines Generators von Zufallszahlen. Ausgehend von diesem Grundprinzip wurden
verschiedene, komplexere Varianten der Zufallsstichprobe entwickelt, beispielsweise
die geschichtete oder die Cluster-Stichprobe. Der große Vorteil einer Zufallsstichprobe
besteht darin, dass man – unter bestimmten Voraussetzungen (s. u. 2.5 und 5.1) –
davon ausgehen kann, dass die Stichprobe die Grundgesamtheit in relevanten Hinsichten abbildet, dass die Stichprobe also für die Grundgesamtheit als repräsentativ gelten
kann. Das ist wiederum eine Voraussetzung dafür, von den Eigenschaften der Stichprobe auf die Eigenschaften der Grundgesamtheit schließen zu können.

Eine der wichtigsten Bedingungen dafür, dass eine Zufallsstichprobe tatsächlich
für die Grundgesamtheit repräsentativ ist, ist die Stichprobengröße (Döring, 2023,
S. 299ff.; Gobo, 2007). Die optimale Stichprobengröße in der quantitativen Forschung


17


1 Fallauswahl in der qualitativen Forschung: Grundlagen


lässt sich unter Abwägen verschiedener Gesichtspunkte bestimmen. Wichtig ist dabei
vor allem, wie sicher man sein will, dass die Schätzung in der Stichprobe auch für die
Grundgesamtheit zutreffend ist (Konfidenzniveau). Wichtig ist ebenfalls die Fehlerspanne, die man bereit ist in Kauf zu nehmen (Konfidenzintervall). In der Regel liefert
eine Stichprobe umso präzisere Schätzungen, je größer sie ist – daher auch die Bedeutung, die dem Stichprobenumfang in der quantitativen Forschung zukommt.

Eine Verallgemeinerung von der Stichprobe auf die Grundgesamtheit ist ein wesentliches Ziel des Großteils der quantitativen Forschung. Deswegen gilt die Zufallsstichprobe hier meist als der Goldstandard, und andere Formen der Stichprobenziehung
werden als nicht zielführend angesehen. Dabei bleibt allerdings außer Acht, dass die
tatsächlichen Stichproben auch in der quantitativen Forschung vielfach die notwendigen Voraussetzungen nicht erfüllen, es sich also manchmal gar nicht um repräsentative Stichproben handelt. Auch wird nicht in allen Bereichen quantitativer Forschung
auf Zufallsstichproben zurückgegriffen. Die experimentelle Forschung basiert beispielsweise mehrheitlich auf anfallenden Stichproben.

In der qualitativen Forschung stehen dagegen meist andere Zielsetzungen als der
Schluss von der Stichprobe auf die Grundgesamtheit im Vordergrund, beispielsweise
die Generierung einer Theorie mittlerer Reichweite oder – wie in der o. g. Untersuchung von Lindahl et al. (2017) – die Exploration eines Phänomens in all seinen Ausprägungen. Entsprechend ist eine Zufallsauswahl hier oft nicht zielführend – auch
wenn sie möglich wäre (s. u. 5.2). Marshall (1996) verdeutlicht dies anhand des folgenden Beispiels: In der qualitativen Forschung eine Zufallsstichprobe auszuwählen
wäre etwa so sinnvoll, als wollte man eine zufällige Auswahl von Passanten um Unterstützung bei der Autoreparatur bitten – anstelle sich an eine Autowerkstatt zu wenden.
Marshall hat hier vermutlich eher die anfallende Stichprobe als die echte Zufallsstichprobe im Blick, aber das Prinzip hinter dem Beispiel hat trotzdem seine Gültigkeit:
Bei der qualitativen Sozialforschung ist nicht eine zufällige, sondern eine absichtsvolle
Stichprobenziehung indiziert. Dabei geht es darum, die Untersuchungseinheiten oder
Fälle so auszuwählen, dass sie in Bezug auf Untersuchungsziel und -gegenstand möglichst _informationshaltig_ sind. Bezogen auf das Beispiel von Marshall bedeutet dies: Es
geht darum, möglichst kompetente Automechaniker:innen zu finden.


Absichtsvolle Fallauswahl bedeutet, möglichst informationshaltige Fälle in die Untersuchung einzubeziehen. Fälle sind dann informationshaltig, wenn sie dazu beitragen, die Forschungsfrage zu
beantworten.


Was im konkreten Fall unter einer möglichst informationshaltigen Untersuchungseinheit zu verstehen ist, hängt von der jeweiligen Untersuchungsfrage ab: Automechaniker:innen sind hilfreich, wenn es um die Autoreparatur geht – aber nicht unbedingt,


18


1.2 Formen der Stichprobenziehung


wenn man sich mit Strategien für das Training von Hundewelpen vertraut machen will.
Und eine Zufallsauswahl kann unter bestimmten Voraussetzungen zwar die Grundgesamtheit repräsentieren – aber in der Stichprobe werden nicht genügend Automechaniker:innen (oder Hundetrainer:innen) enthalten sein, um eine entsprechende Forschungsfrage zu beantworten.

Folglich sind bei der absichtsvollen Fallauswahl andere Kriterien und Strategien
wichtig als bei der Zufallsauswahl in der quantitativen Forschung. Auch kommt der
Stichprobengröße bei der absichtsvollen Fallauswahl eine deutlich geringere Bedeutung zu als bei der Zufallsauswahl. Ungleich wichtiger als die Stichprobengröße sind
aber zwei zentrale Kriterien: Das ist erstens das schon genannte Kriterium der _Informa-_
_tionshaltigkeit_, also inwieweit die ausgewählten Fälle dazu beitragen, die Forschungsfrage zu beantworten. Zweites Kriterium ist das der _Angemessenheit_, also ob die erhobenen Daten auch ausreichen, um die Forschungsfrage zu beantworten (zu den Kriterien
s. Morse, 1991; Schreier, 2023, S. 211ff.).


In der qualitativen Forschung ist nicht die Anzahl der Fälle entscheidend, sondern ihre Informationshaltigkeit und Angemessenheit.


Lindahl et al. (2017) haben in ihrer Untersuchung zum problematischen Meditationserleben die Informationshaltigkeit sichergestellt, indem sie gezielt solche Personen
in ihre Untersuchung einbezogen haben, die schon einmal belastende Erfahrungen
während der Meditation gemacht haben. Um die Angemessenheit ihres Materials zu
gewährleisten, haben sie zunächst bei der Fallauswahl berücksichtigt, was alles mit der
Art problematischer Erfahrungen beim Meditieren in Zusammenhang stehen könnte;
folglich haben sie Praktizierende aus verschiedenen Meditationstraditionen sowie
Männer und Frauen zu gleichen Teilen in ihre Studie einbezogen. Die Angemessenheit des Materials steht somit in engem Zusammenhang mit der Zusammensetzung der
Stichprobe. Außerdem haben sie nach den ersten 30 einige weitere Interviews geführt,
um zu überprüfen, ob diese noch neue Informationen zur Forschungsfrage ergaben –
und da dies der Fall war, haben sie ihre Datenerhebung fortgesetzt. Zwar wird dieses
Vorgehen dem Konzept der Sättigung nur teilweise gerecht, aber sie haben Überlegungen zur Sättigung ihres Datenmaterials einbezogen (zur Sättigung s. u. 4.1.1).

Neben der Zufalls- und der absichtsvollen wollen wir hier noch auf _die anfallende_
_Stichprobe_ eingehen (auch: Ad-hoc- oder willkürliche Stichprobe bzw. Auswahl). Eine
Ad-hoc-Fallauswahl ist darüber definiert, dass solche Untersuchungseinheiten in die
Stichprobe aufgenommen werden, die gerade verfügbar sind. Angenommen, die Forschenden möchten sich ein Bild davon machen, wie die Studierenden an der Universität X das dortige Mensaessen und -angebot beurteilen. Eine anfallende Stichprobe läge
vor, wenn die Forschenden sich mittags in die Mensa aufmachen und dort beliebige 50


19


1 Fallauswahl in der qualitativen Forschung: Grundlagen


oder 100 Personen befragen würden. An diesem Beispiel wird auch gleich der Nachteil der anfallenden Stichprobe deutlich. Denn da es den Forschenden in diesem Beispiel darum geht, von der Stichprobe auf die Grundgesamtheit zu schließen, benötigen
sie eine repräsentative Stichprobe. Die Studierenden, die mittags in die Mensa gehen,
dürften aber kein repräsentatives Bild aller Studierenden abgeben. Insbesondere diejenigen Studierenden, denen das Mensaessen nicht sonderlich schmeckt, meiden dieses
Angebot vermutlich. Die anfallende Stichprobe beinhaltet daher wahrscheinlich eine
überproportional große Anzahl von Studierenden, die das Mensaessen positiv beurteilen. Die Stichprobe ist somit gegenüber der Grundgesamtheit verzerrt – und dies
ist zugleich das zentrale Problem der anfallenden Stichprobe. Dieses Problem gilt im
Übrigen auch für Varianten der anfallenden Stichprobe, die durchaus verbreitet sind,
wie beispielsweise die Quotenstichprobe in der Marktforschung oder die Online-Befragung einer großen Anzahl von Personen.

Dieser Vorbehalt gegenüber der anfallenden Stichprobe hat aber nur dann Gültigkeit, wenn die anfallende Fallauswahl nicht zum jeweiligen Untersuchungsziel passt.
Wenn das Ziel einer Untersuchung darin besteht, von der Merkmalsverteilung in der
Stichprobe auf die Verteilung in der Grundgesamtheit zu schließen, ist die anfallende Stichprobe aus den genannten Gründen nicht zielführend. Ebenso gilt, dass die
anfallende Stichprobenauswahl nicht passend ist, wenn das Untersuchungsziel darin
besteht, eine datenbasierte Theorie zu generieren; hier wäre das Theoretical Sampling die angemessene Strategie (s. u. 2.3). Es gibt aber durchaus Forschungsfragen, bei
denen auch eine anfallende Stichprobe wichtige Erkenntnisse liefern kann. Dies ist beispielsweise der Fall, wenn man davon ausgehen kann, dass alle Mitglieder der Grundgesamtheit in Bezug auf das interessierende Merkmal vergleichbar sind (s. u. 5.2).
Eine anfallende Stichprobe kann auch nützlich sein, wenn es darum geht festzustellen,
ob ein bestimmtes Phänomen in einer Grundgesamtheit überhaupt vorliegt (s. ebenfalls 5.2).

Die anfallende Stichprobe ist also nicht per se problematisch, sondern immer nur
in Relation zur jeweiligen Fragestellung und zum Untersuchungsziel. Auch lässt sich
die anfallende Stichprobenziehung durchaus mit Aspekten absichtsvoller Fallauswahl
kombinieren. Häufig werden z. B. Kriterien, die die ausgewählten Fälle erfüllen sollten, absichtsvoll festgelegt; die konkrete Fallauswahl erfolgt dann jedoch anfallend
(s. das Untersuchungsbeispiel in 2.5.2). Auch wenn sich konzeptuell klar zwischen
absichtsvoller und anfallender Fallauswahl unterscheiden lässt, sind die beiden Strategien in der Forschungspraxis vielfach verwoben. Im Übrigen lässt sich auch die Zufallsauswahl mit Elementen absichtsvoller Fallauswahl kombinieren (s. 2.5.3).


20


1.3 Das Wann und Wo absichtsvoller Fallauswahl


1.3 Das Wann und Wo absichtsvoller Fallauswahl


Quantitative Forschung verläuft linear, von der Formulierung einer Forschungsfrage
und/oder Hypothese über die Stichprobenziehung, Datenerhebung, Auswertung hin
zu den Untersuchungsergebnissen und deren Interpretation. Eine Auswahlentscheidung im Sinne der Stichprobenziehung fällt dabei nur einmal an, und zwar vor der
Datenerhebung.

In der qualitativen Forschung ist die Situation in mehreren Hinsichten eine andere.
Was den Ablauf betrifft, so kann qualitative Forschung zwar auch linear verlaufen.
Häufig werden qualitative Untersuchungen jedoch gerade nicht linear umgesetzt,
sondern zyklisch-iterativ. Das bekannteste Beispiel für ein solches iteratives Untersuchungsdesign ist die Datenbezogene Theoriebildung (Grounded-Theory-Methodologie; s. u. 3.1). Fallauswahl, Datenerhebung und –auswertung greifen hier ineinander,
so dass der Auswahlprozess sich über den gesamten Untersuchungsverlauf erstreckt.
Aber auch in Studien, denen ein anderes Untersuchungsdesign zugrunde liegt, kann
die Fallauswahl während der Durchführung mehrfach überprüft und angepasst werden (s. auch hier wieder die Untersuchung von Lindahl et al., 2017.).


In qualitativen Studien kann die Fallauswahl während der Durchführung mehrfach überprüft und
angepasst werden, je nach Design auch über den gesamten Untersuchungsverlauf.


Außerdem fallen Auswahlentscheidungen in der qualitativen Forschung nicht nur in
Bezug auf die Datenerhebung an, sondern manchmal auch in Bezug auf die Auswertung und die Ergebnisdarstellung (Akremi, 2019a; Merkens, 2010). Was die Auswertung betrifft, lassen sich drei Situationen unterscheiden, in denen eine weitere Auswahl aus dem bereits erhobenen Datenmaterial getroffen werden muss.


In der qualitativen Forschung fallen Auswahlentscheidungen nicht nur bei der Datenerhebung an,
sondern auch bei der Auswertung und der Ergebnisdarstellung.


Erstens kann es sein, dass bei der Datenerhebung mehr Material erhoben wurde als
nötig; und manchmal lassen es beschränkte Ressourcen nicht zu, das gesamte Material
in die Auswertung einzubeziehen. Das ist vor allem dann der Fall, wenn die Teilnehmer:innen bestimmte Kriterien erfüllen sollen, die Forschenden aber vor der Datenerhebung nicht feststellen können, ob diese Kriterien auch tatsächlich vorliegen.

Angenommen, Lindahl et al. (2017) hätten in ihrer Untersuchung zu problematischen Erlebnissen während der Meditation auch die bisherige Meditationserfah

21


1 Fallauswahl in der qualitativen Forschung: Grundlagen


rung als Kriterium berücksichtigt. Danach wollten sie zu etwa gleichen Teilen sowohl
Anfänger:innen mit weniger als zwei Jahren Meditationserfahrung, Menschen mit
einer regelmäßigen Meditationspraxis von zwei bis sechs Jahren; und Personen mit
einer regelmäßigen Praxis von sieben Jahren aufwärts in ihre Studie einbeziehen.
Dann hätten sie die Wahl, potenzielle Untersuchungsteilnehmer:innen entweder vorab
nach ihrer Meditationserfahrung zu fragen und solche Interessent:innen abzuweisen,
die in der Stichprobe schon hinreichend vertreten sind. Das ist natürlich eine Möglichkeit, könnte aber dazu führen, dass die betroffenen Personen sich zurückgewiesen fühlen. Oder sie könnten alle Interessent:innen zur Teilnahme einladen und sie erst während des Interviews nach der Dauer ihrer Meditationspraxis fragen. In dem Fall hätten
Lindahl et al. vermutlich einen vergleichsweise höheren Anteil von Personen mit eher
kurzer bisheriger Meditationspraxis in ihrer Stichprobe; es würde also ein Oversampling vorliegen. Dann hätten die Forschenden wieder die Wahl: Sie könnten entweder
sämtliche Daten in die Auswertung mit einbeziehen, würden sich damit aber von der
ursprünglichen Quotierung entfernen. Oder sie könnten für die weitere Analyse aus
der Stichprobe der Personen, für die sie Daten erhoben haben, nur so viele auswählen,
wie dies der Quotierung entspricht. Das würde allerdings bedeuten, dass für einige
Personen Daten erhoben, aber nicht in die Auswertung einbezogen würden. Diese Personen hätten sich auf die Untersuchung eingelassen, dafür Zeit aufgewandt und sich
geöffnet, aber ohne dass ihre Überlegungen in die Ergebnisse Eingang fänden. Diese
Vorgehensweise wäre unter ethischen Gesichtspunkten problematisch.

Zweitens kann es sein, dass nicht alles erhobene Material gleichermaßen für die
Forschungsfrage von Bedeutung ist. Dies betrifft insbesondere solches Material, das
die Forschenden schon vorfinden, das sie also nicht speziell für Untersuchungszwecke
generiert haben. Solche Daten, wie etwa Dokumente verschiedenster Art oder Daten
aus den sozialen Medien, wurden im Hinblick auf andere Zielsetzungen erstellt. Sie
setzen daher vielfach andere Schwerpunkte, so dass manchmal nur ein Teil des Materials pro Fall für die Untersuchung relevant ist. Dasselbe gilt, wenn auch in geringerem
Maße, für Daten aus Beobachtungen, Interviews oder Fokusgruppen. Vor der Auswertung kann es also erforderlich sein, zwischen mehr oder weniger informationshaltigem
Material zu unterscheiden und sich bei der weiteren Auswertung auf das informationshaltigere zu konzentrieren.

Drittens unterscheiden Forschungsdesigns und Auswertungsverfahren sich dahingehend, in welchem Umfang und wie detailliert das erhobene Material analysiert
wird. Bei der qualitativen Inhaltsanalyse wird beispielsweise alles relevante Material
einbezogen und zu einem mittleren Detailierungsgrad analysiert. Bei der GroundedTheory-Methodologie gibt es Unterschiede zwischen den verschiedenen Kodierschritten (s. u. 3.1). Das offene Kodieren ist sehr detailliert und wird daher auch nur auf
ausgewählte, besonders informationshaltige Teile des Materials angewandt. Auch bei
der Dokumentarischen Methode und manchen Formen der Diskursanalyse findet eine
sehr differenzierte Analyse statt, wobei ausgewählte Teile des Materials fokussiert wer

22


1.3 Das Wann und Wo absichtsvoller Fallauswahl


den. Man kann also auch sagen: Je detaillierter die Analyse, desto wichtiger ist es, hierfür besonders informationshaltiges Material auszuwählen. Auch in dieser Hinsicht fallen im Zusammenhang mit der Auswertung also weitere Auswahlentscheidungen an.


In den folgenden Situationen müssen Forschende auch in Bezug auf die Auswertung Auswahlentscheidungen treffen:


  - Wenn Daten für mehr Fälle erhoben wurden, als ausgewertet werden kann: Welche Fälle sollen

in die Auswertung einbezogen werden?

  - Wenn nur ein Teil des Materials relevant ist: Welche Teile des Materials pro Fall sollen ausge
wertet werden?

  - Wenn nur ein Teil des Materials im Detail analysiert werden kann: Welche Teile des relevanten

Materials sollen eher oberflächlich und welche Teile sollen im Detail ausgewertet werden?


Was für die Auswertung gilt, gilt für die Darstellung der Ergebnisse noch einmal umso
mehr: Es ist unmöglich, die Reichhaltigkeit des qualitativen Materials in der Ergebnisdarstellung in vollem Umfang abzubilden. Hier ist also aus dem Material, das für
die Auswertung berücksichtigt wurde, eine weitere Auswahl zu treffen. Und auch hier
stellt die Informationshaltigkeit das zentrale Kriterium dar: Die Auswertungsschritte,
Ergebnisse und Schlussfolgerungen werden anhand von besonders passendem, einschlägigem Material veranschaulicht. Das ist natürlich nicht so gemeint, dass hier
selektiv nur die eigenen Schlussfolgerungen gestützt werden sollen. Vielmehr geht
es darum, den Analyseprozess und die Schlussfolgerungen transparent und für die
Leser:innen nachvollziehbar zu machen. Und das bedeutet auch, mögliche alternative Interpretationen zu diskutieren und anhand des Materials zu verdeutlichen, weshalb diese alternativen Interpretationen dem Material weniger gerecht werden als die
jeweils vertretene Interpretation.


Für die Ergebnisdarstellung ist das Material so auszuwählen, dass die eigenen Schlussfolgerungen
für die Leser:innen nachvollziehbar werden.


Neben dem Wann von Auswahlentscheidungen stellt sich in der qualitativen Forschung in bestimmten Situationen auch die Frage des Wo. Wir haben schon darauf
hingewiesen (s. o. 1.2), dass Fälle, Untersuchungseinheiten und Datenquellen nicht
immer identisch sind. Wann immer es hier Unterschiede gibt – wenn also ein Fall beispielsweise mehrere Untersuchungseinheiten umfasst –, sind auch für alle diese Einheiten Auswahlentscheidungen zu treffen. Die Entscheidungen werden auf mehre

23


1 Fallauswahl in der qualitativen Forschung: Grundlagen


ren Ebenen getroffen, weshalb man hier auch von einem _Mehrebenendesign_ spricht.
In einer Fallstudie sind beispielsweise sowohl die Fälle auszuwählen (also bestimmte
Organisationen und Kulturen) als auch die Personen, mit denen Interviews geführt
werden sowie die Settings, in denen beobachtet werden soll. Die konkrete Auswahlstrategie kann dabei auf jeder Ebene eine andere sein: Auf der Ebene der Fälle könnte
etwa eine gezielte Auswahl miteinander kontrastierender, extremer Fälle erfolgen
(s. u. 2.4), während Personen für Interviews innerhalb jedes Falls nach dem Prinzip
des Maximum-Variation-Sampling ausgewählt werden (s. u. 2.3). Andere Kombinationen von Auswahlstrategien sind natürlich ebenfalls möglich.


Bei Mehrebenendesigns müssen auf jeder Ebene Fälle ausgewählt werden.


Anders als in der quantitativen Forschung stellt die Fallauswahl in der qualitativen Forschung somit nicht eine einmalige Entscheidung dar. Vielmehr beinhaltet sie wiederholte Entscheidungen, die im Forschungsprozess weiter überprüft und angepasst werden können.


1.4 Gesichtspunkte bei der qualitativen Fallauswahl


Bei den Entscheidungen im Prozess der Fallauswahl, die wir im letzten Abschnitt
beschrieben haben, sind mehrere Gesichtspunkte zu berücksichtigen. Die Literatur
zu diesem Thema wirkt schnell verwirrend. So unterscheidet Patton in der neuesten
Ausgabe seines Lehrbuchs zur qualitativen Forschung beispielsweise mehr als 40 verschiedene Formen qualitativer Fallauswahl, wie etwa die kriterienbasierte Fallauswahl, heterogene Stichproben, realistisches Sampling oder das Schneeballverfahren
(2015). Eine solche Auflistung ist verwirrend, weil dabei jeweils auf ganz unterschiedliche Gesichtspunkte bei Entscheidungen zur Fallauswahl Bezug genommen wird. Eine
Forscherin kann beispielsweise ein realistisches Vorgehen wählen, um Kriterien für die
Fallauswahl festzulegen. Damit zielt sie eine heterogene Stichprobe an. Um konkret
Personen für ihre Untersuchung zu gewinnen, bittet sie einschlägige Personen, ihr
andere potenzielle Teilnehmer:innen zu nennen; sie verwendet hier also ein Schneeballverfahren.

Das realistische Vorgehen bezieht sich darauf, zu welchem Zeitpunkt im Untersuchungsverlauf Kriterien für die Fallauswahl festgelegt werden. Mit der resultierenden
heterogenen Stichprobe ist die Zusammensetzung der Stichprobe thematisch, und
mit dem Schneeballverfahren ist die Vorgehensweise bei der Gewinnung von Teilnehmer:innen benannt. Diese drei Gesichtspunkte – Zeitpunkt der Kriterienfestlegung,
Zusammensetzung der Stichprobe und Vorgehensweise bei der Gewinnung von Teil

24


1.4 Gesichtspunkte bei der qualitativen Fallauswahl


nehmer:innen – sind bei jeder Form der Fallauswahl relevant, und idealerweise sollten
Forschende ihr Vorgehen bei der Fallauswahl auch im Hinblick auf alle drei Aspekte
beschreiben (im Überblick Schreier, 2020; Schreier, 2023; S. 211ff.). Wir gehen im
Folgenden auf die drei Gesichtspunkte genauer ein und befassen uns in diesem Zusammenhang auch mit dem Kriterienbegriff, der für die absichtsvolle Fallauswahl von zentraler Bedeutung ist.

Wie oben genauer beschrieben, zielt absichtsvolle Fallauswahl immer darauf ab,
möglichst informationshaltige Fälle in die Stichprobe einzubeziehen (1.1). Absichtsvolle Fallauswahl ist somit immer an Kriterien orientiert – eben jenen Kriterien, an
denen sich die Informationshaltigkeit eines Falls oder einer Untersuchungseinheit
bemisst. Mit dem ersten Gesichtspunkt ist die Frage thematisch, zu welchem _Zeitpunkt_
im Untersuchungsverlauf diese Kriterien festgelegt werden. In der oben dargestellten Untersuchung zu problematischen Meditationserfahrungen (Lindahl et al., 2017)
erfolgte die Kriterienfestlegung konzeptgesteuert; das heißt, die Forschenden haben
bereits vor Untersuchungsbeginn festgelegt, dass sie Personen aus drei Meditationstraditionen sowie Männer und Frauen zu gleichen Anteilen in die Stichprobe einbeziehen
wollten. Ein solches konzeptgesteuertes Vorgehen wird manchmal auch als _Top-Down_
oder _deduktiv_ bezeichnet. Wir verwenden die drei Begriffe (konzeptgesteuert, TopDown, deduktiv) im Folgenden synonym. Alternativ kann die Kriterienfestlegung auch
datengesteuert erfolgen. Dabei werden die relevanten Kriterien sukzessive im Untersuchungsverlauf herausgearbeitet, und die Fallauswahl wird entsprechend modifiziert und angepasst. Dieses Vorgehen wird auch _Bottom-Up_ oder _induktiv_ genannt,
und diese drei Begriffe verwenden wir ebenfalls synonym. Das klassische Beispiel für
eine solche datengesteuerte Vorgehensweise ist das Theoretical Sampling im Rahmen
der Grounded-Theory-Methodologie (für Beispiele s. u. 2.3). Schließlich finden sich
in der Praxis vielfach auch Mischformen einer daten- und konzeptgesteuerten Vorgehensweise: So haben die Forschenden oft schon Vorwissen über ihren Gegenstand und
legen entsprechende Kriterien konzeptgesteuert fest. Im Untersuchungsverlauf werden dann meist weitere Kriterien sichtbar, und es ist gerade die Stärke qualitativer Forschung, solche Erkenntnisse im Untersuchungsverlauf aufzugreifen und das weitere
Vorgehen entsprechend anzupassen.


Die Festlegung von Kriterien für die Informationshaltigkeit der Fälle kann in der qualitativen Forschung entweder konzeptgesteuert vor Untersuchungsbeginn oder datengesteuert im Untersuchungsverlauf erfolgen. Auch Mischformen sind möglich.


Bevor wir zum zweiten Gesichtspunkt kommen, zunächst noch einige Überlegungen
zu _Kriterien_ und dem Kriterienbegriff. Unter Kriterien verstehen wir solche Merkmale
der Fälle oder Untersuchungseinheiten, die mit dem interessierenden Phänomen in


25


1 Fallauswahl in der qualitativen Forschung: Grundlagen


Zusammenhang stehen. Lindahl et al. (2017) gingen beispielsweise davon aus, dass es
zwischen der buddhistischen Meditationstradition und der Art von Problemen bei der
Meditation einen Zusammenhang gibt. In der qualitativen Forschung sind bei der Fallauswahl vor allem solche Kriterien von Interesse, die in einem direkten, analytischen
Zusammenhang mit dem interessierenden Phänomen stehen, die also unter theoretischen Gesichtspunkten von Bedeutung sind. Es handelt sich nicht nur um eine oberflächliche Korrelation, sondern um einen Sinnzusammenhang.

In der Vipassana-Tradition geht es u. a. darum, die eigenen Empfindungen, Gedanken und Gefühle zu beobachten. Das kann dazu führen, dass Meditierende auch nach
der Meditationspraxis quasi neben sich stehen. Solche Dissoziationserlebnisse könnten
somit bei der Vipassana-Meditation eher auftreten als bei den anderen beiden Meditationstraditionen. Das wäre ein Beispiel für einen Sinnzusammenhang zwischen der
Meditationsform und der Art der Probleme.

Ebenso wäre denkbar, dass die Autor:innen den Wohnort (Stadt / Land) als Kriterium bei der Fallauswahl berücksichtigen. Angenommen, es gibt in der Tat einen solchen Zusammenhang derart, dass Menschen auf dem Land mehr Probleme beim Meditieren erleben als solche auf dem Land. Dabei würde es sich jedoch nicht um einen
Sinnzusammenhang handeln, sondern nur um eine oberflächliche Korrelation. Denn
der Wohnort als solcher beeinflusst das Meditationserleben nicht. Wer auf dem Land
wohnt, hat aber möglicherweise schlechter Zugang zu Präsenzveranstaltungen und
lernt Meditation eher in Online-Veranstaltungen. Online haben die Meditationslehrer:innen aber weniger Überblick darüber, wie es den einzelnen Teilnehmer:innen
geht. Und es besteht auch nicht die Möglichkeit, nach der Veranstaltung noch informell ins Gespräch zu kommen. Menschen in Online-Veranstaltungen werden daher in
ihrem Meditationserleben vielleicht schlechter betreut, und dadurch kommt es vielleicht öfter zu Problemen. So kann es sein, dass tatsächlich ein Zusammenhang zwischen dem Wohnort und problematischem Erleben bei der Meditation besteht. Bei
diesem Zusammenhang handelt es sich aber nur um eine oberflächliche Korrelation.
Tatsächlich ist der Zusammenhang auf das Ausmaß der Betreuung während der Meditation zurückzuführen – dies ist der dahinter liegende Sinnzusammenhang. Der Wohnort stellt lediglich einen sogenannten Proxy für das Ausmaß der Betreuung dar, eine
Art Stellvertreter.

Konzeptuell bedeutsame Kriterien (wie die Meditationstradition oder das Ausmaß
der Betreuung) bezeichnen wir hier mit Sandelowski (1995) auch als _analytische Kri-_
_terien_ . Analytische Kriterien sind in der Regel nicht von außen feststellbar, ohne sich
bereits genauer mit dem Fall befasst zu haben. Bei dem Beispiel der Meditationstradition ist dies gerade noch möglich, wenn man etwa Teilnehmer:innen gezielt über
Meditationszentren anspricht, die jeweils in einer bestimmten Tradition verankert
sind. Einstellungen, Lebenserfahrungen usw. sind dagegen häufig nur im Untersuchungsverlauf oder mittels Voruntersuchung feststellbar.


26


1.4 Gesichtspunkte bei der qualitativen Fallauswahl


Von analytischen Kriterien sind _soziodemographische Kriterien_ wie der Wohnort
abzugrenzen. Diese finden vielfach in der quantitativen Forschung Anwendung, etwa
wenn eine Stichprobe nach soziodemografischen Faktoren wie Alter, Geschlecht, Bildungsstand etc. geschichtet wird. Die Auswahl soziodemografischer Kriterien basiert
ebenfalls auf der Annahme, dass sie – als Stellvertreter für ein analytisches Kriterium –
in einem Zusammenhang mit dem interessierenden Phänomen stehen. Es handelt sich
aber meist nicht um einen direkten, sondern um einen indirekten Zusammenhang: Das
soziodemografische Kriterium wird als Stellvertreter für ein dahinter liegendes analytisches Kriterium verwendet. In der Wahlforschung weiß man beispielsweise, dass
Menschen mit akademischem Abschluss in Großstädten häufiger Die Grünen wählen;
die Kombination von Bildungsstand und Wohnort kann also beispielsweise als Indikator für eine ökologische, umweltbewusste Einstellung dienen. Auch in der qualitativen Forschung finden soziodemografische Faktoren durchaus als Kriterien Verwendung; so haben Lindahl et al. (2017) als zweites Kriterium für ihre Fallauswahl das
Geschlecht der Teilnehmer:innen einbezogen.

Der Vorteil der Verwendung soziodemografischer Kriterien besteht darin, dass ihre
Ausprägung von außen beobachtbar ist. Damit kann man schon vor Untersuchungsbeginn oder durch einfache Befragung feststellen, in welche Gruppe die Untersuchungseinheiten fallen (z. B. als Wohnort Stadt oder Land, Bildungsstand usw.). Das macht sie
gerade für die quantitative Forschung interessant, wo eine Kriterienfestlegung grundsätzlich vor Untersuchungsbeginn erfolgt – oder auch für die qualitative Forschung,
wenn die Fallauswahl konzeptgesteuert stattfinden soll. Ihr Nachteil besteht allerdings
darin, dass sie immer nur einen ungefähren Indikator für analytische Kriterien darstellen. So gibt es durchaus Menschen mit akademischem Abschluss, die in Großstädten leben, Parteien des rechten politischen Spektrums wählen und sich stärker von
Migration als von Klimaveränderungen bedroht fühlen. Dennoch können soziodemografische Kriterien auch in qualitativen Untersuchungen einen hilfreichen Ausgangspunkt darstellen, der im Untersuchungsverlauf durch analytische Kriterien ergänzt
wird. Wenn man sich in qualitativen Studien jedoch ausschließlich auf konzeptgesteuert vor Untersuchungsbeginn festgelegte soziodemografische Kriterien bei der Fallauswahl beschränkt und diese im Untersuchungsverlauf auch nicht weiter hinterfragt und
anpasst, dann läuft man Gefahr, dass die Ergebnisse konzeptuell wenig ergiebig sind
und an der Oberfläche verbleiben.


Die Fallauswahl in der qualitativen Forschung wird in erster Linie von analytischen Kriterien geleitet, die in einem Sinnzusammenhang mit dem interessierenden Phänomen stehen.


Wenn im Zusammenhang mit absichtsvoller Fallauswahl von Kriterien die Rede ist,
dann werden dabei oft auch Merkmale der Grundgesamtheit genannt. In der Untersu

27


1 Fallauswahl in der qualitativen Forschung: Grundlagen


chung von Lindahl et al. (2017) wäre das beispielsweise der Fall, wenn die Autor:innen
geschrieben hätten (was sie nicht getan haben), dass Untersuchungsteilnehmer:innen
auch das Kriterium problematischer Meditationserfahrungen erfüllen mussten, um in
die Studie aufgenommen zu werden. Problematische Meditationserfahrungen sind
aber kein Kriterium im hier gemeinten Sinn, sondern sie sind eben das Phänomen,
das von Interesse ist und in seinen verschiedenen Ausprägungen untersucht werden
soll. Sie sind sozusagen das definierende Merkmal der Grundgesamtheit. Mit (analytischen) Kriterien sind hier vielmehr solche Merkmale gemeint, die mit diesem Phänomen in einem sinnhaften Zusammenhang stehen, und solche analytischen Kriterien
sind gemeint, wenn im Folgenden von kriterienorientierter Fallauswahl die Rede ist.

Der zweite Gesichtspunkt qualitativer Fallauswahl bezieht sich auf die _Zusammen-_
_setzung_ der Stichprobe. Dabei sind homogene und heterogene Stichproben zu unterscheiden. Von _homogenen Stichproben_ spricht man, wenn die Fälle innerhalb der Stichprobe einander ähnlich sind. Bei _heterogenen Stichproben_ sind die Fälle innerhalb der
Stichprobe untereinander verschieden. Was auf den ersten Blick wie eine einfache
Unterscheidung klingt, ist in der Praxis oft deutlich komplexer. Zunächst ist festzuhalten, dass Homogenität und Heterogenität immer nur relativ in Bezug auf einzelne
Kriterien zu sehen sind. So mag eine Stichprobe von Meditierenden in der Tradition
des Zen-Buddhismus im Hinblick auf das Kriterium der Meditationstradition homogen
sein, ist aber vielleicht heterogen im Hinblick auf Geschlecht, Meditationserfahrung
oder traumatische Lebensereignisse. Hinzu kommt, dass heterogene Stichproben sich
vielfach in homogene Untergruppen unterteilen lassen. So ist die Stichprobe von Lindahl et al. (2017) insgesamt gesehen heterogen im Hinblick auf Meditationstradition
und Geschlecht der Teilnehmer:innen. Zugleich ist die Untergruppe von Frauen in der
Tradition des Zen-Buddhismus in Bezug auf die entsprechenden zwei Kriterien in sich
homogen, ebenso die Gruppe der Männer in der Tradition des Tibetischen Buddhismus. Die Rede von homogenen und heterogenen Stichproben ist somit verkürzt.


In Bezug auf die Zusammensetzung der Stichprobe ist zwischen homogenen Stichproben mit einander ähnlichen Fällen und heterogenen Stichproben mit unterschiedlichen Fällen zu unterscheiden. Homogenität und Heterogenität sind aber immer nur relativ zu einem Kriterium zu sehen.


Der dritte Gesichtspunkt qualitativer Fallauswahl betrifft die _Vorgehensweise_, um konkret zu denjenigen Fällen oder Untersuchungseinheiten zu gelangen, für die Daten
erhoben werden. Eine solche Auswahl ist immer erforderlich, wenn die Grundgesamtheit umfangreicher ist als die Anzahl der Einheiten, die in der Untersuchung berücksichtigt werden können. Onwuegbuzie und Leech (2007) sprechen hier auch von _Sam-_
_pling Schemes_ . Wir haben weiter oben in diesem Kapitel drei grundlegende Arten der
Stichprobenziehung oder Fallauswahl beschrieben: die Zufallsauswahl, die absichts

28


1.5 Wie viele Fälle sind genug


volle Fallauswahl und die anfallende Stichprobenziehung. Die Zufallsstichprobe und
die anfallende Stichprobenziehung stellen Beispiele für solche Sampling Schemes dar;
es wird jeweils beschrieben, wie konkret bei der Auswahl vorzugehen ist. Die absichtsvolle Fallauswahl bildet dagegen eher einen Oberbegriff, mit dem noch nichts Genaues
über die Vorgehensweise ausgesagt wird. In der Tat ist die absichtsvolle Fallauswahl
hier offen für verschiedene Verfahren: Eine Auswahl mittels Schnellballverfahren ist
ebenso möglich wie eine anfallende Fallauswahl oder sogar ein Zufallsverfahren.


Mit der Entscheidung für eine absichtsvolle Fallauswahl ist noch nichts über die konkrete Vorgehensweise bei der Stichprobenziehung gesagt. Sie kann mit unterschiedlichen Vorgehensweisen
kombiniert werden.


Manche Autor:innen (z. B. Meyer & Mayrhofer, 2022) weisen darauf hin, dass zusätzlich zu den hier genannten Gesichtspunkten absichtsvoller Fallauswahl auch die _Zielset-_
_zung_ der Studie von wesentlicher Bedeutung ist. So macht es für die Fallauswahl einen
Unterschied, ob beispielsweise ein Phänomen in all seinen Ausprägungen erfasst, eine
Evaluation durchgeführt oder eine Theorie entwickelt werden soll. Wir behandeln die
Zielsetzung hier jedoch nicht als separaten Gesichtspunkt, sondern fassen sie unter die
verschiedenen Untersuchungsdesigns qualitativer Forschung und die mit ihnen jeweils
verbundenen Überlegungen zur Fallauswahl (s. u. Kap. 2).


1.5 Wie viele Fälle sind genug?


Kaum eine Frage haben wir in der Beratung bei Qualifikationsarbeiten in der qualitativen Forschung so häufig gehört wie diese: Wie viele Fälle, wie viele Interviews,
wie viele Facebook-Posts muss ich in meine Studie einbeziehen? Die Antwort auf diese
Frage lautet, wie so oft in der (qualitativen) Forschung: Es kommt darauf an.

Wie wir oben bereits ausgeführt haben, ist die Stichprobengröße in der qualitativen
Forschung nicht von zentraler Bedeutung (s. o. 1.1). Wichtiger ist, dass die ausgewählten Fälle geeignet sind, die Forschungsfrage zu beantworten (Informationshaltigkeit)
und dass hinreichend Datenmaterial zur Verfügung steht, um die Forschungsfrage zu
beantworten (Angemessenheit). Bei der Angemessenheit geht es nur zum Teil um die
Anzahl der Fälle. Wichtiger ist, ob die vorhandenen Daten ausreichen, um auch alle
Aspekte der Forschungsfrage und des interessierenden Phänomens abzudecken. Dabei
ist neben der Anzahl der Fälle auch die Zusammensetzung der Stichprobe von Bedeutung, also die Frage, wie die Fälle sich zueinander verhalten. Soweit die Anzahl der
Fälle dabei eine Rolle spielt, ist nie die absolute Zahl als solche von Bedeutung, sondern stets die Anzahl der Fälle in Relation zur Forschungsfrage.


29


1 Fallauswahl in der qualitativen Forschung: Grundlagen


In der qualitativen Forschung sind Informationshaltigkeit, Angemessenheit und Zusammensetzung
der Stichprobe wichtiger als die Anzahl der Fälle.


Weiterhin muss man im Zusammenhang mit der Anzahl der Fälle immer auch die
Frage der _Tiefe_ versus _Breite_ des Datenmaterials berücksichtigen. In der quantitativen
Survey-Forschung werden beispielweise viele Teilnehmer:innen einbezogen; diese Art
der Forschung weist also eine hohe Breite auf. Zugleich werden diese vielen Fälle aber
in der Regel nicht differenziert in der Tiefe untersucht, und es interessiert meist die
Aggregierung über die Fälle hinweg. In der prototypischen qualitativen Forschung verhält es sich genau umgekehrt: Es werden nur wenige Fälle einbezogen (geringe Breite),
diese werden aber in ihrer Ganzheit und Komplexität analysiert (große Tiefe). Diese
Relation sollte man bei der Planung aller (qualitativen) Untersuchungen beachten und
abwägen: Je mehr Fälle man einbezieht, desto größer die Breite und desto geringer
die Tiefe – und umgekehrt. Es kommt also immer darauf an, welche Zielsetzungen mit
einer Studie verbunden sind. Wenn man differenziert die Prozesse und Mechanismen
erkunden möchte, wie ein demokratisches sich zu einem quasi-demokratischen und
schließlich zu einem autoritären Regime verändert, dann ist es vermutlich sinnvoll,
dieser Fragestellung an Hand von ein oder zwei einschlägigen Regimes nachzugehen.
Wenn man dagegen wie Lindahl et al. (2017) wissen möchte, welche Arten von problematischen Erfahrungen Menschen beim Meditieren machen, dann bietet es sich an,
eine größere Anzahl von Fällen einzubeziehen (hier: N=60), die dann allerdings primär im Hinblick auf diese Probleme und die damit verbundenen Coping-Strategien hin
untersucht werden (und damit in vergleichsweise geringerer Tiefe).


Breite und Tiefe stehen in einem inversen Verhältnis zueinander. Je mehr Fälle man in die Stichprobe aufnimmt, desto oberflächlicher bleibt die Analyse – und umgekehrt.


Woher weiß man nun aber, wie viele Fälle in etwa man in eine konkrete Studie einbeziehen sollte? In diesem Zusammenhang stößt man immer wieder auf den Begriff der
_Sättigung_, der teilweise sogar als Goldstandard für die Bestimmung der Fallanzahl in
der qualitativen Forschung beschrieben wird (Guest et al., 2006). Wir vertreten hier
die Position, dass die Sättigung zwar in der Tat ein wichtiges Kriterium zur Bestimmung der Fallanzahl darstellen kann, aber nicht darstellen muss. Seinen Ursprung hat
das Konzept in der Grounded-Theory-Methodologie (s. u. 3.1), wo es eng mit der Vorgehensweise des Theoretical Sampling verbunden ist. Sättigung wird dabei als die Sättigung einer Theorie verstanden bzw. der Konzepte innerhalb der Theorie und deren
Beziehung untereinander. In der Folge wurde der Begriff jedoch auch in anderen Kon

30


1.5 Wie viele Fälle sind genug


texten und teilweise anderen Bedeutungen verwendet. Saunders et al. (2018) unterscheiden beispielsweise vier verschiedene Modellierungen von Sättigung. All diesen
Modellen ist jedoch eines gemeinsam: Sättigung ist grundsätzlich mit einer induktiviterativen Vorgehensweise verbunden, und es fungiert als eine Art Abbruchkriterium.
Wenn eine Theorie hinreichend gesättigt ist, erübrigt es sich, weitere Daten zu erheben. Sättigung als Kriterium für die Bestimmung der Fallanzahl macht also nur Sinn,
wenn die Stichprobe sukzessive im Verlauf der Untersuchung, parallel zur Datenerhebung und -analyse erstellt wird. Wenn ein konzeptgesteuertes Verfahren der Fallauswahl zur Anwendung kommt, ist das Kriterium der Sättigung dagegen eher nicht zur
Bestimmung der Fallanzahl geeignet.

Außerdem ist bei der Anwendung des Kriteriums zu berücksichtigen, dass es in
erster Linie für Studien mit Interviews oder Fokusgruppen ausgearbeitet wurde. Für
Untersuchungen in der Tradition der Phänomenologie, narrativen Forschung, Fallstudie oder Konversationsanalyse – um nur einige Beispiele zu nennen – ist es weniger gut
anwendbar (O’Reilly & Parker, 2012). Weil Vorschläge zur Umsetzung des Kriteriums
sich mehrheitlich auf Interviewstudien konzentrieren, beschäftigen wir uns mit der
Sättigung auch erst im Zusammenhang mit der Stichprobenziehung beim Interview
genauer (s. u. 4.1). Auf die Theoretische Sättigung im Kontext der GTM gehen wir bei
der Darstellung dieses Ansatzes differenzierter ein (s. u. 3.1). Im Folgenden befassen
wir uns genauer mit solchen Kriterien zur Bestimmung der Fallanzahl, die auch bei
konzeptgesteuerten Strategien der Fallauswahl geeignet sind (Sim et al., 2018): Faustregeln und konzeptuelle Überlegungen.


Sättigung eignet sich vor allem in Interviewstudien als Kriterium für die Bestimmung der Fallanzahl, in denen die Fallauswahl induktiv im Untersuchungsverlauf erfolgt.
Bei Untersuchungen mit konzeptgesteuerter Fallauswahl können Faustregeln und konzeptuelle
Überlegungen Anhaltspunkte für die Bestimmung der Fallanzahl bieten.


_Faustregeln_ orientieren sich meist daran, welche Fallzahlen in welchen qualitativen
Forschungstraditionen üblich sind. Die Vorschläge weichen allerdings erheblich voneinander ab. Smith, Flowers und Larkin (2022) sehen beispielsweise drei bis zehn Personen als angemessene Fallzahl für eine phänomenologische Studie an, während Guettermann (2015) auf empirischer Grundlage für die Erziehungswissenschaften eine
mittlere Fallanzahl von 15 und für die Gesundheitswissenschaften eine mittlere Fallanzahl von 25 beschreibt (für weitere Beispiele und andere Forschungstraditionen vgl.
Sim et al., 2018). Die Anhaltspunkte durch solche Faustregeln sind also eher vage, vor
allem, wenn man die Vorschläge verschiedener Autor:innen vergleicht. Aber dennoch
sind es Anhaltspunkte für das, was innerhalb eines Fachs oder einer Forschungstradition akzeptabel ist. Und es kann gerade im Kontext von Qualifikationsarbeiten hilf

31


1 Fallauswahl in der qualitativen Forschung: Grundlagen


reich sein, wenn Forschende darauf verweisen können, dass andere die Frage der Fallanzahl ähnlich gehandhabt haben.

Dem zweiten, konzeptuellen Ansatz zur Bestimmung der Fallanzahl liegt die
Annahme zugrunde, dass das Ziel qualitativer Forschung darin besteht, ein interessierendes Phänomen in seinen verschiedenen Ausprägungen zu beschreiben und zu
verstehen (oder eine entsprechende Theorie zu erstellen). Innerhalb dieses zweiten
Ansatzes werden Faktoren benannt, die vermutlich einen Einfluss darauf haben, wie
viele Fälle erforderlich sind, um dieses Ziel zu erreichen. Malterud et al. (2016) schlagen in diesem Zusammenhang in Anlehnung an Morse (2015) das Konzept der _Infor-_
_mation Power_ vor, also eine Art Effektstärke für Informationshaltigkeit: Je höher die
Informationshaltigkeit, desto geringer die erforderliche Fallanzahl. Sie gehen davon
aus, dass Information Power von den folgenden Faktoren beeinflusst wird: dem Untersuchungsziel, der Spezifizität der Stichprobe, dem theoretischen Hintergrund der Studie, der Qualität der Datenerhebung (wobei Malterud et al. sich speziell auf das Interview beziehen) sowie die Vorgehensweise bei der Auswertung (Einzelfallbezug oder
Fallvergleich). Eine höhere Fallanzahl ist erforderlich, wenn die Fragestellung und
das Untersuchungsziel eher breit als eng gefasst sind, wenn die Fälle in der Stichprobe
eher weniger über einschlägiges Wissen verfügen, wenn die erhobenen Daten nicht
von hoher Qualität sind und wenn mittels Fallvergleich ausgewertet wird. Komplementär sind weniger Fälle erforderlich, wenn die Fragestellung sehr spezifisch ist, wenn die
Teilnehmer:innen über einschlägiges Wissen verfügen, wenn die Datenqualität hoch
ist und wenn einzelfallorientiert ausgewertet werden soll. Darüber hinaus sind die
Anforderungen des jeweiligen Ansatzes zu berücksichtigen.

Weitere Einflussfaktoren werden von Ritchie et al. (2014) benannt. Sie weisen darauf hin, dass die Heterogenität der Grundgesamtheit im Gegenstandsbereich einen
wichtigen Faktor für die Bestimmung der geeigneten Fallanzahl darstellt. Je heterogener eine Grundgesamtheit, desto wahrscheinlicher ist es, dass diese Heterogenität durch eine Vielzahl an Faktoren bedingt wird. Je nach Fragestellung sind dann
meist auch mehrere solcher Faktoren und deren Ausprägungen bei der Fallauswahl zu
berücksichtigen. Schließlich spielen auch ganz praktische Gegebenheiten eine Rolle
dabei, wie viele Fälle in einer Untersuchung berücksichtigt werden können, wie beispielsweise die finanziellen und die zeitlichen Ressourcen oder auch die Zugänglichkeit der Fälle und des Settings.

Auch solche konzeptuellen Überlegungen können wichtige Anhaltspunkte für die
Bestimmung der Fallanzahl an die Hand geben. Aufgrund der Offenheit qualitativer
Forschung muss man allerdings davon ausgehen, dass solche Überlegungen immer
nur vorläufig sind und im Verlauf der Untersuchung revidiert werden können. Wenn
sich während der Untersuchung beispielsweise herausstellt, dass noch weitere als
die ursprünglich berücksichtigten Faktoren mit dem interessierenden Phänomen in
Zusammenhang stehen, dann sollten diese ebenfalls in die Fallauswahl einbezogen
werden. Um dieser Offenheit Rechnung zu tragen, schlagen manche Autor:innen auch


32


Weiterführende Literatur


vor, zunächst eine _minimale Fallanzahl_ anzugeben, mit dem Vorbehalt, dass diese ggf.
noch erweitert wird. Das ist vor allem in Situationen sinnvoll, in denen eine Angabe
der geplanten Fallanzahl erforderlich ist, wie etwa in den Vorüberlegungen zu einer
Qualifikationsarbeit oder bei der Stellung eines Antrags auf Forschungsförderung.


Wenn eine Angabe der Fallanzahl erforderlich ist, kann man eine vorläufige minimale Fallanzahl
nennen – mit dem Hinweis, dass diese im Untersuchungsverlauf noch angepasst wird.


Weiterführende Literatur


Akremi, Leila (2019a). Stichprobenziehung in der qualitativen Sozialforschung. In

Nina Baur, & Jörg Blasius (Hrsg.), _Handbuch Methoden in der empirischen Sozialfor-_
_schung_ (2. Aufl., Bd. 1, S. 313–332). SpringerVS.
Meyer, Michael, & Mayrhofer, Wolfgang (2022). Selecting a sample. In Uwe Flick

(Hrsg.), _The Sage Handbook of qualitative research design_ (S. 273–289). Sage.
Ritchie, Jane et al. (2014). Designing and selecting samples. In Jane Ritchie, Jane

Lewis, Carol McNaughton Nicholls, & Rachel Ormston (Hrsg.), _Qualitative research_
_practice_ (2. Aufl., S. 111–146). Sage.
Sandelowski, Margarete (1995). Sample size in qualitative research. _Research in Nur-_

_sing & Health_, _18_ [(2), 179–183. https://doi.org/10.1002/nur.4770180211](https://doi.org/10.1002/nur.4770180211)
Schreier, Margrit (2020). Fallauswahl. In Günter Mey, & Katja Mruck (Hrsg.), _Hand-_

_buch Qualitative Forschung in der Psychologie_ (2. Aufl., Bd. 2, S. 19–40). Springer VS.


33


#### **2 Strategien absichtsvoller Fallauswahl**

Nachdem wir im ersten Kapitel Grundbegriffe dargestellt haben, beschreiben wir nun
verschiedene Strategien, wie eine absichtsvolle Fallauswahl konkret durchgeführt
werden kann. Dabei konzentrieren wir uns auf solche Strategien, die in der qualitativen Forschung besonders häufig zur Anwendung kommen, nämlich die kriterienorientierte Fallauswahl, das Maximum-Variation-Sampling, das Theoretical Sampling und
die gezielte Auswahl bestimmter Arten von Fällen (etwa typische oder abweichende
Fälle). Abschließend gehen wir auf konkrete Vorgehensweisen zur Kontaktierung von
Personen ein, die nach Anwendung einer dieser Strategien für eine Teilnahme in Frage
kommen: das Schneeballverfahren, die Ad-hoc-Auswahl sowie die Zufallsauswahl.


2.1 Kriterienorientierte Fallauswahl


Bei der kriterienorientierten Fallauswahl werden solche Untersuchungseinheiten in
die Studie aufgenommen, die bestimmte vordefinierte Kriterien erfüllen, die sich aus
der Forschungsfrage bzw. dem Untersuchungsgegenstand herleiten. Die Kriterien werden in der Regel vor Untersuchungsbeginn aufgrund von Vorwissen festgelegt, können
aber im Untersuchungsverlauf noch erweitert werden.


**Untersuchungsbeispiel: Mitgefühls-Meditation und Empathie bei Psychotherapeut:innen**


In einer ganzen Reihe von Studien konnte gezeigt werden, dass Mitgefühlsmeditation sich positiv
auf die psychische Gesundheit auswirkt und auch die Arbeit von Psychotherapeut:innen bereichern
kann. Dabei wurde aber bisher kaum zwischen der Wirkung von Mitgefühlsmeditation im Besonderen und Achtsamkeitsmeditation allgemein unterschieden. Marc Bibeau, Frédérick Dionne, Anaïs
Riera and Jeannette Leblanc (2020) gingen in ihrer Studie der Frage nach, wie Psychotherapeut:innen, die bereits regelmäßig Achtsamkeitsmeditation betreiben, einen Kurs ­speziell in Mitgefühlsmeditation erleben und wie diese Erfahrung sich in ihrer therapeutischen Arbeit niederschlägt.
Zur Exploration dieser Fragestellung führten sie eine phänomenologische Studie mit drei Psychotherapeut:innen durch, die sie sowohl vor, während, unmittelbar nach und einen Monat nach der
Teilnahme an einem Kurs zur Mitgefühlsmeditation interviewten. Die drei Personen wurden kriterienorientiert ausgewählt, und zwar mussten die Teilnehmer:innen die folgenden vier Kriterien
erfüllen: Sie mussten in Québec als Psychotherapeut:innen registriert sein (um einen gemeinsamen Hintergrund sicherzustellen), über mindestens fünf Jahre Berufserfahrung verfügen, seit


34


2.1 Kriterienorientierte Fallauswahl


mindestens einem Jahr regelmäßig Achtsamkeitsmeditation betreiben, aber nicht Mitgefühlsmeditation. Die Forschenden wandten sich zunächst an den relevanten Berufsverband in Kanada; auf
diesen Aufruf hin meldete sich jedoch nur eine Person, die sämtliche Kriterien erfüllte. Weitere
Teilnehmer:innen wurden im Schneeballverfahren gefunden, d. h. die eine Person, die alle Kriterien
erfüllte, verwies die Forschenden an weitere mögliche Teilnehmer:innen, die ihrerseits ebenfalls
Kontakte zwischen den Forschenden und geeigneten Kolleg:innen herstellten. Auf diese Weise
konnten zunächst vier Teilnehmer:innen gewonnen werden, von denen eine jedoch nach kurzer
Zeit aus der Studie ausschied, so dass drei Personen verblieben.
Die Teilnehmer:innen berichteten unter anderem, dass sie nach dem Kurs besser in der Lage
waren, für ihre Klient:innen präsent zu sein, ihnen genuine Akzeptanz entgegenzubringen und ihr
Leiden zu halten.


Diese Untersuchung von Bébec und Kolleg:innen zeigt Folgendes. Erstens wird daran
deutlich, wie die Fallauswahl in der qualitativen Forschung in erster Linie von analytischen Kriterien geleitet wird und nicht von soziodemographischen Merkmalen
(s. o. 1.4). Durch die Kombination verschiedener Kriterien ergibt sich meist eine sehr
spezifische und kleine Personengruppe bzw. Grundgesamtheit, die als Teilnehmer:innen für die entsprechende Untersuchung in Frage kommt. Die Untersuchung zeigt
außerdem, dass die kriterienorientierte Fallauswahl meist dazu dient, eine homogene
Stichprobe zu generieren. Dadurch, dass Fälle in die Stichprobe aufgenommen werden, die eine sehr spezifische Kombination von Kriterien erfüllen, müssen die Fälle
einander in diesen Hinsichten auch ähnlich sein (zu Ausnahmen s.u.). Und drittens
veranschaulicht die Studie auch, dass mit der Entscheidung für eine kriterienorientierte Fallauswahl nur etwas darüber ausgesagt wird, welche Arten von Fällen oder
Untersuchungseinheiten in die Stichprobe aufgenommen werden sollen. Es sind damit
aber noch keine Entscheidungen darüber verbunden, wie diese Form der Fallauswahl
konkret umgesetzt wird, wie die Forschenden also Zugang zu der interessierenden
Personengruppe erhalten. Typisch ist hier beispielsweise die Nutzung von Aushängen,
der Kontakt über Schlüsselorganisationen (in der Untersuchung von Bébec et al. war
dies der Berufsverband) oder auch Formen des responsiven Sampling (in der Untersuchung von Bébec das Schneeballverfahren; s. u. 2.5).


Bei der kriterienorientierten Fallauswahl werden solche Fälle in die Untersuchung aufgenommen,
die vorab spezifizierte, meist analytische Kriterien erfüllen. Um die Kriterien festzulegen, ist Vorwissen über den Gegenstandsbereich erforderlich. Die Kriterien können im Untersuchungsverlauf
modifiziert und angepasst werden.


35


2 Strategien absichtsvoller Fallauswahl


2.2 Qualitativer Stichprobenplan und Maximum-Variation-Sampling


Der _qualitative Stichprobenplan_ (auch als Quotenplan bezeichnet) ist von seiner Anlage
her vergleichsweise stark an das quantitative Vorgehen angelehnt. Denn erstens handelt es sich dabei um ein a priori bestimmtes Vorgehen: Auf der Grundlage von Vorwissen werden Kriterien identifiziert, die mit dem untersuchten Phänomen in Zusammenhang stehen. Zweitens wird die Grundgesamtheit auf der Grundlage dieser Kriterien,
ähnlich wie bei der Quotenstichprobe in der quantitativen Forschung, in Schichten
unterteilt. In der am stärksten vordefinierten Variante des qualitativen Stichprobenplans legen die Forschenden sogar vorab fest, wie viele Untersuchungseinheiten pro
Schicht und Kombination von Schichten (d. h. pro Zelle des Stichprobenplans) in die
Untersuchung einbezogen werden sollen. Der zentrale Unterschied zur Quotenstichprobe in der quantitativen Forschung besteht darin, dass die Fallzahlen beim qualitativen Stichprobenplan deutlich geringer sind; manchmal sind pro Zelle des Untersuchungsplans lediglich ein oder zwei Untersuchungseinheiten vorgesehen. Der
qualitative Stichprobenplan führt zu einer heterogenen Stichprobe.


**Untersuchungsbeispiel: Rauchen im Lockdown während der Covid-Pandemie**


Rachel O’Donnell und ihre Kolleg:innen befassten sich in einer Interviewstudie mit der Frage, ob
und wie sich das Rauchen unter Lockdown-Bedingungen während der Corona-Pandemie veränderte (2021). Bei der Auswahl der Teilnehmer:innen legten sie einen qualitativen Stichprobenplan
zugrunde. Auf der Grundlage von Vorwissen gingen sie davon aus, dass die folgenden Merkmale
mit dem Rauchverhalten in Zusammenhang stehen und daher bei der Auswahl der Teilnehmer:innen variiert werden sollten: Alter (vor dem Ruhestand: 21–64; nach dem Ruhestand: 65 und darüber), Geschlecht (männlich, weiblich), Rauchstatus (Haushalt mit anderen Rauchern, Haushalt
mit Nichtrauchern), Zusammensetzung des Haushalts (Einpersonenhaushalt, Mehrpersonenhaushalt), Kinder (Kinder unter 18 leben im Haushalt; keine Kinder unter 18 im Haushalt), ob von der
Wohnung aus Zugang zu einem Außenbereich bestand (ja, nein) sowie Veränderungen in der
Work-Life-Balance (Veränderungen durch den Lockdown, keine Veränderungen durch den Lockdown); sekundär wurden außerdem der sozioökonomische Status und der berufliche Status (Vollzeit, Teilzeit, arbeitslos, im Ruhestand etc.) erfasst. Aufgrund der hohen Anzahl an zu variierenden
Merkmalen wurden diese nicht miteinander gekreuzt, sondern es wurden pro Merkmal und Merkmalsausprägung Quoten festgelegt. So sollten beispielsweise ca. 75 Prozent Personen im arbeitsfähigen Alter interviewt werden und etwa 25 Prozent Personen im Alter über 65, je 50 Prozent Personen mit direktem Zugang zu einem Außenbereich und 50 Prozent ohne usw.
Bei der Suche nach Untersuchungsteilnehmer:innen, die diese differenzierten Kriterien erfüllten,
konnten die Forschenden auf das Panel einer umfangreichen Marktforschungsstudie zurückgreifen, das mehr als 11.800 Personen umfasste. Alle Mitglieder des Panels wurden angeschrieben


36


2.2 Qualitativer Stichprobenplan und Maximum-Variation-Sampling


und gebeten, einen Fragebogen zum Vorab-Screening auszufüllen. Auf der Grundlage dieser Fragebögen wurden solche Personen von der Teilnahme ausgeschlossen, die entweder selbst wegen
einer Covid-Erkrankung einen Krankenhausaufenthalt hinter sich hatten oder bei denen ein Mitglied des Haushalts wegen einer Covid-Erkrankung im Krankenhaus behandelt werden musste.
Damit verblieben 572 potenzielle Teilnehmer:innen. Darunter wurden sukzessive entsprechend
dem Stichprobenplan 25 Personen für den hier relevanten Teil der Studie ausgewählt. Dabei konnten die vorgegebenen Quotierungen hinsichtlich der verschiedenen Merkmale fast alle eingehalten
werden; lediglich die Gruppe der Personen, die über keinen Zugang zu einem Außenbereich verfügten, war etwas unterrepräsentiert.


Diese Untersuchung veranschaulicht die Verwendung eines komplexen qualitativen
Stichprobenplans. Der Rückgriff auf ein umfangreiches Marktforschungspanel zeigt
aber andererseits auch, dass die Realisierung eines solchen Plans nicht ohne weitere
Voraussetzungen möglich ist. Um die vorgegebenen Quotierungen zu erreichen, ist
ein größerer Pool potenzieller Teilnehmer:innen erforderlich, über den qualitativ Forschende üblicherweise nicht verfügen. Meist werden daher deutlich weniger Merkmale
und Merkmalskombinationen in einen qualitativen Stichprobenplan einbezogen, und
auch die angezielten Quotierungen können meist nicht so präzise eingehalten werden.

Ein Nachteil eines vorab festgelegten qualitativen Stichprobenplans besteht
darin, dass sich im Untersuchungsverlauf nicht selten zeigt, dass noch andere als die
ursprünglich einbezogenen Kriterien in Zusammenhang mit dem interessierenden
Phänomen stehen. Würde man in dieser Situation an dem ursprünglichen Stichprobenplan festhalten, so würde das der offenen, iterativen Vorgehensweise in der qualitativen Forschung zuwiderlaufen. Es ist daher sinnvoll, den Stichprobenplan nicht
als in Stein gemeißelt zu betrachten, sondern ihn im Untersuchungsverlauf flexibel
anzupassen, etwa durch Einbeziehung oder Weglassen einzelner Merkmale. Bei einer
solchen flexiblen Handhabung qualitativer Stichprobenpläne, bei der deduktive und
induktive Elemente integriert sind, nähern sich die Vorgehensweise beim qualitativen
Stichprobenplan und beim Theoretical Sampling (s. u. 2.3) einander an.


Beim qualitativen Stichprobenplan werden vor Untersuchungsbeginn aufgrund von Vorwissen
relevante Kriterien und Kriterienkombinationen festgelegt. Es wird auch vorab bestimmt, wie viele
Fälle pro Kriterienkombination in die Untersuchung einbezogen werden. Es resultiert eine heterogene Stichprobe.


Eine Variante des qualitativen Stichprobenplans, die forschungspraktisch deutlich
leichter zu realisieren ist, ist das _Maximum-Variation-Sampling._ Auch hier werden auf


37


2 Strategien absichtsvoller Fallauswahl


der Grundlage eines Literaturüberblicks vorab Kriterien festgelegt, die vermutlich mit
dem interessierenden Gegenstandsbereich in Zusammenhang stehen. Anders als beim
qualitativen Stichprobenplan werden dabei aber keine präzisen Quoten für einzelne
Kriterien oder Kriterienkombinationen bestimmt. Stattdessen besteht das Ziel darin,
über die verschiedenen Kriterienausprägungen und ihre Kombinationen hinweg so
viel Variabilität wie möglich zu realisieren. Wie beim qualitativen Stichprobenplan
wird also auch hier ein deduktives Vorgehen umgesetzt, und es wird eine heterogene
Stichprobe angestrebt, und auch das Maximum-Variation-Sampling kann im Untersuchungsverlauf angepasst werden.


**Untersuchungsbeispiel: Einstellungen von Psychiater:innen zu psychedelischen Substanzen**


Marija Franka Žuljević und Kolleg:innen (2024) verwenden zwar nicht den Begriff des MaximumVariation-Sampling, nutzen aber genau diese Strategie der Fallauswahl in ihrer Interviewstudie
über die Einstellungen von Psychiater:innen zur Nutzung psychedelischer Substanzen im Rahmen
psychotherapeutischer Interventionen in verschiedenen europäischen Ländern.
Bei der Fallauswahl verfolgten sie das Ziel einer möglichst heterogenen Stichprobe. Dabei bezogen sie die folgenden Kriterien ein: das Geschlecht; ob die Personen sich noch in Ausbildung
befanden oder bereits praktizierten; die Region Europas, aus der die Teilnehmer:innen stammten
(West-, Ost- und Zentral-Europa); sowie das Vorwissen über psychedelische Substanzen (gering,
mittel, gut). Das Vorwissen über Psychedelika erfassten sie mit einem Fragebogeninstrument und
zogen außerdem das Interview selbst zur Einschätzung heran. Um potenzielle Teilnehmer:innen zu
finden, nutzen sie verschiedene Wege. Das waren teils persönliche Kontakte, teils Informationen
über die Bereitschaft zur Teilnahme an einer Interviewstudie aus einer anderen, vorausgehenden
Studie; außerdem nutzten sie das Schneeballverfahren. Auf diese Weise konnten 12 Personen aus
acht verschiedenen europäischen Ländern für eine Teilnahme gewonnen werden.


Beim Maximum-Variation-Sampling werden bei der Fallauswahl möglichst viele Kriterien und Kriterienkombinationen herangezogen, so dass eine heterogene Stichprobe resultiert. Die Kriterien
können im Untersuchungsverlauf angepasst werden. Anders als beim qualitativen Stichprobenplan werden vorab keine Fallzahlen pro Kriterienkombination festgelegt. Das Maximum-VariationSampling ist daher leichter umzusetzen.


Sowohl der qualitative Stichprobenplan als auch das Maximum-Variation-Sampling
eignen sich besonders gut, um ein Phänomen in seinen verschiedenen Facetten zu
beschreiben.


38


2.3 Theoretical Sampling


2.3 Theoretical Sampling


Das Theoretical Sampling gehört zu den flexiblen Arten der qualitativen Stichprobenziehung: Die Auswahl der Fälle wird nicht vorab festgelegt, sondern forschungsbegleitend in direktem Zusammenhang mit den Erkenntnissen der Forschenden weiterentwickelt. Die Stichproben werden dabei so konzipiert, dass die Fälle das zu untersuchende
Phänomen entsprechend der Forschungsfrage veranschaulichen. Dafür wählen Forschende ihre Fälle nacheinander aus, immer vor dem Hintergrund, ob der nächste Fall
das Wissen über die Ausprägungen des zu untersuchenden Phänomens erweitern, vertiefen, differenzieren, bestätigen oder auch in Frage stellen kann. Die Kriterien zur
Auswahl von Fällen basieren somit auf vorläufigen Anhaltspunkten, die auf dem Wissen und den Erkenntnissen aus den bereits erhobenen Daten aufbauen.


Beim Theoretical Sampling wird die Auswahl der Fälle nicht vorab festgelegt, sondern im Forschungs
verlauf entwickelt. Forschende wählen ihre Fälle vor dem Hintergrund aus, ob der nächste Fall dazu

beitragen kann, das Wissen über die Ausprägungen des Forschungsphänomens zu erweitern.


Das Ziel der theoretischen Fallauswahl ist eine „konzeptuelle Repräsentativität“
(Strübing, 2014, S. 31). Dabei wird geprüft, innerhalb welcher Grenzen ein Konzept
anwendbar ist (s. u. 3.1), und dies gibt auch Hinweise auf die Bandbreite des Geltungsbereichs. Es geht darum herauszufinden, in welchen unterschiedlichen Kontexten das
Konzept relevant bleibt und wo seine Grenzen liegen. Die gezielte Auswahl von abweichenden oder kontrastierenden Fällen wird von Forschenden eingesetzt, um den Geltungsbereich ihrer Kategorien herauszufordern. Werden in diesen Fällen Abweichungen deutlich, führt dies zu einer Begründungspflicht der Forschenden, inwieweit die
Erkenntnisse Einfluss auf die Reichweite der entwickelten Konzepte haben. Eine Repräsentativität hinsichtlich spezifischer Populationen oder demografischer Faktoren wird
in der Regel nicht angestrebt (s. u. 5.4). Sind demografische Merkmale jedoch relevant, um das Phänomen tiefergehend zu verstehen, dann sollten auch diese Aspekte
beim Theoretical Sampling einbezogen werden. Das Theoretical Sampling folgt entsprechend keiner festen Abfolge von eindeutigen Schritten, sondern wird durch die
Forschenden jeweils in Anbetracht des zu untersuchenden Phänomens schrittweise
angepasst und weiterentwickelt.


39


2 Strategien absichtsvoller Fallauswahl


**Untersuchungsbeispiel: Erfahrungen von Eltern mit dem Tod ihres Kindes**


Ashleigh Butler und Kolleginnen (2018) untersuchten in ihrer Studie die Erfahrung von Eltern mit
dem Tod ihres Kindes auf einer pädiatrischen Intensivstation und mit der Gestaltung der verschiedenen Beziehungsphasen mit dem Gesundheitspersonal. Die Grounded Theory Studie folgte dem
Prinzip des Theoretical Sampling.
In einem ersten Schritt führten die Forscherinnen Interviews mit fünf Eltern durch, um hierdurch
erste Erkenntnisse über das Untersuchungsphänomen zu erhalten. Das Einschlusskriterium für
die Auswahl der ersten fünf Eltern war daran geknüpft, dass ein Kind dieser Eltern auf dieser Intensivstation innerhalb der letzten 6–48 Monate verstorben war. Die Interviews folgten einem offenen Interviewleitfaden, der aufgrund der sensiblen Thematik ein besonderes Augenmerk auf den
empathischen Gesprächsraum und das Wohlbefinden der Interviewten legte und inhaltlich offen
den narrativen Schwerpunktsetzungen der Eltern folgte. Durch die Datenaufbereitung und Analyse
dieser Interviewdaten entwickelten die Forscherinnen erste Konzepte und vorläufige Kategorien
zur Bedeutung, die eine Unterstützung durch das Gesundheitspersonal während und nach dem
Krankenhausaufenthalt für die Eltern hatte. In den Daten wurde offensichtlich, dass sich die Eltern
während des Aufenthalts auf der Intensivstation sehr stark unterstützt, sich jedoch nach dem Tod
des Kindes durch das Krankenhaus und das Gesundheitspersonal im Stich gelassen fühlten. Dies
wurde insbesondere daran festgemacht, dass der Kontakt mit dem Gesundheitspersonal nach
dem Tod des Kindes abriss. Ausgehend von den Erkenntnissen aus diesen ersten fünf Interviews
entwickelten die Forscherinnen ihr Theoretical Sampling auf mehreren Ebenen weiter.


Abb. 2.1: Zentrale Phasen des Theoretical Sampling (eigene Darstellung)


Die schrittweise Fallauswahl in der Studie von Butler et al. (2018) zeigt exemplarisch, wie Forschende ihre Fallauswahl im Verlauf der Studie anpassen und eng mit


40


2.3 Theoretical Sampling


den Erkenntnissen des Forschungsprozesses verknüpfen und weiterentwickeln können. Hierbei lassen sich drei zentrale Phasen des Theoretical Sampling unterscheiden
(s. Abb. 2.1).


2.3.1 Erste Phase: Die selektive Fallauswahl


Das Theoretical Sampling startet mit einem vorläufigen Ausgangspunkt, von dem aus
die Theorieentwicklung ihren Ausgang nehmen kann. Dieser Ausgangspunkt wurde
von Thompson (1999) als _Jumping-Off Point_ bezeichnet, wird häufig jedoch auch als
Phase der selektiven Fallauswahl beschrieben. Die Auswahl der ersten Datenquellen –
oder in unserem Untersuchungsbeispiel die Auswahl der ersten Eltern für Interviews –
wird von einem klar markierten Ausgangspunkt aus betrieben. Für dessen Bestimmung
sind theoretische Vorannahmen und / oder Vorahnungen der Forschenden maßgeblich. Sie geben Hinweise darauf, welche Aspekte im weiteren Verlauf für die Beantwortung der Forschungsfrage von Bedeutung sein können. Dies können sowohl spezifische
demografische Faktoren sein, wie Geschlechtlichkeit und Alter, als auch Merkmale,
die mit dem Untersuchungsphänomen verbunden sind, wie beispielsweise persönliche
Erfahrungen oder verschiedene Zugänge zum untersuchten Phänomen.

Zur Veranschaulichung hatte Yin (2017) das Beispiel von Christopher Kolumbus‘
Aufbruch zur Entdeckung der sogenannten Neuen Welt als einen solchen Ausgangspunkt genutzt: Kolumbus hatte für seine Suche nach einem Seeweg nach Indien drei
Schiffe angefordert ( _warum nicht zwei oder vier?_ ) und ist in westlicher Himmelsrichtung aufgebrochen ( _warum nicht südlich und dann östlich?_ ). Sein Weg zur Erforschung
der angeblichen Neuen Welt startete mit subjektiv begründeten Vermutungen (Anzahl
der Schiffe und Himmelsrichtungen). Auch wenn diese Annahmen sich im Verlauf des
Forschungsprozesses als falsch herausstellten, waren sie der Ausgangspunkt für seine
weitere Expedition und die damit verbundenen Erkenntnisse.

Übertragen auf das Theoretical Sampling bedeutet dies, dass Forschende von einem
Startpunkt aus mit einer bestimmten Auswahl an Fällen beginnen und die nächsten Fälle
kontinuierlich zu diesen Ausgangsfällen in Vergleich setzen. Der Auswahl der ersten
Fälle kommt beim Theoretical Sampling entsprechend eine besondere Bedeutung zu.


Den ersten Fällen (Jumping-Off Point) kommt im Theoretical Sampling besondere Bedeutung zu,
da alle folgenden Fälle zu diesen Ausgangsfällen in Vergleich gesetzt werden.


Mit Blick auf unser Untersuchungsbeispiel von Butler et al. (2018) haben die Forscherinnen im ersten Schritt ihre Interviews mit Eltern einer spezifischen Kinderintensivstation geführt. Zentrales Auswahlkriterium war, Eltern einzubeziehen, deren Kin

41


2 Strategien absichtsvoller Fallauswahl


der innerhalb der letzten 6–48 Monate auf dieser Kinderintensivstation verstorben
waren. Das Alter der Kinder, die Todesursache (chronische oder akute Erkrankung)
und die familiäre Situation wurden zwar dokumentiert, waren jedoch für die Auswahl
der Fälle zu diesem Zeitpunkt der Studie nicht entscheidend. Durch diesen Ausgangspunkt und die damit verbundene Entscheidung für die ersten Datenquellen haben die
Forscherinnen bereits ihren Ergebnishorizont angelegt: Die Erfassung der elterlichen
Perspektive in den Interviews führt unmittelbar zu einem Fokus auf die elterliche Sicht
des Trauerprozesses und beispielsweise nicht die Sicht der Pflegenden oder anderer
begleitender Personen.

Die Relevanz der Unterstützung trauernder Eltern durch das Gesundheitspersonal, auch über den stationären Aufenthalt hinaus, wurde den Forschenden erst durch
die unmittelbare Auseinandersetzung mit den Eltern bewusst. Entsprechend war den
Forscherinnen nicht von Beginn an klar, dass der Fokus der Studie nachhaltig auf der
Beziehung zwischen Eltern und Gesundheitspersonal bleiben würde. Der Unterstützungsbedarf zeigte sich jedoch bereits in den ersten fünf Interviews, in dem Kontrast
zwischen der als sehr gut bewerteten Betreuung während des stationären Aufenthalts
und dem Gefühl der Eltern, dass sie nach dem Tod des Kindes im Stich gelassen wurden. Die Forschenden entschieden daher, in den folgenden Forschungsschritten unter
anderem ein spezifisches Augenmerk auf den Aspekt der Unterstützung zu legen.

Die Kriterien, die Forschende für den Ausgangspunkt und damit die Auswahl ihrer
ersten Fälle zugrunde legen, sollten sie im Sinne eines _Prüfpfads_ detailliert dokumentieren, ebenso wie auch alle weiteren methodischen Entscheidungen. Die Aufzeichnungen umfassen in der Regel die Gedanken über Abwägungen zu demografischen
Aspekten, möglichen ersten Institutionen oder Orten / Stadtteilen und Überlegungen
zu den Strategien zur Rekrutierung der Teilnehmenden. Für den Verlauf der Studie
bieten diese ersten Aufzeichnungen hilfreiche Anhaltspunkte zur Reflektion und Kontrastierung der weiteren Fallauswahl.

Die Bestimmung des Zeitpunkts, um von der initialen Phase des selektiven Sampling in die Erkundungsphase des relationalen Sampling überzugehen, liegt in den Händen der Forschenden.


2.3.2 Zweite Phase: Die relationale Fallauswahl


Ausgehend von der selektiven Auswahl der ersten Datenquellen bzw. Interviews wechseln Forschende in der zweiten Phase in eine relationale Fallauswahl. In dieser Phase
erkunden sie die Bezüge zwischen den Stichprobenkriterien. Dabei sind Forschende in
der Stichprobenzusammenstellung jedoch nicht auf spezifische demografische Faktoren (Abdeckung verschiedener Alterskategorien) oder die Repräsentanz einer Grundgesamtheit (Abbild nach spezifischen Parametern) hin verpflichtet, es sei denn, dies ist
zum Verständnis der Kategorien oder der entwickelten Theorie notwendig.


42


2.3 Theoretical Sampling


In der zweiten Phase der relationalen Fallauswahl erkunden die Forschenden die Bezüge zwischen
den Stichprobenkriterien.


In unserem Untersuchungsbeispiel haben die Forscherinnen sich entschieden, den
Aspekt der Unterstützung durch das Gesundheitspersonal in verschiedenen Ausprägungen tiefer zu erkunden. Hier suchten die Forscherinnen in einem zweiten Schritt
nach weiteren pädiatrischen Intensivstationen, die ein vergleichbares Maß an stationärer Kinderbetreuung boten wie die erste Klinik, jedoch optional zusätzlich einen
Trauerbegleitungsdienst für die Zeit nach dem Krankenhausaufenthalt anboten. Durch
die Einbeziehung von zwei weiteren pädiatrischen Intensivstationen konnten die Forscherinnen zusätzliche Elternerfahrungen einbeziehen. Die Eltern hatten ein weitergehendes Versorgungsangebot zur Trauerbegleitung über die stationäre Begleitung hinaus; dies bot einen Kontrast zum Eindruck der Eltern des Ausgangsklinikums, die sich
nach dem Tod ihres Kindes vom Gesundheitspersonal im Stich gelassen fühlten.

Durch die _Kontrastierung_ konnten die Forscherinnen die verschiedenen Dimensionen und Merkmale über die Fälle (in diesem Fall: Eltern) hinweg ausdehnen und vergleichend ausdifferenzieren. Sie unterteilten den Unterstützungsbedarf der Eltern in
folgende Phasen: während des Krankenhausaufenthalts, in der akuten Phase des Sterbens und während der Trauerphase (in der sich das enge Verhältnis von Eltern und
Gesundheitspersonal schrittweise löste).

Neben der Ausweitung auf zwei weitere Intensivstationen nutzten die Forscherinnen
die ersten Interviews als Ausgangspunkt für eine Erweiterung ihres Interviewleitfadens.
In den ersten Interviews beschrieben die Eltern ihre Erfahrungen mit dem Gesundheitspersonal als durchweg positiv oder sogar „fantastisch“ – trotz einzelner Hinweise auf
negative Erfahrungen. Bei den folgenden Interviews fragten die Forscherinnen daher
gezielt nach, wenn Eltern das Personal als „gut“ oder „fantastisch“ beschrieben, ob sie
auch schlechte Erfahrungen gemacht hätten. Durch diese Nachfragen stellten die Forscherinnen fest, dass die meisten Eltern zögerten oder auswichen, bevor sie sich negativ über das Gesundheitspersonal äußerten. Bei der Erkundung dieses ausweichenden
Verhaltens stießen die Forscherinnen auf eine Interviewsequenz, in der eine Mutter
Verhaltensweisen und Eigenschaften beschrieb, die ihr an dem Personal „nicht gefielen“. In den folgenden Interviews nutzten die Forscherinnen diese sanftere Formulierung, indem sie die Eltern nach Verhalten und Eigenschaften fragten, die weniger gut
waren oder ihnen nicht gefielen. Auf diese Weise konnten die Forscherinnen ein differenzierteres und komplexes Bild der Bewertung seitens der Eltern entwickeln, jenseits
von einer allzu vereinfachenden Gegenüberstellung von „gut“ und „schlecht“.

Zusätzlich zum Unterstützungsbedarf und der Bewertung des Verhaltens und der
Eigenschaften des Gesundheitspersonals rekonstruierten die Forscherinnern als dritte
Dimension verschiedene Anforderungen an die elterliche Rolle eines sterbenden Kin

43


2 Strategien absichtsvoller Fallauswahl


des auf einer Intensivstation. Die Forscherinnen nutzten ein Interview mit einer Mutter, um ihr Verständnis der elterlichen Rolle auf der Kinderintensivstation darzulegen
und darin ihr Verständnis zu überprüfen. Die Mutter war jedoch nicht mit allen Erläuterungen der Forscherinnen einverstanden. Zwar stimmte sie in vielen Aspekten zu;
widersprach jedoch auch an zentralen Stellen. Bis zu diesem Zeitpunkt waren demographische Faktoren nicht im Fokus der Studie. Die Rückmeldung der Mutter, deren
verstorbenes Kind ein zuvor gesunder und unabhängiger Teenager war, lenkte die Forscherinnen jedoch auf folgende Diskrepanz: Die Mutter empfand sich nicht für die
körperliche Pflege ihres schwer kranken Kindes zuständig und betonte den Wunsch,
die Intimsphäre ihres Kindes zu schützen und daher keine pflegende Rolle zu übernehmen. Diese unerwartete Erkenntnis führte zu einem bewussten Nachjustieren des
Theoretical Sampling: Die Forscherinnen bezogen im Folgenden gezielt Eltern von Kindern unterschiedlicher Altersgruppen und verschiedener Entwicklungsstadien ein und
erkundeten den Aspekt von körperlicher Nähe und Distanz zwischen Eltern und Kindern. So konnten die Forscherinnen ein differenziertes Verständnis der elterlichen Rollen entwickeln, das die unterschiedlichen Erfahrungen und Perspektiven von Eltern
mit Blick auf die körperliche Versorgung ihrer Kinder berücksichtigte.

Die Vorgehensweise von Butler et al. (2018) macht deutlich, wie die gezielte Auswahl der Fälle zu einer Variation und Vielfalt der Ausprägungen eines Phänomens beitragen kann. Entsprechend werden auch bewusst ungewöhnliche Fälle und Konzepte
berücksichtigt, um die Heterogenität auf verschiedenen konzeptionellen Ebenen (konzeptionelle Repräsentanz; s. o.) zu entwickeln. Fälle werden entsprechend so ausgewählt, dass sie im Vergleich kontrastierende Ausprägungen eines Konzeptes ausleuchten. In unserem Beispiel wurde dies mit Blick auf die Unterstützung während und nach
dem Krankenhausaufenthalt, die Bewertung des Gesundheitspersonals wie auch das
Verständnis der elterlichen Rolle hinsichtlich der körperlichen Pflege des eigenen Kindes herausgearbeitet. Der Prozess der Fallauswahl entwickelt sich dabei flexibel und
schrittweise, so dass Forschende – sobald sie die ersten Daten erhoben haben und erste
Hinweise auf Merkmale und Muster zur Beantwortung der Forschungsfrage identifizieren können -, diesen Hinweisen in alle Richtungen folgen. Die Auswahl und Entscheidung, welche Merkmale und Muster für die Beantwortung der Forschungsfrage
relevant sein könnten, liegt in den Händen der Forschenden.


Sobald Forschende die ersten Daten erhoben haben, entwickeln sie die Fallauswahl anhand ihres
bestehenden Datenbestands und ihrer Erkenntnisse kontrastierend weiter. Die Kriterien zur Fallauswahl sind entsprechend vorläufig und flexibel emergent.


Die Entscheidungen der Forschenden sind _vorläufig_ und offen für Veränderungen im
Verlauf der Forschung (auch Kolumbus hat seinen Segelkurs immer wieder aufs Neue


44


2.3 Theoretical Sampling


angepasst). So entscheiden auch Forschende immer wieder aufs Neue, welche Aspekte
für den weiteren Verstehensprozess als interessant erachtet oder (vorläufig) außer
Acht gelassen werden. Wie bereits anhand unseres Untersuchungsbeispiels erläutert,
passen die Forschenden ihre Befragungen entsprechend an und beziehen weitere Orte
oder Personengruppen ein, um allen relevanten Mustern in ihren Daten zu folgen.
Hierfür kehren Forschende immer wieder zu ihren bereits analysierten Daten oder vernachlässigten Aspekten zurück, um bisherige Vermutungen und Erwartungen erneut
an dem Datenbestand zu überprüfen. So können durch den Vergleich neue Gesichtspunkte sichtbar werden, die sich als vielversprechend für die Weiterentwicklung der
Theorie erweisen. Und auch die erneute Befragung von Interviewteilnehmenden aus
vorherigen Erhebungen kann vielversprechend sein, um Informationen zu vertiefen,
die sich erst im Forschungsverlauf als relevant erwiesen haben.

Die Kriterien für das Theoretical Sampling werden nur vorübergehend festgelegt
und in ständigem Vergleich mit dem Datenbestand und der Kenntnis über das Phänomen kontrastierend weiterentwickelt.

Das kontrastive Vorgehen beim Theoretical Sampling bietet die Grundlage für eine
sorgfältige Abwägung der relevanten Merkmale zur Fallauswahl (s. u. 3.1). Insbesondere in der relationalen Phase, in der Forschende die Beziehungen zwischen Kategorien erkunden, ist eine _detaillierte Erläuterung_ der Auswahlkriterien unerlässlich. Im
Forschungsbericht sollten Forschende ihre Überlegungen und Entscheidungen nachvollziehbar machen, aus welchem Grund bestimmte Aspekte des Forschungsgegenstands als relevant erachtet und andere vernachlässigt wurden. Eine solche nachvollziehbare Darlegung der Fallauswahl hilft, die Entwicklung der Theorie begründet
darzulegen. Forschungspraktisch wird darin offensichtlich, dass die im Forschungsverlauf erarbeiteten Auswahlkriterien sehr unterschiedlich sind: Einige Merkmalsräume
sind aufgrund ihrer konzeptionellen Beschaffenheit schwieriger in Stichprobenkategorien zu überführen als andere. Während beispielsweise das Alter oder der körperliche Pflegebedarf eines Kindes für die Fallauswahl vorab abgefragt werden kann, ist die
Ausgestaltung der elterlichen Rolle von sehr unterschiedlichen Merkmalen abhängig,
die sich nicht unbedingt vorab feststellen lassen. Im Fall solcher analytischen Kriterien
ist daher zu Beginn der Datenerhebung unklar, ob ein Fall dann auch tatsächlich den
relevanten Kriterien entspricht (zur Unterscheidung zwischen soziodemographischen
und analytischen Kriterien s. o. 1.4).


In der relationalen Phase der Fallauswahl sind die Forschenden angehalten, ihre Auswahlkriterien
und deren Modifikation differenziert zu erläutern.


Darüber hinaus gibt es Forschungsarrangements, in denen die Phase der ­Datenerhebung
zeitlich so eng strukturiert ist, dass eine differenzierte Analyse der Fälle nicht ­parallel


45


2 Strategien absichtsvoller Fallauswahl


zur Datenerhebung geleistet werden kann. Im Sinne einer flexiblen Anpassung des
Theoretical Sampling kann die Datenerhebung in solchen, zeitlich kritischen Fällen
in mehreren Phasen durchgeführt werden. Das Theoretical Sampling wird dann entsprechend in verschiedenen Erhebungs- und Auswertungswellen umgesetzt. Alternativ lässt sich das Vorgehen auch so modifizieren, dass begrenzte Analyseschritte direkt
im Anschluss an einen Teil der Datenerhebung durchgeführt werden, um daraus erste
Hinweise für die weitere Fallauswahl abzuleiten. Eine differenzierte Betrachtung der
Fallauswahl erfolgt erst in einer zweiten Analysewelle. Jede Form der Abweichung
von der idealtypischen Fallauswahl im Theoretical Sampling erfordert eine nachvollziehbare Begründung im Forschungsbericht. Dabei müssen Forschende reflektieren,
inwiefern diese Abweichungen die Möglichkeiten einschränken, kontrastive Fälle hinzuzuziehen, und dadurch auch die konzeptionelle Ausdifferenzierung begrenzen.
Eine solche Einschränkung würde die Tiefe der Theorieentwicklung beeinflussen. Forschende sollten Einschränkungen im Hinblick auf die theoretische Verallgemeinerung
ihrer Ergebnisse offenlegen und diskutieren (s. u. 5.4).


2.3.3 Dritte Phase: Die theoretische Fallauswahl


In der dritten Phase des Theoretical Sampling sind Forschende angehalten, _fokussie-_
_rende Entscheidungen_ zur Fallauswahl zu treffen, um ein höheres Maß an theoretischer
Konsistenz für die Beantwortung ihrer Forschungsfrage zu erreichen. Nachdem sie in
der relationalen Phase den Hinweisen in alle Richtungen gefolgt sind, fokussieren sie
sich in dieser letzten Phase in der Regel auf _eine_ Analyseperspektive und _ein_ damit
verbundenes _Schlüsselmerkmal_ . Hierfür überdenken sie nochmals alle bisher erarbeiteten Auswahlkriterien und deren Relevanz für die konzeptionellen und relationalen
Ausprägungen des Phänomens. Ein zentrales Ergebnis der relationalen Phase ist typischerweise, dass Forschende ein bestimmtes Schlüsselmerkmal für die Beantwortung
der Forschungsfrage als durchgehend relevant erachten; in seltenen Fällen können es
auch zwei Schlüsselmerkmale sein. Diese zentralen Merkmale werden _Kernkategorien_
genannt und bleiben durchgehend relevant für die Beantwortung der Forschungsfrage, auch wenn Forschende vielfältige Variationen untersucht haben. Eine solche
konstante Relevanz einer Kernkategorie bestätigt deren fundamentale Bedeutung für
die sich herauskristallisierende Theorie.


Die Phase der theoretischen Fallauswahl ist durch die Fokussierung auf ein Schlüsselmerkmal
bzw. eine Kernkategorie gekennzeichnet. Dabei handelt es sich um eine Kategorie, die für die
Beantwortung der Forschungsfrage durchgehend relevant ist.


46


2.3 Theoretical Sampling


Ausgehend von diesem zentralen Merkmal verfeinern Forschende ihr Verständnis für
das Phänomen mit Blick auf dessen soziale und strukturelle Ursachen und Kontexte,
intervenierende Bedingungen, Konsequenzen und Strategien ( _Kodierparadigma_ ). Sie
suchen in dieser Phase bewusst nach einzelnen Fällen, die ihr Verständnis erweitern,
vertiefen, differenzieren, bestätigen oder auch in Frage stellen können. Ziel ist es auszuloten, unter welchen Bedingungen ihre Schlussfolgerungen stabil bleiben, auch
wenn der Kontext der Fälle variiert.


In der letzten Phase des Theoretical Sampling verdichten Forschende ihr Verständnis von Kernkonzepten und deren Ausprägungen, indem sie gezielt einzelne Fälle auswählen, die Dimensionen
und Bezüge ihrer Kernkategorie erweitern, vertiefen, differenzieren, bestätigen oder auch in Frage
stellen können.


Bei unserem Untersuchungsbeispiel war der Ansatz der körperlichen Pflege so lange
durchgängig relevant, bis die Mutter eines Teenagers befragt wurde, und hier der
Aspekt der körperlichen Intimsphäre von Jugendlichen die elterliche Fürsorgerolle
klar begrenzt hat. Damit wird deutlich, wie weit die zuvor entwickelten Merkmale
zum Verständnis des Phänomens beitragen und ab wann eine Modifikation erforderlich wird (konzeptionelle Repräsentativität; s.o.).

Forschende suchen und verdichten auf diese Weise den konzeptionellen Kern ihres
Phänomens, bis das Hinzuziehen weiterer Fälle keine zusätzlichen Merkmalsräume
mehr eröffnet. Ab dann gilt die Stichprobe als gesättigt (zum Kriterium der Theoretischen Sättigung s. u. 3.1).

Ausgehend von unserem Untersuchungsbeispiel wird deutlich, dass das Theoretical
Sampling das komplexe Entwickeln und Ineinandergreifen von nicht-linearen Vorgehensweisen zur Fallauswahl beinhaltet. Entsprechend ist es auch für Forschende eine
Herausforderung, diesen iterativ-rekursiven Verstehensprozess in einer linearen schriftlichen Dokumentation festzuhalten. Forschende sind aus diesem Grund angehalten, die
Entwicklung dieses Auswahlprozesses von Fällen kontinuierlich Schritt für Schritt im
Verlauf zu _dokumentieren_ : ausgehend vom Jumping-Off Point, über die komplexen Prozesse der kontrastierenden-relationalen Fallauswahl, bis hin zur Entscheidung für ein
Schlüsselmerkmal und den damit verbundenen konzeptionellen Verdichtungen.


Forschende sind angehalten, den komplexen, schrittweisen Prozess des Theoretical Sampling
vollständig zu dokumentieren. Dies beinhaltet auch Einschränkungen der theoretischen Verallgemeinerbarkeit.


47


2 Strategien absichtsvoller Fallauswahl


2.4 Gezielte Auswahl bestimmter Arten von Fällen


Bei der gezielten Auswahl von Fällen handelt es sich um eine konzeptgesteuerte Strategie der Fallauswahl. Auf der Grundlage von Vorinformationen über die Ausprägungen des Phänomens, das untersucht werden soll, werden solche Fälle ausgewählt, die
in einem spezifischen Bereich auf diesem Spektrum liegen (etwa in der Mitte, an den
Extremen etc.). Dabei spricht man beispielsweise von typischen, intensiven, extremen,
intrinsischen oder kritischen Fällen. Je nach Anlage und Ziel der Untersuchung kann
die Auswahl sich auf einen einzelnen Fall beschränken, etwa einen typischen Fall (für
ein Beispiel einer Einzelfallstudie mit einem typischen Fall s. die Beschreibung der
‚Middle­town‘-Studie in 3.2; Lynd & Lynd, 1929) oder einen intrinsischen Fall. Wenn
mehrere Fälle ausgewählt werden, kann dies auf zwei Arten geschehen: Entweder
werden die Fälle so ausgewählt, dass sie einander ähnlich sind (zum Beispiel mehrere intensive Fälle). Dies führt zu einer homogenen Stichprobe. Oder die Fälle werden
bewusst so gewählt, dass sie sich deutlich voneinander unterscheiden (zum Beispiel
zwei extreme Fälle, in denen das Phänomen einmal stark und einmal schwach ausgeprägt ist). Dies führt zu einer heterogenen Stichprobe. Mit der Anwendung der gezielten Auswahl bestimmter Arten von Fällen ist also noch nichts über die Zusammensetzung der Stichprobe ausgesagt. Gemeinsam ist allen Formen der gezielten Auswahl
von Fällen lediglich, dass eine solche Auswahl Vorwissen erfordert.

Die gezielte Fallauswahl findet in erster Linie im Untersuchungsdesign der Fallstudie Anwendung oder auch in der Ethnografie (s. u. 3.2 und 3.3; auch in der Evaluationsforschung, auf die wir in diesem Band nicht eingehen). Dabei handelt es sich
meist um in sich komplexe Fälle, und innerhalb jedes Falls findet auf darunter liegenden Ebenen eine weitere Auswahl von Untersuchungseinheiten statt (etwa von Personen, Situationen oder Dokumenten). Im Folgenden gehen wir zunächst auf die Auswahl bestimmter Arten von Einzelfällen ein (Einzelfallstudie), anschließend auf die
Auswahl mehrerer Fälle (multiple Fallstudie).


Die gezielte Auswahl bestimmter Arten von Fällen erfolgt auf der Grundlage von Vorwissen. Je

nachdem, wie die Fälle sich zueinander verhalten, resultiert eine homogene oder eine heterogene

Stichprobe. Die Auswahlstrategie wird vor allem in der Fallstudie und in der Ethnografie angewandt.


Wie oben bereits erwähnt, sind die verschiedenen Arten von Einzelfällen über ihre
Position auf dem Spektrum der Verteilung des interessierenden Phänomens definiert.
Nehmen wir als Beispiel zur Illustration der verschiedenen Arten von Fällen Verläufe
von Grippe-Erkrankungen.

Der _typische Fall_ vereint in sich solche Merkmale, die für die Grundgesamtheit charakteristisch sind. Der typische Fall ist also auch ein repräsentativer Fall. In unserem


48


2.4 Gezielte Auswahl bestimmter Arten von Fällen


Beispiel wären dies Menschen, die plötzliches hohes Fieber, Gliederschmerzen, Halsschmerzen und Atemwegsbeschwerden entwickeln und nach zwei bis drei Wochen
wieder gesund sind, wenn vielleicht auch noch etwas geschwächt.

Der _intensive Fall_ zeigt alle Merkmale des interessierenden Phänomens in einer stärkeren Ausprägung als üblich. Das wären also beispielsweise Menschen, die alle die
oben genannten Grippe-Symptome aufweisen, wobei das Fieber aber länger anhält als
üblich und die anschließende Schwäche besonders stark ausgeprägt ist. Der gesamte
Krankheitsverlauf zieht sich so über drei bis vier Wochen hin.

Der _extreme Fall_ zeigt alle Merkmale des interessierenden Phänomens in einer ungewöhnlich geringen oder starken Ausprägung. Ein Extremfall einer geringen Ausprägung von Grippe wäre jemand, der oder die nach einer kurzen Fieberepisode nur leichten Husten entwickelt und nach drei oder vier Tagen schon wieder auf den Beinen
ist. Die Merkmale des Extremfalls mit einer starken Ausprägung sind ähnlich denen
des intensiven Falls – aber vielleicht kommt zu der Grippe noch ein bakterieller Infekt
hinzu, etwa eine Bronchitis. Und die Schwäche hält sogar noch Wochen bis Monate
nach der eigentlichen Erkrankung an.

Der _intrinsische_ _Fall_ ist ein Fall, der Merkmale aufweist, die diesen Fall aus sich heraus interessant machen; seine Merkmale können auf weitere Aspekte des Phänomens
hinweisen, die bisher in der Theoriebildung noch nicht hinreichend berücksichtigt
sind. Angenommen, ein Mensch würde sich aufgrund des Kontakts mit einem Tier mit
dem Vogelgrippe-Virus anstecken (was unseres Wissens bisher noch nicht vorgekommen ist) und entsprechende Symptome entwickeln, dann würde dies aufgrund des
ungewöhnlichen Ansteckungswegs einen intrinsischen Fall darstellen.

Der _kritische Fall_ ist ein Fall, der geeignet ist, eine Theorie zu testen – beispielweise
entsprechend der Überlegung: Wenn die Theorie zutrifft, dann müsste der kritische
Fall bestimmte Merkmale aufweisen. Wenn die Theorie korrekt ist, dass eine Ansteckung mit der Vogelgrippe nicht vom Tier zum Mensch erfolgen kann, dann sollte eine
Geflügelbäuerin, in deren Ställen die Vogelgrippe ausgebrochen ist, auch bei intensivem Kontakt mit den infizierten Vögeln keine Symptome entwickeln. Entwickelt sie
aber Symptome, dann stellt dies die Theorie in Frage. In diesem Beispiel würde also
die Geflügelbäuerin mit intensivem Kontakt zu infizierten Tieren den kritischen Fall
darstellen.


**Untersuchungsbeispiel: Copingstrategien einer wohnungslosen Frau**


Clara Posada-Ibadia und Kolleginnen (2021) führten im Rahmen ihrer Forschung zu Copingstrategien von wohnungslosen Frauen, die auf der Straße erheblicher Gewalt ausgesetzt sind, eine
Einzelfallstudie unter Verwendung der Photo Elicitation Technique durch. Die Untersuchungsteilnehmerin Maria wurde auf der Grundlage einer vorausgehenden Interviewstudie mit 20 Frauen in


49


2 Strategien absichtsvoller Fallauswahl


einem Obdachlosenheim ausgewählt: Die Forscherinnen hatten den Eindruck, dass Marias Erfahrungen und Strategien besonders informationshaltig waren und zu einem vertieften Verständnis
des Untersuchungsgegenstands beitrugen. Das macht Maria zu einem intrinsisch relevanten Fall.
Maria berichtet eindrücklich zunächst von ihren Gewalterfahrungen und anschließend von ihren
Copingstrategien, insbesondere dem Aufbau neuer Familienstrukturen, der Wiederherstellung des
Kontakts zu ihren Kindern und der Bedeutung von Spiritualität.


Diese Untersuchung verdeutlicht zunächst, dass ein Fall nur auf der Grundlage von
Vorwissen als eine bestimmte Art von Fall identifiziert werden kann. Dass Maria unter
obdachlosen Frauen, die Gewalt auf der Straße ausgesetzt waren, einen intrinsischen
Fall im Hinblick auf die Entwicklung von Copingstrategien darstellt, wird erst vor dem
Hintergrund der vorgängigen Interviewstudie und im Vergleich mit den anderen interviewten Frauen sichtbar. Das Beispiel zeigt weiterhin, dass die Unterscheidung zwischen verschiedenen Arten von Fällen nicht immer eindeutig ist. Im Rahmen ihres
Artikels bezeichnen die Forscherinnen Maria zunächst als intrinsischen, später als
repräsentativen und zuletzt gar als extremen Fall. Aus unserer Sicht ist die ursprüngliche Bezeichnung als intrinsischer Fall zutreffend: Marias Erfahrungen sind gerade
deshalb für die Forscherinnen so wertvoll, weil sie nicht typisch (bzw. repräsentativ)
sind. Auch stellt Maria aus unserer Sicht keinen Extremfall dar. Zwar war sie extremer
Gewalt ausgesetzt – aber das waren die anderen Frauen ebenfalls, die ihre Erfahrungen vielleicht weniger differenziert dargestellt und die weniger Copingstrategien entwickelt haben.


Ein Fall ist nicht per se typisch, extrem usw. Um zu entscheiden, um welche Art von Fall es sich
handelt, braucht man Vorwissen über die anderen Fälle in der Grundgesamtheit.


In einer multiplen Fallstudie können die Fälle gezielt so ausgewählt werden, dass entweder eine homogene Stichprobe gleichartiger Fälle resultiert, beispielsweise mehrere
typische Fälle, oder eine heterogene Stichprobe von Fällen, die untereinander kontrastieren (etwa zwei Extremfälle, je ein Fall mit einer besonders niedrigen und mit einer
besonders hohen Ausprägung des interessierenden Phänomens; s. u. 3.2).


50


2.5 Sampling Schemes: Das Vorgehen bei der konkreten Auswahl von Untersuchungseinheiten


2.5 Sampling Schemes: Das Vorgehen bei der konkreten Auswahl

von Untersuchungseinheiten


Bisher haben wir in diesem Kapitel solche Strategien dargestellt, bei denen der Schwerpunkt darauf liegt, nach welchen Gesichtspunkten Fälle oder Untersuchungseinheiten ausgewählt werden. Bei der kriterienorientierten Fallauswahl oder dem qualitativen Stichprobenplan sind dies bestimmte Merkmalskombinationen, denen die Fälle
entsprechen sollen; bei der gezielten Auswahl bestimmter Fälle geht es darum, dass
die Fälle in einer bestimmten Relation zur Grundgesamtheit oder zueinander stehen;
und beim Theoretical Sampling geht es ebenfalls darum, eine spezifische Relation
der Fälle untereinander zu realisieren, wobei diese Relationen sich erst im Untersuchungsverlauf ergeben.

Mit diesen Strategien wird also festgelegt, aus welchen Einheiten die Stichprobe
sich zusammensetzen soll. Damit ist allerdings noch nichts darüber gesagt, welche Einheiten konkret in die Untersuchung aufgenommen werden und wie die Forschenden
Zugang zu diesen Einheiten erhalten. Denn in aller Regel existiert eine ganze Reihe
von Einheiten, die den jeweiligen Kriterien entsprechen. Auch in der oben genannten Untersuchung von Bibeau et al. (2020) über die Zusammenhänge zwischen Mitgefühlsmeditation und therapeutischem Arbeiten gibt es in Québec sicherlich mehr
als nur drei oder vier registrierte Psychotherapeut:innen, die seit mindestens fünf
Jahren in ihrer Praxis tätig sind, regelmäßig Achtsamkeitsmeditation betreiben, aber
nicht Mitgefühlsmeditation. Vor diesem Hintergrund stellt sich die Frage, wie qualitativ Forschende konkret die Fälle und Einheiten auswählen, für die sie anschließend
Daten erheben. Diese Vorgehensweisen wurden von Onwuegbuzie und Leech (2007)
in Abgrenzung zu Strategien der Fallauswahl (Sampling Strategies) als Schemata der
Fallauswahl (Sampling Schemes) bezeichnet. Um solche Schemata soll es in diesem
Abschnitt gehen, und wir gehen auf drei von ihnen genauer ein: das Schneeballverfahren, die Ad-hoc-Fallauswahl und die Zufallsauswahl.


Unter Sampling Schemes versteht man die konkreten Vorgehensweisen, wie Forschende Zugang
zu Untersuchungsteilnehmer:innen erhalten.


2.5.1 Das Schneeballverfahren


Beim _Schneeballverfahren_ stehen am Anfang der Fallauswahl einige wenige Personen,
die den Kriterien für die Untersuchungsteilnahme entsprechen. Das können Personen
aus dem Bekannten- und Freundeskreis der Forschenden sein oder auch Personen, die
über einschlägige Organisationen gefunden wurden und sich zur Teilnahme bereit


51


2 Strategien absichtsvoller Fallauswahl


erklärt haben. Diese ersten Untersuchungsteilnehmer:innen werden auch als „Seeds“
bezeichnet, also als Samen oder Setzlinge (Parker, Scott, & Geddes, 2019, o. S.).

Die weitere Fallauswahl vollzieht sich nun ausgehend von diesen ersten Untersuchungsteilnehmer:innen. Die Forschenden bitten sie, weitere Personen zu nennen, die
auch für die Untersuchung in Frage kommen. Idealerweise erklären diese Personen
sich ebenfalls zur Teilnahme bereit, nennen ihrerseits Personen, die in Frage kommen
usw. Auf diese Weise kommt – daher der Name des Verfahrens – quasi ein Schneeball
ins Rollen, der umso größer wird, je weiter man sich bei der Suche nach Teilnehmer:innen von den ursprünglichen Teilnehmer:innen entfernt. Theoretisch beginnen die Forschenden mit einigen wenigen Personen und enden, vermittelt über die Kontakte der
Teilnehmer:innen, mit einer umfangreichen Stichprobe.

Diese Form der Fallauswahl wird in der (englischsprachigen) Literatur auch als
_Chain Sampling_ oder als _Responsive Sampling_ bezeichnet (im Folgenden auch: responsives Sampling). In diesen Benennungen kommt, stärker als im Schneeballverfahren,
zum Ausdruck, dass die Auswahl von Untersuchungseinheiten sich hier sukzessive
vollzieht und dass der Auswahlprozess stärker als bei anderen Verfahren von den Teilnehmer:innen gesteuert wird.

Das Schneeballverfahren wird in erster Linie eingesetzt, um Zugang zu schwer
erreichbaren Personengruppen zu erhalten (im Englischen auch: Hidden Populations,
also verborgene Grundgesamtheiten). Dabei kann es sich sowohl um Gruppen handeln, die von der Gesellschaft marginalisiert und oft auch stigmatisiert werden (beispielsweise Nutzer:innen von Drogen, wohnungslose Menschen) als auch um Personen, die sich selbst über ihre Differenz zum Mainstream definieren (etwa religiöse
oder extreme politische Gruppierungen), um kleine und weit verstreute Gruppen oder
um Eliten am oberen Ende der sozialen Skala. Eine besondere Form von Eliten stellen
Expert:innen dar, etwa Politiker:innen im Bundestag. Gemeinsam ist all diesen Gruppen, dass sie der Teilnahme an einer sozialwissenschaftlichen Untersuchung häufig
nicht offen gegenüberstehen, ggf. auch Misstrauen gegenüber dem universitären und
Forschungs-Betrieb an den Tag legen, und sich in der Öffentlichkeit nicht unbedingt als
Mitglied der entsprechenden Gruppe zu erkennen geben. Daraus leitet sich her, dass
sie schwer erreichbar sind. Aufrufe in den sozialen Medien oder Aushänge im Supermarkt führen hier in aller Regel nicht zum Erfolg. Personen aus diesen Gruppen können nur für eine Untersuchungsteilnahme gewonnen werden, wenn sie den Forschenden vertrauen – sei es, weil sie sie persönlich kennen oder weil eine Person, die sie
kennen und der sie vertrauen, den Kontakt hergestellt hat.


Beim Schneeballverfahren werden in einem ersten Schritt einige wenige Personen identifiziert,
die die Kriterien für eine Untersuchungsteilnahme erfüllen. Sie werden gebeten, Kontakte zu weiteren Personen zu vermitteln, die derselben Personengruppe angehören. Diese werden ebenfalls


52


2.5 Sampling Schemes: Das Vorgehen bei der konkreten Auswahl von Untersuchungseinheiten


gebeten, mögliche Teilnehmer:innen zu nennen, bis die erforderliche Stichprobengröße erreicht
ist. Das Verfahren eignet sich besonders, um Zugang zu schwer erreichbaren Personengruppen
zu erhalten.


Die resultierende Stichprobe ist in Bezug auf solche konzeptgesteuert festgelegten Kriterien homogen. Je nachdem, wie leicht oder schwer sich der Zugang zu der interessierenden Gruppe gestaltet, können Forschende innerhalb dieser Homogenität auch
eine gewisse Variabilität realisieren (etwa im Hinblick auf soziodemografische Merkmale wie Alter oder Geschlecht oder hinsichtlich weiterer Merkmale, die sich ggf. erst
im Untersuchungsverlauf induktiv gegeben). Je schwerer es Forschenden fällt, Zugang
zum Feld zu erhalten, desto schwieriger wird es, einzelne Personen gezielt im Hinblick
auf zusätzliche Variabilität auszuwählen. Daher ergibt sich aus dem Schneeballverfahren meist eine homogene Stichprobe (wie auch im folgenden Untersuchungsbeispiel).


**Untersuchungsbeispiel: Erfahrungen Schwarzer Wissenschaftlerinnen in New Mexico**


Xetura Woodley, selbst Schwarze, wollte in ihrer Dissertation dem Erleben und den Erfahrungen
Schwarzer Wissenschaftlerinnen an Universitäten in New Mexico nachgehen (Woodley & Lockhard, 2016). Zu der Zeit, als sie ihre Studie durchführte (um 2010), waren nur 1,9 Prozent der Einwohner:innen von New Mexico Schwarz, so dass die Anzahl afroamerikanischer Wissenschaftlerinnen an Universitäten voraussichtlich sehr gering war. Kriterien für die Untersuchungsteilnahme
waren, dass die Frauen sich selbst als Schwarz bezeichneten, derzeit wissenschaftlich an einer
Universität in New Mexico beschäftigt waren, mindestens 18 Jahre alt waren und entweder über
einen Master-Abschluss oder einen PhD verfügten. Woodley selbst kannte lediglich zwei Frauen,
die diese Kriterien erfüllten. Diese waren auch bereit, an der Studie teilzunehmen. Als Woodley sie
um die Namen von anderen potenziellen Teilnehmerinnen bat, verwiesen sie jedoch nur aufeinander; weitere Namen nannten sie nicht. Daraufhin versuchte Woodley es mit Aufrufen und Bitten
um die Nennung von Namen in einschlägigen Organisationen – aber auch auf diesem Weg kam sie
nicht weiter. Der eigentliche Schneeball kam erst ins Rollen, als sie ihrer Friseurin von ihrer Untersuchung erzählte und von den Schwierigkeiten, Teilnehmerinnen zu finden. Es stellte sich heraus,
dass der Frisiersalon eine Art Zentrum der Schwarzen Community war, und innerhalb dieser Community konnten Kontakte zu weiteren Teilnehmerinnen hergestellt werden. Als wichtige Quelle
erwies sich auch ein hispanischer Kollege. Er war Mitglied einer internationalen, multikulturellen
Gruppe von Wissenschaftler:innen, die sich gegenseitig im Universitätsbetrieb unterstützten. Über
diese Wege konnten insgesamt zehn Teilnehmerinnen für die Interviewstudie gewonnen werden.


53


2 Strategien absichtsvoller Fallauswahl


Schwarze Wissenschaftler:innen an Universitäten in New Mexico stellten um 2010 eine
schwer erreichbare Personengruppe dar: teilweise aufgrund ihrer geringen Anzahl,
aber auch, weil sie innerhalb des weißen Wissenschaftsbetriebs nicht unbedingt Aufmerksamkeit als Angehörige einer Minderheitengruppe auf sich ziehen wollten. Das
Schneeballverfahren als Methode der Fallauswahl erscheint daher angemessen und
zielführend. Die Studie verdeutlicht aber zugleich auch die Grenzen des Verfahrens:
Das Schneeballverfahren basiert auf sozialen Netzwerken, also darauf, dass die Mitglieder der interessierenden Personengruppe untereinander in Kontakt stehen. Das
ist hier zunächst einmal nicht der Fall: Die beiden Wissenschaftlerinnen, zu denen
Woodley einen persönlichen Kontakt hatte, standen nicht in Verbindung zu weiteren
Schwarzen Wissenschaftlerinnen an Universitäten in New Mexico.

In ihrer Reflexion der Probleme bei der Implementierung des Schneeballverfahrens betonen Woodley und Lockard, wie wichtig es ist, die Besonderheiten der Kultur zu kennen, in der die Untersuchung durchgeführt wird. Erst aus der Kenntnis der
Schwarzen Kultur ergibt sich die Bedeutung des Frisiersalons als Zentrum der Schwarzen Gemeinschaft, in der über verschiedene soziale Gruppierungen hinweg Informationen ausgetauscht werden. Auf den ersten Blick erscheint der Frisiersalon nicht unbedingt als das geeignete Umfeld, Schwarze Wissenschaftlerinnen zu identifizieren. Auf
den zweiten Blick erweisen sich die informellen Verbindungen zwischen den Frauen
jedoch als zahlreicher und tragfähiger als die innerhalb des universitären Kontexts.
Gerade weil die Anzahl der Wissenschaftlerinnen so gering ist, die die Kriterien für
die Untersuchungsteilnahme erfüllen, erweist sich außerdem der hispanische Kollege
über seine Mitgliedschaft in einer interkulturellen Organisation als wichtiger Multiplikator. Weil die Anzahl nicht-weißer Wissenschaftlerinnen in diesem Umfeld so gering
ist, findet die Vernetzung nicht innerhalb einer einzelnen ethnischen Gruppe statt,
sondern über verschiedene Ethnien – und Geschlechter – hinweg. Woodleys Untersuchung ist somit erstens ein Beispiel für die Grenzen des Schneeballverfahrens – die
Angehörigen der interessierenden Gruppe müssen untereinander vernetzt sein. Zweitens weist sie darauf hin, wie wichtig es ist, auf kreative Weise nach sozialen Bereichen
zu suchen, in denen entsprechende Verbindungen vorhanden sind, auch jenseits konventioneller Vorstellungen.

Eine weitere Grenze des Schneeballverfahrens hat mit der Bedeutung von _Vertrauen_
für die Einwilligung in die Untersuchungsteilnahme zu tun – und Vertrauen entsteht
am ehesten dort, wo Forschende und Teilnehmer:innen über einen gemeinsamen
Erfahrungshintergrund verfügen, wie dies in Woodleys Studie der Fall war. Wenn dieser gemeinsame Hintergrund jedoch fehlt, wird es schwierig, das Vertrauen herzustellen: Potenzielle Untersuchungsteilnehmer:innen begegnen den Forschenden oft mit
Misstrauen, was durch ein Machtgefälle (von den Forschenden hin zu der einschlägigen Personengruppe) noch verstärkt wird.


54


2.5 Sampling Schemes: Das Vorgehen bei der konkreten Auswahl von Untersuchungseinheiten


Das Schneeballverfahren stößt an seine Grenzen, wenn die Angehörigen der interessierenden Personengruppe nicht untereinander in Kontakt stehen. Es ist außerdem davon abhängig, dass Forschende und Teilnehmer:innen über einen gemeinsamen Erfahrungshintergrund verfügen.


Abschließend möchten wir hier noch kurz auf eine weitere Form des responsiven
Sampling eingehen. Sie betrifft die Auswahl von Teilnehmer:innen für Interviews
mit Eliten oder Expert:innen. Manchmal ist der Status als Expert:in nicht von außen
ersichtlich. In solchen Situationen kann es sinnvoll sein, dass die Forschenden erste
Teilnehmer:innen bitten, ihnen weitere einschlägige Expert:innen zu nennen. Im
nächsten Schritt werden die Vorschläge mehrerer Expert:innen verglichen, um so
die wichtigsten Personen in dem Forschungsfeld zu identifizieren. Hier besteht das
Ziel also nicht darin, die Stichprobe zu vergrößern, sondern darin, die wichtigsten
Expert:innen zu bestimmen.


2.5.2 Die Ad-hoc-Fallauswahl


Bei der _Ad-hoc_ - oder _willkürlichen Fallauswahl_ werden diejenigen Fälle oder Untersuchungseinheiten in die Stichprobe aufgenommen, die zum Zeitpunkt der Untersuchung
für die Forschenden verfügbar sind. Diese Vorgehensweise findet sich insbesondere im
Zusammenhang mit der kriterienorientierten Fallauswahl, dem Maximum-VariationSampling und dem qualitativen Stichprobenplan. Es werden vorab Kriterien und Kriterienkombinationen festgelegt, die die Untersuchungseinheiten erfüllen sollen. Dann
wird, beispielsweise über persönliche Kontakte, Aushänge oder Anzeigen in den sozialen Medien nach entsprechenden Personen gesucht; und diejenigen, die sich melden,
werden in die Untersuchung einbezogen. Absichtsvolle Fallauswahl und Ad-hoc-Auswahl schließen einander somit nicht aus, sondern werden in der Forschungspraxis
häufig kombiniert.


Bei der Ad-hoc-Fallauswahl werden alle Personen in die Untersuchung einbezogen, die vorab festgelegte Kriterien erfüllen und an der Untersuchungsteilnahme Interesse haben.


55


2 Strategien absichtsvoller Fallauswahl


**Untersuchungsbeispiel: Subjektive gesundheitsbezogene Verschwörungstheorien**


In ihrer Studie verfolgten Rosa Semle und Marius Raab (2021) das Ziel, Subjektive Theorien
zu gesundheitsbezogenen Verschwörungstheorien zu erheben. Kriterium für die Fallauswahl war,
dass die Teilnehmer:innen sich mit zentralen Aussagen gesundheitsbezogener Verschwörungstheorien identifizierten. Um dies festzustellen, verfassten die Autor:innen einen Text mit Aussagen, die im Einklang mit gängigen Verschwörungstheorien standen. Den Text legten sie potenziellen Teilnehmer:innen vor; Personen, die angaben, dass sie diesen Aussagen zustimmten, wurden
in die Studie einbezogen. Auf diese Weise konnten über Aufrufe in den Medien und persönliche
Kontakte sechs Personen für die Studie gewonnen werden. Alle Personen, die sich innerhalb von
zwei Monaten meldeten und angaben, dass sie den Aussagen zustimmten, wurden einbezogen.


2.5.3 Die Zufallsauswahl


Auch die _Zufallsauswahl_, die ja eigentlich eher in der quantitativen Forschung verankert ist, kann im Kontext einer absichtsvollen Strategie der Fallauswahl eingesetzt
werden. Die Zufallsauswahl ist dabei in eine absichtsvolle Vorgehensweise quasi eingebettet: Es werden Kriterien festgelegt, denen die Untersuchungsteilnehmer:innen
entsprechen müssen. Unter den Untersuchungseinheiten, die diese Kriterien erfüllen
und zu denen die Forschenden Zugang haben, werden die konkreten Teilnehmer:innen nach dem Zufallsprinzip ausgewählt (zur Zufallsauswahl s. o. 1.2).


**Untersuchungsbeispiel: Das Erleben von Hochsensibilität**


Unter Hochsensibilität versteht man ein Persönlichkeitsmerkmal, das durch Verarbeitungstiefe,
emotionale Intensität und Empathie, intensive und differenzierte Sinneswahrnehmung, Tendenz
zur Reizüberflutung und Bedürfnis nach Rückzug gekennzeichnet ist. Marcus Roth und Kollegen
(2023) führten eine qualitative Interviewstudie durch, in der sie untersuchten, was hochsensible
Menschen selbst unter Hochsensibilität verstehen und welche Coping-Strategien sie anwenden.
Kriterium für die Teilnahme war entsprechend, dass die potenziellen Teilnehmer:innen sich selbst
als hochsensibel definierten oder anschließend mittels Fragebogen als hochsensibel identifiziert
werden konnten. Um Teilnehmer:innen zu gewinnen, veröffentlichten die Forscher einen Aufruf
auf einer einschlägigen Webseite. Es meldeten sich 83 Interessent:innen; darunter wurden jedoch
solche Personen nicht in die weitere Auswahl einbezogen, bei denen eine psychische Erkrankung
diagnostiziert worden war oder die mit der Teilnahme die Hoffnung auf therapeutische Begleitung
verbanden. Unter den verbleibenden Personen wurden 40 per Zufall ausgewählt.


56


2.5 Sampling Schemes: Das Vorgehen bei der konkreten Auswahl von Untersuchungseinheiten


Anhand des Beispiels werden die oben benannten Schritte bei dieser Vorgehensweise
noch einmal anschaulich: Am Anfang steht die Spezifikation des Teilnahmekriteriums
der Hochsensibilität bzw. Selbstwahrnehmung als hochsensibel. Darauf folgt im zweiten Schritt die Veröffentlichung des Aufrufs auf der einschlägigen Webseite, die Erstellung einer Liste von potenziellen Teilnehmer:innen (wobei an dieser Stelle zusätzliche
Ausschlusskriterien zum Tragen kommen) sowie schließlich die zufällige Auswahl der
konkreten Teilnehmer:innen.

Das Untersuchungsbeispiel macht deutlich, dass es sich hier nicht um eine reine
Zufallsauswahl wie in der quantitativen Forschung handelt. Es steht keine Urliste aller
Mitglieder der Grundgesamtheit zur Verfügung (im Beispiel also aller hochsensiblen
Menschen in Deutschland), aus der dann per Zufall Untersuchungseinheiten ausgewählt werden. Und es geht auch nicht darum, eine repräsentative Stichprobe zu generieren, von der sich auf die Grundgesamtheit schließen lässt. Vielmehr ist die Zufallsauswahl in eine qualitative, absichtsvolle Strategie der Fallauswahl eingebettet. Weil
bei dieser Vorgehensweise Elemente einer qualitativ-absichtsvollen und einer quantitativen Form der Zufallsauswahl kombiniert werden, wird sie in der Literatur auch
als eine Form von Mixed-Methods-Sampling beschrieben (Patton, 2015), und nicht als
rein qualitative Strategie der Fallauswahl. Diese Vorgehensweise eignet sich vor allem,
wenn eine homogene Stichprobe angestrebt wird (im Beispiel: eine Stichprobe, die in
Bezug auf Hochsensibilität als homogen gelten kann). Alle Personen oder Einheiten,
die den Kriterien genügen, sind gleichermaßen für die Teilnahme an der Untersuchung
geeignet und werden im Hinblick auf die Fragestellung als äquivalent betrachtet.


Bei der Zufallsauswahl in Kombination mit der absichtsvollen Fallauswahl werden zunächst Kriterien bestimmt, die die Teilnehmer:innen erfüllen müssen. Im nächsten Schritt wird, z. B. per Aushang, nach Personen gesucht, die diese Kriterien erfüllen. Aus der Liste dieser Personen werden
dann die Teilnehmer:innen nach dem Zufallsprinzip ausgewählt.


Sowohl die Ad-hoc-Fallauswahl als auch die Zufallsauswahl werden also in qualitativen Untersuchungen eingesetzt, in denen es darum geht, zunächst mittels Spezifikation von Kriterien und Kriterienkombinationen festzulegen, wer für die Teilnahme
in Frage kommt (und zu wem die Forschenden Zugang haben). Aus dieser Personengruppe werden dann mittels einer dieser Strategien die konkreten Teilnehmer:innen
ausgewählt. Der Unterschied in der Anwendbarkeit der beiden Strategien ist folgender: Wenn überhaupt nur ein sehr kleiner Personenkreis in Frage kommt, dann ist die
Strategie der Ad-hoc-Auswahl angemessen: Alle Personen, die zur Teilnahme bereit
sind, werden in die Untersuchung einbezogen. Wenn dagegen ein größerer Personenkreis zur Verfügung steht, dann eignet sich die Strategie der Zufallsauswahl.


57


2 Strategien absichtsvoller Fallauswahl


Teilweise verschwimmt diese Unterscheidung zwischen der Ad-hoc- und der ZufallsAuswahl allerdings in der Forschungspraxis. Dies ist immer dann der Fall (wie auch in
dem oben beschriebenen Untersuchungsbeispiel), wenn in qualitativen Studien davon
die Rede ist, dass aus einem Kreis von potenziellen Teilnehmer:innen „zufällig“ die­
jenigen ausgewählt wurden, die in die Studie einbezogen wurden. Hier wird oft nicht
deutlich, ob es sich um eine echte Zufallsauswahl handelt oder um eine Zufallsauswahl
im alltagssprachlichen Sinn, d. h. eine willkürliche und somit eine Ad-hoc-Auswahl.
Um solche Unklarheiten zu vermeiden, empfiehlt es sich, die Vorgehensweise möglichst genau zu dokumentieren.


Weiterführende Literatur


Charmaz, Cathleen (2006): _Constructing grounded theory. A practical guide through_

_qualitative analysis_ (3. Aufl.). Sage.
Onwuegbuzie, Anthony J., & Leech, Nancy L. (2007). A call for qualitative power analy
ses. _Quality & Quantity_, _41_ [, 105–121. https://doi.org/10.1007/s11135-005-1098-1](https://doi.org/10.1007/s11135-005-1098-1)
Palinkas, Lawrence et al. (2015). Purposeful sampling for qualitative data collection

and analysis in mixed method implementation research. _Administration and Policy_
_in Mental Health, 42_ [(5), 533–444. https://doi.org/10.1007/s10488-013-0528-y](https://doi.org/10.1007/s10488-013-0528-y)
Patton, Michael Quinn (2015). Designing qualitative studies. In ders., _Qualitative_

_research & evaluation methods_ (4. Aufl., S. 244–326). Sage.
Schreier, Margrit (2020). Fallauswahl. In Günter Mey, & Katja Mruck (Hrsg.), _Hand-_

_buch Qualitative Forschung in der Psychologie_ (2. Aufl., Bd. 2, S. 19–40). Springer VS.


58


#### **3 Fallauswahl im Kontext qualitativer Ansätze**

In Kapitel 1 haben wir bereits darauf hingewiesen, dass die Zielsetzung einer Untersuchung in engem Zusammenhang mit der passenden Strategie der Fallauswahl steht.
Unterschiedliche Forschungsdesigns – wie etwa die Grounded-Theory-Methodologie
(GTM) oder die Fallstudie – gehen jeweils mit unterschiedlichen Zielsetzungen einher.
Daher kommen in den verschiedenen Untersuchungsanlagen auch je andere Strategien
der Fallauswahl zur Anwendung, und es liegen den Strategien teilweise unterschiedliche Überlegungen zugrunde. In diesem Kapitel betrachten wir Strategien der Fallauswahl daher im Kontext verschiedener qualitativer Untersuchungsdesigns. Dabei gehen
wir auf die GTM, die Fallstudie, die ethnografische Forschung, die Phänomenologie,
die Diskursforschung und den qualitativen Survey genauer ein.


3.1 Gegenstandsbegründete Theoriebildung


Die Gegenstandsbegründete Theoriebildung, auch Grounded-Theory-Methodologie
(GTM) genannt, gilt als eine der populärsten qualitativen Forschungsdesigns. Die GTM
wird weltweit von Forschenden z. B. in der Psychologie, Soziologie, den Bildungsund Gesundheitswissenschaften genutzt, um individuelle und kollektive Handlungen
sowie soziale und sozialpsychologische Prozesse zu untersuchen. Sie gilt überall dort
als geeignete Methodologie, wo es darum geht, ein tiefgreifendes Verständnis eines
spezifischen Phänomens zu erzielen und eigene Erfahrungen, Gedanken und Emotionen in den wissenschaftlichen Erkenntnisprozess einzubeziehen (Strauss & Corbin,
1998). Charakteristisch sind hierfür sehr offene und breite Fragestellungen, die Forschenden eine größtmögliche Flexibilität zur Untersuchung des Forschungsphänomens eröffnen. Ziel ist es, eine Theorie über das zu untersuchende Phänomen unmittelbar aus den Daten abzuleiten ( _Grounded Theory_, also eine Theorie, die in den Daten
begründet ist).

Historisch gesehen ist die GTM ein vergleichsweise neuer Forschungsstil, der aus
der Zusammenarbeit von Barney Glaser und Anselm Strauss hervorging. Sie entwickelten den Ansatz im Rahmen einer Studie zur Interaktion von Pflegepersonal mit
unheilbar kranken Patienten in den USA (Glaser & Strauss, 1967). Dabei grenzten sie
sich bewusst von hypothesentestenden Verfahren der empirischen Sozialforschung ab.
Der Grundgedanke bestand darin, Forschenden die Möglichkeit zu eröffnen, ihre Forschungen ohne vorgefasste Theorien und Konzepte im jeweiligen Interessensgebiet
durchführen zu können. Heute, nach über 50 Jahren, gibt es nicht mehr nur eine GTM,
sondern eine Vielzahl von GTM-bezogenen Ansätzen. Diese positionieren sich kontro

59


3 Fallauswahl im Kontext qualitativer Ansätze


vers, insbesondere mit Blick auf die Frage, wie sich vorgängiges Wissen und Vorannahmen auf die Theoriebildung auswirken (Kelle, 2005; Strübing, 2014; einen Überblick
gibt Morse, 2009, S. 17 _)_ . Wir stützen uns im Folgenden insbesondere auf die von Charmaz (2006) entwickelte _konstruktivistische GTM_ sowie den von Breuer (Breuer et al.,
2017) entwickelten Ansatz der _reflexiven GTM_ .


Abb. 3.1: Die Entstehungsgeschichte der Grounded-Theory-Methodologie
(eigene Darstellung, nach Morse 2009, S. 17)


Das Vorgehen der GTM ist gegenstandsbezogen und ermöglicht es Forschenden, die
methodologischen Prämissen nicht als starre Vorschriften zu verstehen, sondern als
flexible Richtlinien, die je nach zugrundeliegendem Phänomen und damit verbundener Forschungsfrage angepasst werden müssen. Ein solches exploratives Forschungsvorgehen eignet sich besonders für Forschungsfelder, über die bisher wenig Forschung
vorliegt und in denen Forschende somit auf wenig theoretische Grundlagen und wenig
systematisiertes Vorwissen zurückgreifen können.

Typischerweise beginnt ein GTM-Forschungsprozess mit einer Fragestellung, die
zwar das Phänomen der Untersuchung bestimmt, jedoch vorab keine weitere konzeptionelle Festlegung vornimmt. Der Fokus der Forschungsfragen liegt häufig auf den
Handlungen von Menschen, den Bedeutungen, die diese den Handlungen zuschreiben, sowie den Prozessen und Umständen, in die diese Handlungen eingewoben sind
(Thornberg & Charmaz, 2014). Die GTM-Forschungsprozesse bauen in wechselseitiger Bezugnahme aufeinander auf. Forschende können (und müssen) im Rahmen einer
GTM-Studie alle Forschungsprozesse ihrem kontinuierlich wachsenden Verständnis
über den Forschungsgegenstand anpassen. Dadurch kann sichergestellt werden, dass


60


3.1 Gegenstandsbegründete Theoriebildung


die zu entwickelnde Theorie auch unmittelbar in den Daten verankert ist und nicht
vornehmlich aus Vorannahmen resultiert.


Abb. 3.2: Der iterative Forschungsprozess der GTM
(eigene Darstellung, nach Mey & Mruck 2009, S. 111)


Diese offene, flexible Vorgehensweise gilt auch für die Fallauswahl in der GTM, das
_Theoretical Sampling_ (s. o. 2.3). Daher werden


1. die Stichproben nicht vorab bestimmt
2. die Kriterien zur Fallauswahl kontinuierlich parallel zur Datenerhebung und -analyse

(weiter) entwickelt
3. Fallauswahl, Datenerhebung und -analyse in wechselseitiger Bezugnahme zuein
ander aufgebaut.


61


3 Fallauswahl im Kontext qualitativer Ansätze


Die Fallauswahl in der Grounded Theory wird nach dem Prinzip des Theoretical Sampling umgesetzt, so dass die Stichprobe nicht vorab festgelegt wird. Die Fallauswahl entwickelt sich entsprechend in direkter Bezugnahme zur Datenerhebung und -analyse, so dass Forschende die Kriterien
zur Fallauswahl in Relation zu den anderen Verfahrensgrundsätzen flexibel (weiter-)entwickeln.


Im Folgenden stellen wir die zentralen Verfahrensgrundsätze der GTM vor: _Theoreti-_
_sche Sensibilität, Kontrastives Vorgehen, Kodieren, Memos schreiben und die Theoretische_
_Sättigung._ Diese Verfahrensgrundsätze entfalten sich innerhalb einer iterativ-zirkulären Arbeitsweise in wechselseitiger Bezugnahme mit dem Theoretical Sampling.


3.1.1 Theoretische Sensibilität


Die _Theoretische Sensibilität_ schärft das Bewusstsein der Forschenden für ihre eigene
Position und Stellung innerhalb des Forschungsprozesses, so dass sie sensibler für
Nuancen, Widersprüche und neue Perspektiven in ihrem Datenmaterial werden. Der
Grundsatz der Theoretischen Sensibilität verweist Forschende darauf, dass das Ergebnis einer GTM-Studie, die _Grounded Theory_, nicht durch die regelgetreue Anwendung
von Verfahrensschritten entsteht. Vielmehr nehmen Forschende im Forschungsprozess
die jeweiligen Geschichten des Forschungsfeldes und der beteiligten Personen auf und
(re-)präsentieren diese. Daher liegt es in deren Verantwortung, transparent darzulegen, wie ihre Vorannahmen, ihr theoretischer Hintergrund sowie ihre soziokulturellen
Prägungen (z. B. Geschlecht, ethnische Identität oder biografische Erfahrungen) den
Forschungsprozess und die darin entwickelten Erkenntnisse beeinflusst haben. Forschungsberichte sollen Anhaltspunkte geben, auf welcher Grundlage Forschende Entscheidungen getroffen haben und welche Perspektiven, Fragestellungen und Stimmen
sie in die Datenerhebung und -analyse haben einfließen lassen. Der Hintergrund der
Forschenden beeinflusst somit auch die Fallauswahl, vom Jumping-off Point, über die
relationale Phase, bis hin zur Entscheidung für ein Schlüsselmerkmal (s. o. 2.3).


Die Theoretische Sensibilität lenkt die perspektivische Ausrichtung von Forschenden. Damit beeinflusst sie nicht nur den analytischen Fokus, sondern auch, welche Fälle als relevant für die Weiterentwicklung der Theorie erachtet werden und welche Zugänge sich Forschenden innerhalb des
Forschungsfeldes erschließen oder auch verschlossen bleiben.


Der Einfluss von Forschenden auf die Fallauswahl wird am Beispiel der Dissertation
von Weydmann (2019) deutlich, in der sie Konzepte und Zugangsweisen von Frauen


62


3.1 Gegenstandsbegründete Theoriebildung


zur Nutzung traditioneller und komplementärer Medizin im urbanen Indonesien
untersuchte. Ihr Hintergrund als weiße Europäerin im (post-)kolonialen Indonesien
erwies sich in ihrer Grounded-Theory-Studie als entscheidender Faktor für den Zugang
zum Forschungsfeld und prägte damit die Fallauswahl maßgeblich. Nach ersten Jumping Off-Interviews mit Frauen, die in diesem Bereich arbeiten oder aufgrund biografischer Nähe zur Forscherin eine große Offenheit zum Austausch zeigten, ereignete
sich eine Schlüsselsituation, die den Forschungshorizont und damit die Fallauswahl
neu justierte: Nach einem langen und vertraulichen Interview mit einer langjährigen
Bekannten stellte Weydmann durch Zufall fest, dass die Informandin ihr – trotz Nachfrage – die regelmäßige Konsultation bei einem magischen Heiler vorenthalten hatte
(Details in Weydmann, 2024). In einer folgenden Reflexion mit einer lokalen Co-Forschenden, erklärte diese das Aussparen von Erzählungen über Konsultationen von
magischen Heilern mit folgenden Worten: „Nicole, no problem. Maybe she didn’t want
to tell because you are West“. Diese Einordnung der Forschungsinteraktionen in den
Kontext von kultureller Fremdheit veränderte für Weydmann auch den weiteren Horizont der Fallauswahl.

Die Einordnung des Forschungszugangs als „Doing Being Western“ (2024, S. 282ff.)
hatte zur Folge, dass Weydmann diesen spezifischen Zugang zum Forschungsfeld in der
weiteren Fallauswahl bewusst nutzte. Im Folgenden kontrastierte sie die einbezogenen
Fälle anhand ihrer eigenen Verortung im Kontinuum zwischen _westlicher_ und _javani-_
_scher_ Identitätszugehörigkeit. Diese Differenzierung der Heilungszugänge erweiterte
ihren Forschungsfokus, so dass neben den verschiedenen Zugriffen auf das indonesische Gesundheitssystem auch die Dynamiken der Forschungsbeziehungen und der
Identitäts- und Rollenaushandlungen der Forschungsbeteiligten im Fokus standen.


3.1.2 Kontrastives Vorgehen


Das _Kontrastive Vorgehen_ ermöglicht es Forschenden, ausgehend von zunächst spezifisch herausgearbeiteten Merkmalen einzelner Fälle, Ähnlichkeiten und Unterschiede
zwischen den Fällen zu entdecken. Forschende folgen den Hinweisen aus dem Kontrastiven Vorgehen in alle Richtungen.

Das Kontrastive Vorgehen wird durch _fortwährende Vergleiche_ geleitet, in denen
Forschende die Bezüge zwischen den einzelnen Daten und Fällen durch gemeinsame
Kategorien sichtbar machen. Verglichen werden im Rahmen des Theoretical Sampling
nicht nur Codes und Kategorien, sondern auch Fälle. Zu Beginn tragen die Vergleiche
dazu bei, spezifische Charakteristika von einzelnen Fällen herauszuarbeiten. Im weiteren Verlauf der Forschung dienen die Vergleiche zunehmend dazu, die Fallauswahl
anzuleiten, um Beziehungen und Kontrastierungen zwischen den Daten sichtbar zu
machen. Davon ausgehend werden die Codes und Kategorien verfeinert. Dies bildet


63


3 Fallauswahl im Kontext qualitativer Ansätze


wiederum die Grundlage dafür, die Kategorien für das Theoretical Sampling immer
wieder neu zu überprüfen und ebenfalls kontrastierend weiterzuentwickeln.


Auf Grundlage des Kontrastiven Vorgehens vergleichen Forschende ihre Daten. Diese Vergleiche
leiten die Fallauswahl, um durch die Auswahl geeigneter nächster Fälle die Beziehungen und Kontrastierungen zwischen den Daten sichtbar zu machen.


In Abschnitt 2.3 haben wir dieses Vorgehen anhand der Studie von Butler et al. (2018)
verdeutlicht. Auf der Grundlage von ersten Interviews mit Eltern, deren Kind auf
einer pädiatrischen Intensivstation verstorben war, wurde deutlich, dass die Eltern
sich während des Aufenthalts auf der Intensivstation durch das Gesundheitspersonal
unterstützt, jedoch nach dem Tod ihres Kindes im Stich gelassen fühlten. Davon ausgehend entschieden die Forscherinnen, Eltern von Kindern auf zwei weiteren pädiatrischen Intensivstationen einzubeziehen, die ein vergleichbares Maß an stationärer Kinderbetreuung, jedoch optional zusätzlich einen Trauerbegleitungsdienst für
die Zeit nach dem Krankenhausaufenthalt boten. Das kontrastive Vorgehen im Fallvergleich ermöglichte es den Forscherinnen, unterschiedliche Erfahrungsräume von
Eltern hinsichtlich des Merkmals der Unterstützung durch das Gesundheitspersonal
einzubeziehen,

Das Untersuchungsbeispiel verdeutlicht den engen Zusammenhang zwischen
dem Theoretical Sampling einerseits und der Datenerhebung und -auswertung in der
GTM andererseits. Forschende orientieren sich an den Hinweisen aus den kontrastiven Vergleichen, so dass die Auswahl weiterer Fälle unmittelbar im Zusammenhang
mit den Entscheidungen der Forschenden darüber steht, welche Merkmale und Muster im weiteren Verlauf der Forschung für die Beantwortung der Forschungsfrage als
relevant erachtet werden. Forschende entscheiden mit neu hinzukommenden Daten
immer wieder aufs Neue, welche Aspekte im nächsten Schritt die Fallauswahl lenken. Wie im Untersuchungsbeispiel verdeutlicht, werden die Fälle jeweils so ausgewählt, dass sie einander entweder möglichst ähnlich sind (die ersten fünf Interviews
mit Eltern) oder sich im Hinblick auf ein ausgewähltes Merkmal unterscheiden (die
Einbeziehung von Eltern, die zusätzlich eine Trauerbegleitung genutzt haben). Die
Fallauswahl folgt hier den Prinzipien der minimalen und maximalen Kontraste. Das
Kontrastive Vorgehen steht ebenfalls in engem Zusammenhang mit den Möglichkeiten der Verallgemeinerung der Theorie (s. u. 5.4).


64


3.1 Gegenstandsbegründete Theoriebildung


3.1.3 Kodieren


Durch das Kodieren identifizieren Forschende jene Kategorien, die in einem nächsten
gezielten kontrastiven Schritt des Vergleichs dazu beitragen können, die bisher entwickelten Kategorien und Codes zu vertiefen, bestätigen oder erweitern.

Das Kodieren ist die Methode der Datenanalyse in der GTM. Beim Kodieren werden Datensegmente mit sogenannten Etiketten („labels“) versehen, um diese zu kategorisieren, zusammenzufassen und zu erklären (Charmaz, 2006, S. 42). Dieser Prozess beginnt unmittelbar mit der ersten Datenerhebung und begleitet den gesamten
Forschungsverlauf. Forschende durchlaufen dabei drei zentrale Kodierphasen: _Offenes_
_Kodieren, Axiales Kodieren_ und _Selektives Kodieren_ . Ebenso wie das Theoretical Sampling entwickeln Forschende auch das Kodieren nicht in einem linearen Prozess, sodass
sich die Arbeitsschritte flexibel zwischen den Phasen des Kodierens hin und her bewegen, um währenddessen für verschiedene Datenhorizonte sensibel zu werden.

Idealerweise werden die Ergebnisse der Analysearbeit immer wieder im Team oder
im Rahmen von Interpretations- und Werkstattgruppen diskutiert, um Deutungen und
offene Interpretationen von Daten multiperspektivisch zu reflektieren (Albrecht-Ross
et al., 2016).

Im Folgenden geben wir einen kurzen Überblick über die Kodierschritte der GTM:


**Offenes Kodieren**
Unmittelbar nach der Erhebung der ersten Daten (erste Phase: Selektive Fallauswahl;
s. o. 2.3) gehen Forschende das Datenmaterial zunächst Zeile für Zeile durch, um erste
Codes (Etiketten) und zusammenfassende Kategorien für Datensegmente zu entwickeln. Forschende orientieren sich in der Vergabe der Etiketten eng an den Formulierungen der Teilnehmer:innen (sogenannte _Invivo-Codes_ ), um sicherzustellen, dass
die entstehenden Codes und Kategorien unmittelbar aus den Daten und nicht aus den
Vorannahmen der Forschenden hervorgehen. Dem Prinzip des Kontrastiven Vergleichs
folgend, erkunden Forschende das Datenmaterial tiefgründig und reflektieren die dargestellten Handlungen und Prozesse kritisch. Sie folgen hierbei Impulsen und Mustern
in alle Richtungen. Dies gilt auch für die Fallauswahl (vgl. die zweite Phase der Relationalen Fallauswahl; s. o. 2.3).


**Axiales Kodieren**
Beim Axialen Kodieren vertiefen Forschende die Codes und Kategorien, die sie beim
Offenen Kodieren entwickelt haben. Hierzu wählen sie jene Kategorien aus, die ihnen
analytisch als sinnvoll erscheinen, um die Beziehungen innerhalb eines Falls oder fallübergreifende Relationen aufzuzeigen. Die Relevanz einer Kategorie ergibt sich jedoch
nicht aus der Häufigkeit, mit der diese in den Daten vorkommt, sondern aus ihrem
analytischen Potenzial (s. u. 4.1). Wenn eine Kategorie mit sehr vielen anderen Codes
und Kategorien in direkter Verbindung steht, dann ist dies ein Hinweis darauf, dass ihr


65


3 Fallauswahl im Kontext qualitativer Ansätze


zentrale Bedeutung zukommt. Eine solch zentrale Kategorie wird auch _Kernkategorie_
genannt.

Die Erkundung der Beziehungen der Kernkategorie(n) zu anderen Kategorien und
Codes leitet auch die weitere Fallauswahl sowie die Datenerhebung und -analyse.
Sobald Forschende im Rahmen des axialen Kodierens beginnen, eine vorläufige Kernkategorie zu entwickeln, die das zentrale Phänomen zu erklären versucht, richten sie
ihre Fallauswahl auf die Erkundung dieser Kernkategorie aus. Die nachfolgende Auswahl von Fällen wird dann so gestaltet, dass sie Informationen über die Kernkategorie,
ihre Ausprägungen sowie ihr Verhältnis zu anderen Kategorien liefert. Der Forschungsprozess richtet sich somit darauf aus, die größtmögliche Vielfalt an Ausprägungen der
Kernkategorie aufzuzeigen und diese Kontrastierungen auch in bereits analysierten
Fällen nachzuzeichnen. In unserem Forschungsbeispiel erkannten Butler et al. (2018),
dass ihre vorläufige Kernkategorie _Unterstützung durch das Gesundheitspersonal_ durch
weitere Einblicke in die Perspektive von Eltern kontrastiert werden musste, die eine längerfristige Betreuung nach dem Tod ihres Kindes erhielten. Aus diesem Grund wählten
sie gezielt neue Standorte aus, die eine solche Nachbetreuung anboten, um dadurch die
Dimensionen von Unterstützung innerhalb der Kernkategorie zu erforschen.


Die Erkundung der Beziehung(en) der Kernkategorien leitet die weitere Fallauswahl. Sie wird so
gestaltet, dass weitere Fälle mehr Informationen über die Kernkategorie, ihre Dimensionen und
ihre Verbindungen zu anderen Kategorien liefern.


Im Vergleich zu den eng am Wortlaut entwickelten _Invivo-Codes_ des offenen Kodierens
sind die Formulierungen der Kernkategorien typischerweise deutlich abstrakter.


**Selektives Kodieren**
Dieser letzte Analyseschritt wird als _Selektives_ oder auch als _Theoretisches Kodie-_
_ren_ bezeichnet und dient dazu, die ausgearbeitete(n) Kernkategorie(n) mit über das
eigene Forschungsfeld hinausgehenden Ideen und Perspektiven zu verknüpfen. Forschende nutzen hierfür die Dimensionen und Bezüge ihrer Kernkategorie, um diese in
textlich nachvollziehbarer Form in Verbindung mit anderen theoretischen Rahmungen
zu bringen.

Forschende schaffen so möglichst vielfältige theoretische und disziplinäre Anknüpfungspunkte, um Bezüge zu etablierten Modellen, Theorien oder Konzepten herzustellen. Das Ziel ist es, dass Forschende am Ende eine kohärente und nachvollziehbare
Darstellungsform ihrer analytischen Geschichte finden (Charmaz, 2006, S. 63).


66


3.1 Gegenstandsbegründete Theoriebildung


3.1.4 Memos Schreiben


Durch das kontrastive Vergleichen von Daten und das parallele Vorantreiben von Fallauswahl, Datenerhebung und Kodierung generieren Forschende aus ihren Daten heraus fortlaufend neue Fragen. Und aus der Interaktion mit ihren Daten entwickeln sie
ebenfalls vorläufige Antworten, Ideen und Assoziationen zu diesen Fragen, die sie mit
Codes und Kategorien etikettieren und in Notizen ausführlich dokumentieren. Diese
Notizen werden _Memos_ genannt und sind ein zentrales Reflexionswerkzeug. Ziel der
Memos ist es, Forschende im Sinne einer theoretischen Sensibilität direkt von Beginn
an zu veranlassen, ihre vorläufigen Überlegungen, konzeptionellen Ideen und Kodierungen niederzuschreiben. Auf diesem Wege werden diese vorläufigen Ideen von relevanten Merkmalen für die Fallauswahl und somit auch die Theoriebildung nutzbar.
Die schriftliche Dokumentation auch früher Überlegungen hilft Forschenden dabei,
ihren Arbeitsprozess nachvollziehbar zu machen sowie ihre Kodierungen und Kategorienbildungen zu reflektieren und kritisch zu hinterfragen.


Memos dokumentieren die analytischen Überlegungen und Fragestellungen, die das Theoretical
Sampling leiten. Das Schreiben von Memos ist somit ein zentrales Werkzeug, um die theoretische
Relevanz für die Auswahl neuer Fälle im Theoretical Sampling zu entwickeln und zu begründen.


3.1.5 Theoretische Sättigung


Die _Theoretische Sättigung_ ist ein charakteristischer Verfahrensgrundsatz der GTM. Sie
verweist auf den Zeitpunkt im Forschungsprozess, an dem weitere Datenerhebungen
keine relevanten neuen Erkenntnisse liefern. Mit anderen Worten: Theoretische Sättigung bedeutet, dass die Konzepte der entstehenden Theorie hinreichend entwickelt und
ihre Eigenschaften sowie die Beziehungen zwischen ihnen ausreichend erfasst sind.

In forschungspraktischer Hinsicht ist es faktisch jedoch nicht möglich, die zur Verfügung stehenden Daten in allen denkbaren Dimensionen theoretisch zu sättigen.
Daher wird eine Sättigung nur in den Dimensionen oder Hinsichten angestrebt, die
die Forschenden als relevant für die Entwicklung der spezifischen Theorie erachten.
Es obliegt somit den Forschenden, pragmatische Entscheidungen darüber zu treffen,
anhand welcher (Kern)Kategorien und in welcher Hinsicht ein weiteres Sampling
keine neuen Einsichten erwarten lässt. Das Erreichen von Theoretischer Sättigung ist
somit unmittelbar an die Entscheidung der Forschenden geknüpft. Diese entscheiden
auf der Grundlage ihrer intensiven Auseinandersetzung mit den Daten, der kontinuierlichen (Weiter)Entwicklung der Kernkategorien sowie der systematischen und reflektierten Weiterentwicklung der Merkmalsräume im Rahmen des Theoretical Samp

67


3 Fallauswahl im Kontext qualitativer Ansätze


lings. Die Theoretische Sättigung ist somit kein starres Abbruchkriterium, sondern ein
flexibler und interpretativer Indikator. Sie zeigt an, dass die entwickelte Theorie eine
ausreichende Tiefe und Reichhaltigkeit erreicht hat, um das untersuchte Phänomen
angemessen zu erklären.


Theoretische Sättigung bedeutet, dass die Konzepte der entstehenden Theorie hinreichend entwickelt und ihre Eigenschaften sowie die Beziehungen zwischen ihnen ausreichend erfasst sind.
Sie stellt jedoch lediglich einen Indikator für theoretische Tiefe dar, kein starres und absolutes
Abbruchkriterium.


Anhand unseres Untersuchungsbeispiels über die Erfahrungen von Eltern mit dem
Tod ihres Kindes von Butler et al. (2018; s. u. 2.3) veranschaulichen wir das Prinzip
der Theoretischen Sättigung: Die Forscherinnen entwickelten in der Analyse ihrer ersten Interviews ein vorläufiges Verständnis über die elterliche Rolle während des Sterbeprozesses eines Kindes. Die Daten stammten aus Interviews mit Eltern von kleinen
oder stark entwicklungsverzögerten Kindern; die elterliche Rolle umfasste hier für die
Eltern selbstverständlich auch die körperliche Pflege ihrer Kinder. Die Forscherinnen
prüften ihre vorläufigen Annahmen über die elterliche Rolle im Rahmen eines Interviews mit einer Mutter eines älteren, zuvor gesunden und unabhängigen Teenagers.
Aus dem Interview ging hervor, dass die körperliche Pflege im Sterbeprozess eines Kindes nicht notwendigerweise ein zentraler Bestandteil der elterlichen Rolle war, da die
Mutter die Intimsphäre ihres Teenagers auch in dieser vulnerablen Situation weiterhin schützen wollte. Dies ermöglichte es den Forscherinnen, die Kategorie der elterlichen Rolle auszudifferenzieren und die Variation in der elterlichen Rolle direkt mit
dem Gesundheitszustand und dem Alter des Kindes in Zusammenhang zu bringen.

Das Beispiel macht deutlich, dass die Theoretische Sättigung auf der Verfahrensebene eng mit dem Kontrastiven Vorgehen durch fortwährendes Vergleichen und dem
Theoretical Sampling verbunden ist: Durch das Kontrastive Vorgehen werden Forschende angehalten, ihre Daten systematisch auf Ähnlichkeiten und Unterschiede
hin zu vergleichen, um so die Eigenschaften und Dimensionen der Kategorien (weiter) zu entwickeln. Die Ähnlichkeiten und Unterschiede sind wiederum leitend für das
Theoretical Sampling und die daraus resultierende Fallauswahl. Das enge Ineinandergreifen von theoretischer Fallauswahl, kontrastiver Datenanalyse und Theoretischer
Sättigung ist allerdings nur anwendbar, wenn die Fallauswahl zumindest teilweise
datengesteuert erfolgt (s. u. 4.1).

Die transparente Darstellung dieser eng verzahnten Verfahrensgrundsätze schafft
die Grundlage dafür, dass Forschende die Angemessenheit der Stichprobengröße und
die Reichweite der theoretischen Verallgemeinerbarkeit nachvollziehbar aufzeigen
können (s. u. 5.4). Erklärtes Ziel von Grounded-Theory-Studien ist es, eine theoreti

68


3.2 Fallstudie


sche Erklärung für das untersuchte Phänomen zu entwickeln, die auch auf ähnliche
Kontexte und Fälle übertragbar sein soll. Eine Verallgemeinerung auf eine statistisch
definierte Grundgesamtheit wird nicht angestrebt.

Als Faustregel für die Stichprobengröße kann gelten, dass eine heterogene Grundgesamtheit die Komplexität der zu entwickelnden Theorie erhöht. Dadurch kann es
notwendig werden, eine größere Fallzahl einzubeziehen, um das Spektrum der relevanten Phänomene in den Kernkategorien und ihren Dimensionen zu erfassen. Umgekehrt gilt jedoch auch: Je höher die Informationshaltigkeit der einzelnen Fälle, desto
geringer ist die erforderliche Anzahl der Fälle.

Die transparente Darstellung des Ineinandergreifens der GTM-Forschungsprozesse
und die detaillierte Erläuterung der eigenen Überlegungen und Entscheidungen bilden die Grundlage dafür, eine Theoretische Sättigung der relevanten Dimensionen
einer Grounded Theory glaubwürdig und nachvollziehbar darzustellen.


3.2 Fallstudie


Bei der Fallstudie handelt es sich um ein komplexes Design, das auf ganz unterschiedliche Weise realisiert werden kann. Eine Fallstudie kann beschreibend oder erklärend
angelegt sein, als Einzelfallstudie oder als multiple Fallstudie, holistisch oder eingebettet (Yin, 2017, S. 61ff.). Und je nach Anlage der Untersuchung sind bei der Fallauswahl
auch jeweils unterschiedliche Gesichtspunkte zu beachten. Da wir im Rahmen dieses
Überblicksbandes der Fallstudie nicht in allen Hinsichten gerecht werden können, konzentrieren wir uns auf Überlegungen zur Fallauswahl bei der Einzelfallstudie und der
multiplen Fallstudie. Fälle können dabei übrigens ganz unterschiedlich geartet sein:
Länder, Organisationen, Events, Personen und vieles mehr können Fälle darstellen.

Bei aller Unterschiedlichkeit der verschiedenen Formen dieses Untersuchungsdesigns gibt es jedoch zwei Aspekte, die bei der Fallauswahl im Rahmen der Fallstudie zu
beachten sind, unabhängig vom konkreten Design.

Erstens erfolgt die Auswahl von Fällen oder Untersuchungseinheiten bei der Fallstudie grundsätzlich auf mehreren Ebenen. Es ist charakteristisch für dieses _Mehrebenen-_
_design_, dass einige wenige Fälle unter Verwendung mehrerer Datenerhebungsmethoden und Datenarten in der Tiefe betrachtet werden, beispielsweise unter Nutzung von
Interviews, Beobachtungen und Dokumenten (s. o. 1.3). Entsprechend geht es bei der
Fallstudie nicht nur um die Auswahl der Fälle selbst und deren Begründung, sondern
ebenso um die Auswahl von Untersuchungseinheiten innerhalb des Falles. Wenn eine
Fallstudie beispielsweise an mehreren Schulen durchgeführt wird, dann ist sowohl zu
begründen, weshalb gerade diese Schulen ausgewählt wurden, als auch welche Klassen innerhalb der Schule, welche Unterrichtsfächer, Schüler:innen oder Lehrkräfte
in die Studie einbezogen wurden. Im Folgenden konzentrieren wir uns auf die erste
Ebene der Auswahl der Fälle selbst. Für weitere Ebenen gelten die Ausführungen zur


69


3 Fallauswahl im Kontext qualitativer Ansätze


Fallauswahl bei verschiedenen Datenarten, beispielsweise zum Interview oder zu
Dokumenten (s. u. Kap. 4).

Zweitens ist für die Fallstudie charakteristisch, dass ganz gezielt bestimmte Arten
von Fällen ausgewählt werden (s. o. 2.4). Für das Untersuchungsdesign bedeutet dies,
dass die Arten der Fälle jeweils schon vor Untersuchungsbeginn festgelegt werden. Die
Stichprobe entsteht also nicht, wie bei der Gegenstandsbezogenen Theoriebildung, im
Untersuchungsverlauf, sondern es handelt sich um eine _konzeptgesteuerte_ Form der
Fallauswahl. Welche Erwägungen dabei in einer konkreten Untersuchung leitend sind,
hängt von der Fragestellung und vom Untersuchungsdesign ab. Dies gilt nur auf der
ersten Ebene der Fallauswahl, also auf der Ebene der Fälle selbst. Auf den darunter liegenden Ebenen, etwa bei der Auswahl von Interviewpartner:innen, können beliebige
andere Formen der Fallauswahl zur Anwendung kommen.


Es gilt für alle Formen der Fallstudie:


  - Die Fallauswahl erfolgt auf mehreren Ebenen.

  - Auf der ersten Ebene (Auswahl der Fälle selbst) werden Fälle konzeptgesteuert ausgewählt.


Fallstudien können, wie erwähnt, im Rahmen verschiedener Designs realisiert werden, unter anderem als Einzelfallstudie oder als multiple Fallstudie. Bei der _Einzelfall-_
_studie_ wird, wie der Name schon sagt, lediglich ein Fall in die Untersuchung einbezogen. Unter Gesichtspunkten der Fallauswahl werden verschiedene Arten von Fällen
unterschieden, die aus je verschiedenen Gründen von Interesse sind. Dies sind insbesondere der typische, der intensive, der extreme, der intrinsische und der kritische Fall
(für Informationen zu diesen verschiedenen Arten von Fällen s. o. 2.4).

Bei der Durchführung einer Einzelfallstudie muss man sich zunächst – wie bei empirischen Untersuchungen allgemein – über das Ziel der Studie klar werden und darüber,
welche Art von Fall am besten geeignet ist, dieses Ziel zu erreichen. Zweitens benötigt
man Informationen über Verteilung und Ausprägung relevanter Merkmale des interessierenden Phänomens in der Grundgesamtheit. Denn ein Fall ist nicht per se typisch
oder extrem. Um welche Art von Fall es sich konkret handelt, lässt sich vielmehr nur
vor dem Hintergrund von Informationen über die Grundgesamtheit sagen. Um eine
Einzelfallstudie durchzuführen, braucht man also Hintergrundinformationen, sei
es auf der Grundlage von Ergebnissen früherer Untersuchungen oder aufgrund von
Daten, die man selbst erhebt. Erst auf dieser Basis ist es im dritten Schritt möglich,
einen geeigneten Fall auszuwählen. Dabei spielen dann nicht zuletzt auch Fragen der
Zugänglichkeit und der Bereitschaft zur Teilnahme eine Rolle.


70


3.2 Fallstudie


Vorgehen bei der Fallauswahl für die Einzelfallstudie:


  - Festlegen des Untersuchungsziels und der Art des Falls (typisch, extrem usw.)

  - Identifikation geeigneter Fälle auf der Grundlage von Hintergrundinformationen zur Verteilung

relevanter Merkmale in der Grundgesamtheit

  - Auswahl eines konkreten Falls.


**Untersuchungsbeispiel Middletown**


Eine klassische Einzelfallstudie mit einem typischen Fall stellt die soziologische Untersuchung dar,
die Robert und Helen Mirrell Lynd in den USA in den frühen 1920er Jahren durchgeführt haben
(1929). Ihr Ziel war es, das Leben in einer amerikanischen Kleinstadt zu Beginn der Industrialisierung zu beschreiben, etwa im Hinblick auf die Rolle der Arbeit, das häusliche Leben, Freizeitaktivitäten usw. In ihrem Buch legen sie ausführlich dar, nach welchen Gesichtspunkten sie Middletown
ausgewählt haben (das später als die Kleinstadt Muncie identifiziert wurde). Es sollte sich u. a.
um eine Stadt mit 25.000 – 50.000 Einwohnern handeln, möglichst im mittleren Westen; sie sollte
nicht von einer einzelnen Industrie oder Firma dominiert werden; es sollte eine lebendige kulturelle Szene existieren; und die Stadt sollte keine ausgeprägten sozialen Probleme aufweisen. Die
Gründe für diese Kriterien und weshalb sie für eine amerikanische Kleinstadt zum Zeitpunkt der
Untersuchung als typisch gelten können, beschreiben Robert und Helen Mirrell Lynd ausführlich
in den ersten Kapiteln ihrer Studie.


Bei der _multiplen Fallstudie_ werden ebenfalls ganz bestimmte Arten von Fällen unter
Berücksichtigung von Hintergrundinformationen konzeptgesteuert ausgewählt.
Anders als bei der Einzelfallstudie ist hier allerdings zusätzlich die Beziehung der Fälle
untereinander zu berücksichtigen bzw. die Frage, wie ähnlich die Fälle einander in
Bezug auf relevante Merkmale sind. Wenn die Fälle einander ähnlich sind, dann handelt es sich um eine homogene Stichprobe; bei unterschiedlichen Fällen liegt eine heterogene Stichprobe vor.

_Multiple Fallstudien mit homogener Stichprobe_ sind meist _beschreibend_ angelegt. Sie
eignen sich besonders, um Typisches zu beschreiben. So hätten Robert und Helen Mirrell Lynd beispielsweise entscheiden können, nicht nur eine, sondern zwei oder drei
Städte in ihre Untersuchung über das Leben in einer amerikanischen Kleinstadt zu
Beginn der Industrialisierung einzubeziehen, die sämtlich den von ihnen erarbeiteten
Kriterien entsprachen. Wenn ihre Ergebnisse für alle zwei oder drei Städte vergleichbar ausgefallen wären, hätte dies ihre Befunde gestärkt. Denn wenn die Ergebnisse nur
auf einem einzigen Fall basieren, kann man letztlich nie ausschließen, dass darin auch
Besonderheiten dieses einen Falls einfließen, die für andere Fälle so nicht gelten wür

71


3 Fallauswahl im Kontext qualitativer Ansätze


den. Befunde, die über mehrere ähnliche Fälle hinweg gelten, sind also immer valider
als solche, die nur an Hand eines Einzelfalls erhoben werden.

Zugleich wird an diesem Beispiel deutlich, dass Ähnlichkeit zwischen Fällen eine
_relative_ und keine absolute Größe ist. Wenn das Ehepaar Lynd drei verschiedene Kleinstädte einbezogen hätte, die alle die vorab festgelegten Kriterien erfüllten (sich in der
Hinsicht also ähnlich wären), wären sie im Hinblick auf andere Merkmale doch notwendig unterschiedlich, beispielsweise in Bezug auf den Bundesstaat oder die Arten der
Industrien, die sich dort angesiedelt haben (und in diesen Hinsichten daher unähnlich).

Bei der _multiplen Fallstudie mit einer heterogenen Stichprobe_ werden die Fälle so ausgewählt, dass sie sich in bestimmten relevanten Hinsichten ähnlich sind, sich in anderen relevanten Hinsichten dagegen gerade unterscheiden. Diese Art der Fallauswahl
eignet sich besonders in _erklärend_ angelegten Fallstudien: Durch die Kontrastierung
von Fällen in Bezug auf ausgewählte Merkmale wird es möglich, die Relevanz und die
Auswirkungen verschiedener Merkmalsausprägungen auf das interessierende Phänomen genauer zu explorieren und zu beschreiben.


**Untersuchungsbeispiel: Vermeidung von Fehlern bei der Warenauslieferung**


Eine solche multiple Fallstudie mit teils ähnlichen, teils kontrastierenden Fällen wurde im Bereich
der Logistik von Helm, Malikowa und Kembro durchgeführt (2024). Ausgangspunkt für ihre Studie
war die Beobachtung, dass es trotz Automatisierung und Digitalisierung bei der Auslieferung von
Waren weiterhin zu Fehlern kommt – dass man also beispielsweise an Stelle des bestellten Kleides
in Rot das Kleid in Blau erhält. Sie gingen der Frage nach, worin die Ursachen von Fehlern bei der
Warenauslieferung begründet liegen und inwieweit eine neue Technologie – Intelligent Video Analysis (IVA) – dazu beitragen kann, diese Ursachen zu identifizieren.
Sie wählten für ihre Studie sechs Firmen bzw. Fälle aus, die sämtlich über mindestens vier Monate
Erfahrung in der Anwendung von IVA verfügten und für die außerdem hinreichend Datenmaterial zur Verfügung stand. Die Firmen wurden erstens daraufhin kontrastiert, ob sie eine stationäre
oder eine mobile Form der Technologie einsetzten. Ein zweiter Kontrast betraf die Operationen, bei
denen die Technologie eingesetzt wurde (Herausnehmen aus dem Lager, Verpacken usw.). Außerdem variierten die Firmen im Hinblick auf die Arten der Güter (Futtermittel, Elektronik, Autoteile
usw.), deren Größe und Wert. Zur Datenerhebung wurden in jeder der Firmen Interviews mit verantwortlichen Personen durchgeführt; es wurden Beobachtungsdaten aus den IVA-Aufzeichnungen herangezogen und teilweise auch in den Interviews besprochen; und für einen Teil der Firmen
standen außerdem Daten zu Fehlerquoten zur Verfügung.
Die Ergebnisse fielen über alle Firmen hinweg vergleichbar aus. Und zwar zeigte sich, dass ein
Teil der Fehler gar nicht in der Warenauslieferung begründet lag. Ein weiteres wichtiges Ergebnis war, dass Fehler bei der Warenauslieferung in nicht unerheblichem Maß auf menschlichen Irrtum zurückzuführen – und somit auch nicht durch immer weiter zunehmende Automatisierung zu


72


3.2 Fallstudie


lösen – waren. Diese Ergebnisse waren unabhängig davon, welche Form der IVA eingesetzt wurde,
in Bezug auf welche Operationen, bei welchen Gütern usw. Die Merkmale, hinsichtlich derer die
Fälle kontrastiert wurden, standen somit in keinem Zusammenhang mit den Ursachen von Fehlern
bei der Warenauslieferung und deren Identifikation durch die IVA-Technologie.


Vorgehen bei der Fallauswahl für die multiple Fallstudie:


  - Festlegen des Untersuchungsziels

  - Festlegen, wie die Fälle sich zueinander verhalten sollen: ähnlich oder kontrastierend, in Bezug

auf welche Merkmale

  - Identifikation geeigneter Fälle auf der Grundlage von Hintergrundinformationen zur Verteilung

relevanter Merkmale in der Grundgesamtheit

  - Auswahl der konkreten Fälle.


Sowohl Einzelfall- als auch multiple Fallstudien können außerdem _holistisch_ oder _einge-_
_bettet_ angelegt sein. Bei den oben beschriebenen Untersuchungsbeispielen handelt es sich
jeweils um holistische Fallstudien; das heißt, dass die Fälle dabei in ihrer Gesamtheit interessieren und betrachtet werden. Bei der eingebetteten Fallstudie wird dagegen zwischen
der Ebene des Falls als Ganzem und der Auswahl von Untersuchungseinheiten, die sich
auf den Fall als Ganzes beziehen, quasi eine weitere Ebene einbezogen, die Ebene von
Untereinheiten. In einer Einzelfallstudie über die Nutzung von Serious Games im Mathematikunterricht untersuchten Giuseppina Barbieri, Rosa Barbieri und Roberto Capone
(2021) beispielsweise das europäische Unterrichtsprojekt E-Magic; Untereinheiten
waren je eine Schule in Italien, Portugal und Griechenland; und Untersuchungseinheiten waren Schüler:innen an diesen drei Schulen. Die Fallauswahl findet bei eingebetteten
Fallstudien somit auf drei Ebenen statt. Die Überlegungen bei der Auswahl von Untereinheiten sind dabei denen bei der Auswahl von Fällen in der multiplen Fallstudie vergleichbar: Untereinheiten können so ausgewählt werden, dass sie einander möglichst ähnlich
sind oder dass sie im Hinblick auf ausgewählte Merkmale miteinander kontrastieren.


Bei der eingebetteten Fallstudie finden Auswahlprozesse auf drei Ebenen statt:


  - der Ebene der Fälle

  - der Ebene von Untereinheiten innerhalb der Fälle

  - der Ebene von Untersuchungseinheiten innerhalb der Untereinheiten.


73


3 Fallauswahl im Kontext qualitativer Ansätze


3.3 Ethnografie


Ziel der Ethnografie ist es, Lebenswelten oder bestimmte kulturelle Praktiken aus
einer Innenperspektive heraus zu verstehen. In der Frühzeit der ethnografischen Forschung galt das Interesse in erster Linie dem Fremden, dem scheinbar Exotischen. Beispiele aus dieser Frühphase sind etwa Malinowskis anthropologische Forschung zu
den Menschen auf den Trobriand-Inseln oder auch die Stadtforschung in der Tradition der Chicagoer Schule, die den Schwerpunkt auf Subkulturen legte, wie beispielsweise Whytes Studie zu den „Streetcorner Boys“ (1943). In der Folge hat sich das Interesse der Ethnografie hin zu einer Soziologie des Alltags verschoben. Von Interesse
sind hier etwa Kulturen in Organisationen, sogenannte kleine Lebenswelten wie die
von Handwerkern, Jugendkulturen, Gemeinschaften im digitalen Raum oder auch,
in der Autoethnografie, die Exploration kulturell relevanten Erlebens durch die Linse
eigener Erfahrungen.

Charakteristisch für die Ethnografie ist es, dass die Forschung im Feld durchgeführt
wird, d. h. an ausgewählten Schauplätzen, die Beispiele für die interessierenden Kulturen, Lebenswelten oder Praktiken darstellen. Dabei kommen in der Regel mehrere
Methoden der Datenerhebung zur Anwendung, meist Formen der (teilnehmenden)
Beobachtung gemeinsam mit Interviews, Fokusgruppen oder auch Dokumenten verschiedener Art und deren Analyse. Die Kombination dieser Verfahren erlaubt es, eine
Außenperspektive (mittels Beobachtung durch die Forschenden oder auch durch die
Analyse von Dokumenten) mit einer Innenperspektive der Personen im Feld (mittels
Interviews oder Fokusgruppen) zu verbinden und so ein umfassendes Bild der interessierenden Lebenswelten oder Praktiken zu gewinnen.

Mit dem Fokus auf einzelnen Kulturen, kulturellen Praktiken oder Lebenswelten
und deren Untersuchung an Hand ausgewählter Schauplätze handelt es sich bei der
Ethnografie genau genommen um eine Art von Fallstudie (s. o. 3.2). Ebenso wie bei
der Fallstudie sind dabei Auswahlentscheidungen auf _mehreren Ebenen_ zu treffen.
Auf der obersten Ebene sind in einem ersten Schritt die Schauplätze auszuwählen, an
Hand derer die interessierenden Lebenswelten oder Praktiken untersucht werden sollen. Auf den darunter liegenden Ebenen sind dann in einem zweiten Schritt für jedes
der Verfahren, die bei der Datenerhebung zur Anwendung kommen, entsprechende
Auswahlentscheidungen zu treffen.


Bei ethnografischen Studien ist eine Fallauswahl auf mehreren Ebenen zu treffen:


1. Ebene: Auswahl von Schauplätzen
2. Ebene: Auswahl von Personen, Beobachtungseinheiten usw. für jede der Erhebungsmethoden,

die in der ethnografischen Studie eingesetzt werden.


74


3.3 Ethnografie


**Untersuchungsbeispiel: Antiretrovirale Therapie bei HIV/AIDS in der Subsahara-Region**


Ausgangspunkt der ethnographischen Studie von Norma Ware und Kolleg:innen (2009) war die
Beobachtung, dass Menschen mit HIV/AIDS in der Subsahara-Region sich deutlich besser an die
ärztlichen Anweisungen zur Medikamenteneinnahme halten als Menschen in den USA – und das
trotz deutlich schlechterer Infrastrukturen (etwa in Form langer und schwieriger Anreise zu den
Behandlungszentren). Ziel der Forschenden war es, besser zu verstehen, wie diese hohe Adhärenz
an die Behandlungsanweisungen zustande kommt.

In einem ersten Schritt fand eine Auswahl geeigneter Kliniken bzw. Behandlungszentren statt. Es

wurde je eine Klinik in Uganda, Tansania und Nigeria einbezogen. Die Kliniken wurden so aus
gewählt, dass die Stichprobe hinsichtlich verschiedener Kriterien möglichst heterogen ausfiel: Sie

lagen in Städten mit einer Bevölkerung von jeweils 16.000 (in einer ländlichen Region Ugandas)

sowie in Großstädten mit je Anderthalb und Drei Millionen Menschen, wobei jeweils mehrere tau
send Patient:innen medizinisch versorgt wurden. Art und Reihenfolge der antiretroviralen Medika
mente, also das Therapieschema, war teilweise unterschiedlich; und die Versorgung der Kliniken mit

Medikamenten wurde teils auf verschiedenen Wegen, teils nur über einen einzelnen Versorgungs
weg sichergestellt. Auch hinsichtlich der eingesetzten Präventionsmaßnahmen (z. B. kostenlose

Kondome, Kondome auch für Frauen, Einbeziehung von Familienmitgliedern in die Beratung) sowie

der zusätzlich angebotenen Gesundheitsmaßnahmen (Multivitamine, Wasserreinigung und -aufbe
reitung usw.) bestanden Unterschiede zwischen den Kliniken. Die einbezogenen Kliniken deckten

somit ein breites Spektrum an Versorgungs- und Beratungsmöglichkeiten für Menschen mit HIV/

AIDS ab. Gemeinsam war allen drei Kliniken eine hohe Adhärenz-Rate zwischen 94 und 100 Prozent.

In einem zweiten Schritt bzw. auf der zweiten Ebene wurde festgelegt, für welche Personengrup
pen Daten erhoben werden sollten. Auf der Grundlage bisheriger Forschung wurden drei Perso
nengruppen als relevant identifiziert und in die Studie einbezogen. Dies waren zunächst die Pati
ent:innen selbst, weiterhin medizinisches Personal sowie Personen, die die Patient:innen bei der

Behandlung unterstützten, also Angehörige und Freunde. Patient:innen wurden einbezogen, soweit

sie bestimmte Kriterien hinsichtlich einer minimalen und maximalen Behandlungsdauer erfüllten

oder an einem ausgewählten Behandlungsprogramm teilnahmen; die genauen Kriterien unterschie
den sich zwischen den Kliniken. Patient:innen, die die Kriterien erfüllten, wurden von den Forschen
den kontaktiert und zur Teilnahme an der Studie eingeladen. Insgesamt wurden Interviews mit

158 Patient:innen durchgeführt. Die Patient:innen wurden wiederum gebeten, Personen zu benen
nen, die sie bei der Behandlung unterstützten, und diese wurden dann von den Forschenden ange
schrieben. 45 Begleitpersonen konnten auf diese Weise für die Studie gewonnen werden. Weiterhin

erklärten sich 49 Angehörige des Gesundheitspersonals aus den drei Kliniken zu einer Teilnahme

bereit. Mit diesem Personenkreis wurden insgesamt 414 Interviews durchgeführt, wobei manche

Personen auch mehrfach interviewt wurden, um die Entwicklung des Behandlungsprozesses über

die Zeit verfolgen und um Aspekte in die Interviews aufnehmen zu können, die sich im Studienver
lauf als relevant erwiesen. Außerdem wurde die Medikamenteneinnahme per Fragebogen erfasst.


75


3 Fallauswahl im Kontext qualitativer Ansätze


Für die Beobachtung im Feld wurden vorab bestimmte Situationen im Rahmen der Behandlung als
relevant identifiziert, nämlich: regelmäßige Kontrollbesuche der Patient:innen in der Klinik, um den
Behandlungsverlauf mit dem medizinischen Personal zu besprechen; Gespräche zur psychologischen Beratung; Gespräche zur Gesundheitserziehung; und die Medikamentenausgabe. Die Beobachtung innerhalb dieser vier Settings verlief frei und non-standardisiert. Er wurden insgesamt
136 Beobachtungen durchgeführt, mit einer Dauer von einer halben bis zu einer Stunde.


Diese Untersuchung zur Adhärenz bei der antiretroviralen Therapie in der SubsaharaRegion ist in vielen Hinsichten typisch für die Vorgehensweise bei der Fallauswahl
in ethnografischen Studien. Zunächst wird deutlich, dass die Fallauswahl, wie oben
beschrieben, auf mehreren Ebenen erfolgt, die teilweise ineinander verschachtelt sind.

Auf der ersten Ebene erfolgt die Auswahl der Schauplätze, hier die drei Kliniken
in der Subsahara-Region. Für die Auswahl ist zunächst maßgeblich, dass die Kliniken
tatsächlich geeignete Exemplare für eine medikamentöse Therapie bei HIV/AIDS darstellen, dass hier also jeweils eine Betreuung einer größeren Anzahl von Patient:innen erfolgt und geschultes Personal zur Verfügung steht. Weiterhin ist für die Auswahl
wichtig, dass die drei Kliniken untereinander ein breites Spektrum der gesundheitlichen Versorgung in der Region abbilden, also beispielsweise städtische und ländliche
Lagen, verschiedene Therapieschemata und Versorgungswege usw. Über die drei einbezogenen Kliniken hinaus gibt es sicher noch weitere Krankenhäuser, die potenziell in
Frage gekommen wären. Neben der Relation der Kliniken zueinander (im Sinne eines
breiten Spektrums) haben bei der Auswahl vermutlich auch Fragen der Zugänglichkeit
für die Forschenden eine Rolle gespielt, so dass hier Aspekte einer gezielten kriterienorientierten Auswahl von Fällen, die in ihrer Gesamtheit heterogen sind, mit einer Adhoc-Vorgehensweise kombiniert sind. Die Auswahl der drei Kliniken in dieser Studie
erfolgte außerdem konzeptgesteuert, also aufgrund von Erwägungen, die vor der Studie angestellt wurden.

Eine solche konzeptgesteuerte Auswahl von Schauplätzen ist für ethnografische Studien typisch, ist allerdings nicht im selben Maß methodologisch vorgegeben wie die
theoriegeleitete Auswahl von Fällen bei der Fallstudie. Je nach Untersuchungsverlauf
kann es durchaus sein, dass aufgrund erster Befunde oder auch spontan noch zusätzliche Schauplätze hinzugenommen werden. Auch eine rein induktive Vorgehensweise ist
möglich, bei der sich das Sample im Untersuchungsverlauf sukzessive konstituiert. Eine
solche Vorgehensweise wählte beispielsweise Nina Schuster in ihrer Studie zu sozialen
Differenzierungsprozessen und Formen der Konfliktaushandlung in Kleingärtnervereinen (2024). Sie unterschied zunächst theoriegeleitet zwischen verschiedenen Arten
von Vereinen (je nach Lage und sozialer Zusammensetzung der Mitglieder). Innerhalb dieser großen Gruppen von Vereinen sprach die Forscherin dann solche Personen
gezielt an, die sie schon kannte oder an die ihre Kontakte sie weiterverwiesen hatten.


76


3.3 Ethnografie


Die Auswahl von Schauplätzen auf der ersten Ebene einer ethnografischen Studie findet oft – aber
nicht zwingend – konzeptgesteuert statt.


Auf der _zweiten Ebene_ erfolgt die Auswahl relevanter Personengruppen und anschließend
der Personen selbst. Auch hier findet sich, bei der Auswahl von Patient:innen und Personen aus dem medizinischen Personal, in der Studie eine Kombination von kriterienorientierten und Ad-hoc-Vorgehensweisen. Dabei werden alle in Frage kommenden Personen
kontaktiert; die schlussendliche Stichprobe setzt sich aus den Personen zusammen, die
einer Teilnahme zugestimmt haben. Die Auswahl von Begleitpersonen erfolgt dagegen
durch sogenanntes _responsives Sampling_ (s. o. 2.4): Relevante Begleitpersonen werden
von den Patient:innen vorgeschlagen, von den Forschenden kontaktiert, und es werden
diejenigen in die Studie einbezogen, die einer Teilnahme zustimmen. Bei der Fallauswahl
auf der zweiten Ebene können in der ethnografischen Forschung somit ganz unterschiedliche Strategien der Fallauswahl zur Anwendung kommen. Eine rein konzeptgesteuerte
Form der Auswahl ist allerdings eher untypisch, weil hier immer auch Fragen der Zugänglichkeit im Feld eine Rolle spielen und weil erste Befunde im Untersuchungsverlauf Anlass
sein können, weitere Personen(-gruppen) in die Studie einzubeziehen.


Bei der Fallauswahl auf der zweiten Ebene von ethnografischen Studien können ganz unterschiedliche Strategien zur Anwendung kommen. Aufgrund der Offenheit ethnografischer Studien ist eine
rein konzeptgesteuerte Auswahl jedoch eher untypisch.


Eine besondere Form des responsiven Sampling ist typisch in der ethnografischen Forschung für die Auswahl von Teilnehmer:innen auf dieser zweiten Ebene (kommt jedoch
in der beschriebenen Untersuchung nicht zur Anwendung). Dabei handelt es sich um die
Vermittlung von Teilnehmer:innen durch einen _Gatekeeper_ (auch: _Türhüter)_ . Gatekeeper
sind Personen, die im ausgewählten Feld über einen hohen Status und somit über Autorität verfügen. Wenn sie der Forschung positiv gegenüberstehen, dann bedeutet dies für
die Forschenden einen Vertrauensvorschuss und somit einen leichteren Zugang zu den
anderen Personen im Feld. Diese Strategie wählte z. B. Whyte in seiner Studie zu den
„Streetcorner Boys“ (1943): Er gewann wesentlichen Zugang zu den Personen im Feld
über den Gatekeeper „Doc“. Der Fokus auf eine oder wenige Einzelpersonen als Gatekeeper beim responsiven Sampling kann allerdings auch Nachteile mit sich bringen. Wenn
eine Person im Feld über eine hohe Autorität verfügt, so verfügt sie damit auch über
Macht. Sie kann gezielt steuern, wessen Positionen in die Untersuchung Eingang finden
und wessen Positionen nicht repräsentiert sind. Und sie kann unter Umständen auch
Einfluss darauf nehmen, was von den Personen im Feld thematisiert wird und was nicht.


77


3 Fallauswahl im Kontext qualitativer Ansätze


Bei der ethnografischen Forschung kommt häufig eine besondere Form des responsiven Sampling
zur Anwendung, nämlich der Zugang zum Feld durch Gatekeeper.


Konstitutiv für die ethnografische Forschung ist die Methode der (teilnehmenden)
Beobachtung. Dies bedeutet, dass bei der Fallauswahl auch Entscheidungen darüber
zu treffen sind, was beobachtet werden soll und zu welchen Zeitpunkten die Beobachtung erfolgen soll. In der hier beschriebenen Studie zur Adhärenz bei der medikamentösen HIV/AIDS-Therapie wurden im Hinblick auf die Beobachtung zwei Entscheidungen getroffen. Eine erste Entscheidung ergab sich durch die Auswahl der Patient:innen
und der Mitglieder des Gesundheitspersonals, mit denen auch Interviews durchgeführt
wurden: Es konnten nur solche Interaktionen beobachtet werden, an denen Personen
beteiligt waren, die einer Teilnahme an der Studie und somit an den Interviews zugestimmt hatten. Die Auswahl von Personen für die Interviews hatte somit auch einen
direkten Einfluss auf die Möglichkeiten der Beobachtung. Zweitens wurden vorab
konzeptgesteuert bestimmte Interaktionsformen ausgewählt, die für die Adhärenz bei
der Medikamenteneinnahme als besonders relevant gelten konnten. Die Autor:innen
geben an, dass 136 Beobachtungen durchgeführt wurden, stellen aber keine genaueren Informationen darüber zur Verfügung, in welcher Weise konkrete Interaktionen
der vier verschiedenen Typen für die Beobachtung ausgewählt wurden; auch zu den
Zeitpunkten finden sich keine genaueren Angaben.

Dies ist durchaus typisch für die Auswahl von Untersuchungseinheiten bei der
Beobachtung in ethnografischen Studien: Hier geht es ja gerade darum, sich das Feld
im Laufe der Untersuchung sukzessive zu erschließen. Häufig verläuft die Beobachtung daher zu Beginn sehr offen. Relevanzen werden oft erst im Untersuchungsverlauf
sichtbar, und damit kann die Beobachtung dann auch fokussierter und auf bestimmte
Ereignisse oder Interaktionen bezogen erfolgen. In anderen Fällen, wie in der hier
beschriebenen Untersuchung, sind Relevanzen schon vorab erkennbar und die Beobachtung kann sich von vornherein darauf konzentrieren. Dabei wird dann meist angestrebt, so viele relevante Ereignisse bzw. Interaktionen wie möglich einzubeziehen.
Deren genauer Zeitpunkt oder Dauer ist aber vorab meist nicht ersichtlich, so dass
auch keine Entscheidungen im Voraus bei der Fallauswahl möglich sind. Entsprechend
finden sich in ethnografischen Studien meist auch keine genaueren Angaben zur Auswahl von Beobachtungseinheiten.


Aufgrund des offenen Charakters ethnografischer Studien sind konzeptgesteuerte Entscheidungen
über die Details der (teilnehmenden) Beobachtung kaum möglich.


78


3.4 Phänomenologie


3.4 Phänomenologie


Mit dem Begriff der Phänomenologie wird eine Reihe von Ansätzen mit unterschiedlichen philosophischen Wurzeln und unterschiedlichen Schwerpunktsetzungen in der
Vorgehensweise bezeichnet. Gemeinsam ist ihnen allen ein Interesse an der gelebten
Erfahrung von Alltagsphänomenen (wie beispielsweise Eifersucht, Lärm seitens der
Nachbarn oder die Auswirkungen chronischer Erkrankungen). Ziel phänomenologischer Untersuchungen ist es zu beschreiben, wie Menschen solche Phänomene erleben
und mit Bedeutung füllen. Da wir in diesem Band nicht die gesamte Vielfalt phänomenologischer Ansätze darstellen können, greifen wir als Beispiel die Interpretative Phänomenologische Analyse heraus (IPA: Interpretive Phenomenological Analysis: Smith,
Flowers, & Larkin, 2022). Der Ansatz findet in verschiedenen sozialwissenschaftlichen
Disziplinen zunehmend Anwendung, und die Überlegungen, die bei der Fallauswahl
zu beachten sind, sind über die verschiedenen Ansätze hinweg vergleichbar.

Die IPA stellt einen idiographischen Ansatz dar. Es geht dabei also nicht um Verallgemeinerung, sondern um die detaillierte Beschreibung und Analyse ausgewählter Fälle.
Diese werden in ihrer Gesamtheit betrachtet; es werden induktiv Themen generiert,
die in einem zweiten Schritt mit den Themen aus den anderen Fällen in Verbindung
gebracht werden. Damit eine solche vertiefte Analyse machbar bleibt, beschränken sich
Forschende bei der IPA in der Regel auf _wenige Fälle_, die sämtlich Exemplare des interessierenden Phänomens darstellen und untereinander eher homogen sind. Es werden bei
der IPA also auf der Grundlage vorab definierter Kriterien, die sich aus dem interessierenden Phänomen selbst ergeben, kleine, homogene Stichproben generiert. Die Stichprobengröße kann dabei zwischen einem und mehr als 50 Fällen variieren, wobei Stichproben mit über 50 Fällen jedoch die Ausnahme darstellen. Typischer sind Stichproben,
die zwischen acht und 15 Fällen umfassen (Guettermann, 2015; Smith & Osborn, 2015).
Methode der Wahl für die Datenerhebung ist bei der IPA meist das Leitfadeninterview.


Typisch für die IPA sind kleine, homogene Stichproben von Fällen, die Exemplare des interessierenden Phänomens darstellen.


**Untersuchungsbeispiel: Das Erleben Jugendlicher von sozialen Medien während der**
**Covid-Pandemie**


Gegenstand der Untersuchung von Betul Keles, Annemarie Grelish und Mary Leamy (2024) waren

die Nutzung und das Erleben sozialer Medien durch Jugendliche in England während der Covid
Pandemie und wie sich, nach Einschätzung der Jugendlichen selbst, die Nutzung sozialer Medien


79


3 Fallauswahl im Kontext qualitativer Ansätze


in dieser Zeit auf ihre psychische Gesundheit ausgewirkt hat. Teilnehmen konnten Jugendliche im

Alter zwischen 14 und 16 Jahren, die aktiv soziale Medien nutzten, zum Zeitpunkt der Untersuchung

in England lebten und fließend Englisch sprachen. Auf der Grundlage dieser Kriterien wurden über

einen Zeitraum von sieben Monaten Interviews mit insgesamt elf Jugendlichen aus zwei verschiede
nen Städten durchgeführt. Sechs der Jugendlichen waren männlich, fünf weiblich. Hinsichtlich ihrer

Ethnizität unterschieden die Jugendlichen sich erheblich: Die Stichprobe umfasste nicht nur briti
sche, sondern auch Teilnehmer:innen pakistanischer, brasilianischer, portugiesischer, finnischer und

vietnamesischer Herkunft. Die Mediennutzung der Teilnehmer:innen variierte ebenfalls stark: Man
che nutzten soziale Medien maximal eine Stunde, andere bis zu elf Stunden täglich; manche nutzten

soziale Medien erst seit anderthalb, andere bereits seit fünf oder sechs Jahren. Die meisten Jugend
lichen beschränkten sich auf eine passive Mediennutzung, wobei Instagram und Snapchat die belieb
testen Medien waren; und die meisten Jugendlichen machten ihr Profil nicht öffentlich. Aber auch

hier gab es Unterschiede: Manche nutzten auch soziale Medien wie Twitter oder ­WhatsApp; manche

posteten selbst neue Inhalte; und manche machten ihr Profil öffentlich zugänglich.


In dieser Untersuchung zum Erleben der Nutzung sozialer Medien in Zeiten der Pandemie zeigt sich das klassische Vorgehen bei der Fallauswahl im Rahmen einer IPA-Studie: Es werden vorab Kriterien festgelegt, die die Teilnehmer:innen erfüllen müssen,
wobei die Kriterien sich aus dem interessierenden Phänomen herleiten. In diesem Beispiel müssen die Teilnehmer:innen Jugendliche im Alter zwischen 14 und 16 Jahren
sein und sie müssen soziale Medien nutzen – und außerdem im Einzugsgebiet der Forschenden leben. In dieser Hinsicht handelt es sich also um eine homogene Stichprobe,
die mit elf Personen im für IPA-Studien typischen Rahmen von etwa acht bis 15 Personen liegt. Unter den vielen potenziell in Frage kommenden Jugendlichen wurden diejenigen in die Studie aufgenommen, die auf öffentliche Aufrufe hin an der Teilnahme
interessiert waren und deren Eltern dem zustimmten.

Zugleich wird an dieser Untersuchung erneut die Relativität des Begriffs der Homogenität deutlich. Einerseits handelt es sich hinsichtlich der Auswahlkriterien um eine
homogene Stichprobe. Andererseits wird beim genaueren Hinsehen deutlich, dass die
Jugendlichen sich in anderen Hinsichten ganz erheblich unterscheiden, etwa hinsichtlich (biologischem) Geschlecht, Ethnizität, Art und Intensität der Nutzung sozialer
Medien. In der hier beschriebenen Studie war diese Heterogenität nicht beabsichtigt.

Für die Qualität und Aussagekraft der Studie ist dabei nicht die Homogenität oder
Heterogenität in Bezug auf weitere Kriterien als solche entscheidend, sondern die
Frage, ob diese Kriterien mit dem interessierenden Phänomen in Zusammenhang stehen. So ist beispielsweise denkbar, das männliche und weibliche Jugendliche die Nutzung sozialer Medien je anders erleben. Und es ist auch zu vermuten, dass die Intensität der Mediennutzung im Zusammenhang mit dem Nutzungserleben steht. Eine
Heterogenität im Hinblick auf solche zusätzlichen, sekundären (also nicht in die Fall

80


3.5 Diskursforschung und Diskursanalyse


auswahl einbezogenen) Kriterien kann dazu beitragen, im Rahmen der Analyse verschiedene Formen des Erlebens des interessierenden Phänomens zu identifizieren.
Eine solche vergleichende Analyse wurde jedoch im Rahmen der vorliegenden Untersuchung nicht durchgeführt.

Zwar basieren IPA-Studien in der Regel auf homogenen Stichproben. Es gibt aber
auch Ausnahmen bzw. Studien, bei denen eine Homogenität der Stichprobe in Bezug
auf ein Set von Kriterien und eine Heterogenität in Bezug auf ein Set anderer Kriterien angestrebt wird, um so die Anwendbarkeit der Ergebnisse auf eine größere Personengruppe zu erleichtern. Ein Beispiel für eine solche Studie ist die Untersuchung
von Lilian Skilbeck, Christopher Spanton und Michael Paton (2023) zum Erleben
der Erkrankung von Long Covid-Patient:innen. Ihre Stichprobe von 18 Personen war
einerseits homogen im Hinblick auf die Kriterien, die sich aus dem Untersuchungsgegenstand herleiteten: Alle Teilnehmer:innen waren mindestens 18 Jahre alt, und sie
hatten eine Diagnose von Long- oder Post-Covid-Syndrom erhalten. Darüber hinaus
strebten die Forschenden eine Heterogenität der Stichprobe im Hinblick auf soziodemographische Kriterien wie Alter, Geschlecht, Ethnie und soziale Schicht an.


Die Homogenität von Stichproben in der IPA bezieht sich meist auf die Auswahlkriterien, die sich
aus dem Untersuchungsgegenstand herleiten. In Bezug auf weitere Kriterien kann die Stichprobe
dagegen auch heterogen sein.


3.5 Diskursforschung und Diskursanalyse


Unter die Begriffe der Diskursforschung und Diskursanalyse werden eine ganze Reihe
unterschiedlicher Ansätze und Vorgehensweisen gefasst, die sich grob in zwei Gruppen unterteilen lassen: eine eher deskriptiv, an der Linguistik orientierte und eine
eher normativ-kritisch ausgerichtete Variante, häufig (aber nicht notwendig) in der
Tradition von Foucault. Im deutschsprachigen Kontext ist vor allem die wissenssoziologische Diskursanalyse weit verbreitet (Keller, 2011). Im Folgenden werden Diskurse ganz allgemein und übergreifend gefasst als „die Produktion sozialen Sinns, verstanden als die Darstellung, Vermittlung und Konstitution von bedeutungstragenden
Objektivationen in kommunikativen Prozessen“ (Traue, Pfahl, & Schürmann, 2019,
S. 565). Forschungsfragen in der Diskursforschung beziehen sich darauf, wie Sinn in
Diskursgemeinschaften ausgehandelt, produziert und verbreitet wird. Zentral ist dabei
die Annahme von der realitätskonstituierenden Funktion von Sprache: Sprache bildet
Realität nicht ab, sondern Sprache erzeugt Realität.

Diskursforschung und die Fallauswahl bei der Diskursforschung unterscheiden sich
in zweierlei wichtigen Hinsichten von der Mehrzahl der anderen Ansätze, die wir in


81


3 Fallauswahl im Kontext qualitativer Ansätze


diesem Kapitel vorstellen. Erstens gehen Forschende im Rahmen anderer Ansätze in
der Regel davon aus, dass Fälle und Untersuchungseinheiten im Feld quasi existieren;
bei der Fallauswahl geht es letztlich darum, solche Fälle auszuwählen, die dieses Feld
repräsentieren. In der Diskursforschung geht man dagegen – im Sinne der realitätskonstituierenden Funktion von Sprache – davon aus, dass ein Diskurs nicht in irgendeiner Weise per se existiert, sondern permanent erzeugt und damit auch verändert wird;
durch die Fallauswahl wird quasi eine Momentaufnahme des Diskurses generiert. Auch
in anderen Ansätzen werden Fälle nicht ganz so naiv als existierend angesehen, wie wir
dies gerade dargestellt haben. So gibt es in der methodologischen Literatur zur Fallstudie Überlegungen dazu, wie der Fall im Forschungsverlauf überhaupt erst konstituiert
wird; und auch in der Ethnografie wird die Frage gestellt, was genau zum Feld gehört
und was nicht und wie die Feldzugehörigkeit bestimmt wird. Dennoch ist das Bewusstsein für die Konstruktion des Phänomens in der Diskursforschung stärker ausgeprägt
als in den meisten anderen sozialwissenschaftlichen Ansätzen (Ausnahmen sind die
konstruktivistische sowie die reflexive Grounded-Theory-Methodologie, wo ebenfalls
von einem Konstruktionscharakter der Phänomene ausgegangen wird; s. o. 3.1).

Ein zweiter Unterschied bezieht sich auf die Art der ausgewählten Untersuchungseinheiten. In der Diskursforschung handelt es sich dabei um Texte, Medienprodukte,
Artefakte oder auch beobachtbare Praktiken. Texte sind dabei in der Regel _natürliche_
_Texte_, d. h. Dokumente unterschiedlichster Art, private sowohl als auch öffentliche,
sowie natürliche Gespräche. Im Forschungsprozess generiertes Material wie beispielsweise Interviews sind dagegen eher selten Gegenstand der Analyse. Wenn solches
Material einbezogen wird, dann wird es jedoch meist nicht auf Themen hin analysiert,
sondern im Hinblick auf die Interaktionsprozesse und die Art und Weise, wie im Interview Bedeutungen generiert werden.


Die Diskursanalyse unterscheidet sich von den anderen hier dargestellten Ansätzen in zwei Hinsichten:


  - Fälle bzw. Diskurse werden durch den Auswahlprozess mit konstituiert.

  - Gegenstand der Analyse sind meist natürliche Texte, aus den die Forschenden auswählen.


Die Fallauswahl erfolgt in der Diskursforschung in drei Schritten. In einem _ersten_
_Schritt_ geht es darum, den zu untersuchenden _Diskurs auszuwählen_ . Wichtig ist dabei
vor allem, wie der interessierende Diskurs sich sprachlich-praktisch konstituiert, beispielsweise institutionell oder thematisch. Dieser Schritt steht in engem Zusammenhang mit der Entwicklung einer Forschungsfrage und beeinflusst seinerseits den _zwei-_
_ten Schritt_, nämlich die _Zusammenstellung eines Datenkorpus_, d. h. einer Sammlung
von Material, das geeignet ist, den interessierenden Diskurs in seiner Breite abzubil

82


3.5 Diskursforschung und Diskursanalyse


den. Keller (2011, S. 87) empfiehlt, hier eine möglichst heterogene Gruppe von Texten, Medienprodukten oder Objekten zusammenzustellen. Um zu entscheiden, welches Material dafür geeignet ist, sind oft Vorarbeiten erforderlich, sei es in Form von
Literaturrecherchen oder von Experteninterviews. Auch ist die Vorgehensweise bei der
Diskursanalyse oft keine lineare, so dass das Datenkorpus im Verlauf der Analyse weiter modifiziert werden kann.

Da die Vorgehensweise bei der Diskursanalyse meist sehr feinanalytisch und nahe
am Text erfolgt, ist es nicht möglich, das gesamte Datenkorpus auf diese Weise zu
analysieren. Daher sind in einem _dritten Schritt_ geeignete Dokumente und Materialteile für die _Feinanalyse_ auszuwählen, sogenannte _Schlüsselpassagen_ oder -texte, die
in Bezug auf den interessierenden Diskurs besonders informationshaltig sind. Keller
(2011) empfiehlt, sich bei der Auswahl an der Vorgehensweise des _Theoretical Sam-_
_pling_ unter Nutzung der Prinzipien der minimalen und maximalen Kontrastierung zu
orientieren (s. o. 2.3). Dabei soll die Auswahl kontrastierender Materialteile sicherstellen, dass der Diskurs tatsächlich in seiner ganzen Breite abgebildet wird. Die Auswahl
möglichst ähnlicher Materialteile erlaubt es dagegen, einen Teildiskurs differenziert
und in der Tiefe zu explorieren. Durch die _Kombination minimaler und maximaler Kon-_
_traste_ können somit auch unterschiedliche Teildiskurse innerhalb eines gesamten Diskurses sichtbar werden.


Die Fallauswahl bei der Diskursanalyse erfolgt in drei Schritten:


  - Auswahl eines geeigneten Diskurses

  - Erstellung eines Datenkorpus

  - Auswahl von Materialteilen für die Feinanalyse.


**Untersuchungsbeispiel: Die Konstruktion des mittleren Lebensalters in Komödien**


In ihrer kritischen Diskursanalyse in der Tradition von Foucault gingen Margaret Gatling, Jane Mills
und David Lindsay (2014) der Frage nach, inwiefern negative Stereotypen, die mit dem mittleren Lebensalter assoziiert sind, in Komödien reproduziert werden. Der Datenkorpus bestand aus
drei Komödien, die über eine Suche nach relevanten Stichworten in der IMDb-Datenbank und in
einschlägigen Rezensionen ausgewählt wurden: _Lost in Translation,_ _Wild Hogs_ und _Something’s_
_Gotta Give._ Alle drei Filme waren kommerziell erfolgreich und gut zugänglich. Aus den drei Filmen
wurden Schlüsselszenen, -handlungen und -objekte ausgewählt. Als Schlüsselszenen galten solche Szenen, in denen das mittlere Lebensalter explizit Gesprächsthema war. Schüsselhandlungen
und -objekte wurden mittels Vergleich der Objekte und Handlungsweisen mit solchen Gegenstän

83


3 Fallauswahl im Kontext qualitativer Ansätze


den und Handlungen identifiziert, die laut der bisherigen Forschung mit der Lebensphase des mittleren Alters assoziiert werden (z. B. Motorräder, schnelle Autos, Rollkragenpullover oder sorgfältig
drapierte Schals).


In dieser Untersuchung zur medialen Konstruktion des mittleren Lebensalters in
Komödien wird zunächst im Zusammenhang mit der Forschungsfrage ein thematisch
konstituierter Diskurs als Untersuchungsgegenstand spezifiziert. Im nächsten Schritt
wird das Datenkorpus zusammengestellt, das hier aus drei Filmen besteht, in denen
das mittlere Lebensalter ein zentrales Thema darstellt. In einem letzten Schritt werden
schließlich für die Feinanalyse thematisch einschlägige Szenen ausgewählt. Anders als
von Keller vorgeschlagen werden diese Szenen nicht im Hinblick auf Ähnlichkeit oder
Unterschiedlichkeit ausgewählt; vielmehr werden alle als relevant identifizierten Szenen in die Untersuchung einbezogen. Die Untersuchung ist zugleich ein Beispiel dafür,
dass auch audiovisuelle Produkte Gegenstand einer Diskursanalyse sein können, dass
das Datenkorpus einer Diskursanalyse also nicht notwendig aus Texten im engeren
Sinne bestehen muss.


Das Datenkorpus einer Diskursanalyse kann aus natürlichen Texten, aus Medienprodukten beliebiger Art oder aus beobachtbaren Praktiken oder Objekten bestehen.


3.6 Der qualitative Survey


In der qualitativen Forschung stößt man immer wieder auf Studien, meist unter Verwendung des Interviews als Verfahren der Datenerhebung, die keinem spezifischen
Ansatz zuzuordnen sind: Es werden Interviews zu einer bestimmten Forschungsfrage
durchgeführt und anschließend mit Verfahren wie der thematischen Analyse, verschiedenen Kodierverfahren oder der qualitativen Inhaltsanalyse ausgewertet. Um solche Studien methodologisch genauer zu beschreiben und einzuordnen, hat Harrie Jansen den Begriff des qualitativen Survey eingeführt (2010). Zwar ist dieser Begriff in
der methodologischen Literatur (noch) nicht fest verankert. Angesichts der Häufigkeit
solcher Studien und der Relevanz des Surveys für Überlegungen zur Fallauswahl wollen wir diesen Ansatz hier jedoch ebenfalls berücksichtigen.

Ziel des qualitativen Surveys nach Jansen ist die Exploration der Vielfalt eines
Phänomens in einer Grundgesamtheit. Je nach Untersuchungsanlage unterscheidet
sie weiterhin zwischen induktiv und deduktiv angelegten qualitativen Survey-Studien. In _induktiven Surveys_ werden die verschiedenen Ausprägungen eines Phäno

84


3.6 Der qualitative Survey


mens und die Kriterien, nach denen sie variieren, erst im Untersuchungsverlauf sichtbar. Beim _deduktiv angelegten Survey_ werden dagegen schon vor Untersuchungsbeginn
Kriterien festgelegt, von denen bekannt ist, dass sie mit den Ausprägungen des Phänomens in der Grundgesamtheit in Zusammenhang stehen. Unabhängig davon, ob
die angestrebte Vielfalt mit einem eher deduktiv oder einem eher induktiv angelegten Untersuchungsdesign exploriert wird, erfordert diese Zielsetzung grundsätzlich
eine _heterogene Stichprobe_ : Nur wenn die Untersuchungsteilnehmer:innen sich hinsichtlich solcher Merkmale unterscheiden, die mit dem Untersuchungsgegenstand in
Zusammenhang stehen, können die verschiedenen Ausprägungen des Gegenstands
und damit seine Vielfalt angemessen rekonstruiert werden. Jansen trifft noch weitere
methodologische Unterscheidungen (z. B. hinsichtlich der Einführung mehrerer Auswahl- und Analyseebenen) die jedoch hier nicht weiter relevant sind.


Der qualitative Survey zielt darauf ab, die Vielfalt eines Untersuchungsgegenstandes zu explorieren. Dafür ist eine heterogene Stichprobe erforderlich. Die Untersuchung kann entweder konzeptoder datengesteuert angelegt sein.


**Untersuchungsbeispiel: Erfolgreiches Altern aus der Sicht älterer Menschen**


Alina Betlej (2023) ging in ihrer Studie der Frage nach, wie ältere Menschen in Polen über erfolgreiches Altern denken und was erfolgreiches Älterwerden in ihrem jeweiligen kulturellen und sozialen Kontext für sie ausmacht. Zur Beantwortung dieser Fragen führte sie Interviews mit sowohl
narrativen als auch teilstrukturierten Anteilen mit 13 Personen durch.
Bei der Fallauswahl verfolgte sie eine Maximum-Variation-Strategie. In einem ersten Schritt legte
sie Kriterien fest, die alle Teilnehmer:innen erfüllen mussten: Und zwar sollten sie mindestens
65 Jahre alt sein, in Polen leben, und entweder innerhalb der letzten 12 Monate aus dem Arbeitsleben ausgeschieden sein oder planen, innerhalb der kommenden 12 Monate aus dem Arbeitsleben auszuscheiden. Um innerhalb dieser Personengruppe eine hinreichende Variation zu erzielen, suchte sie in einem zweiten Schritt in der Literatur nach Merkmalen, die vermutlich mit der
Wahrnehmung des Älterwerdens in Zusammenhang stehen. Auf dieser Grundlage identifizierte sie
Alter, Geschlecht, Bildungsniveau, das Leben in der Stadt oder auf dem Land sowie den Gesundheitszustand als relevante Merkmale und achtete bei der Auswahl von Teilnehmer:innen darauf,
möglichst viele unterschiedliche Kombinationen der Ausprägungen dieser Merkmale zu realisieren. Ihre Stichprobe umfasste beispielsweise Frauen um die 80 Jahre, die über eine Grundschulausbildung verfügten, auf dem Land lebten und ihre Gesundheit als durchschnittlich beurteilten;
Männer aus derselben Altersgruppe, die die Realschule abgeschlossen hatten, in der Stadt lebten
und ihre Gesundheit als gut beurteilten usw. In Bezug auf Kombinationen von Wohnort, Alter und


85


3 Fallauswahl im Kontext qualitativer Ansätze


Geschlecht war eine gezielte Auswahl geeigneter Personen möglich; Bildungsniveau und Beurteilung des Gesundheitszustands mussten dagegen während der Untersuchung erfragt werden.
Um innerhalb der großen Gruppe potenziell geeigneter Personen konkrete Untersuchungsteilnehmer:innen auszuwählen, nutzte Betlej das Schneeballverfahren, d. h. sie bat Personen, die der
Teilnahme zugestimmt hatten, um die Nennung weiterer Personen, die vielleicht Interesse haben
könnten, an der Studie teilzunehmen.
Die Auswertung der Interviews erfolgte mittels thematischer Analyse, wobei die Auswertung und
die weitere Fallauswahl nach dem Prinzip der thematischen Sättigung ineinander geschachtelt
waren: Es wurden so lange weitere Personen in die Studie einbezogen, wie in den Interviews neue
Themen identifiziert werden konnten. Als sich die Themen auch bei Einbeziehung weiterer Personen wiederholten, wurde die Fallauswahl beendet.


Betlej verfolgte in ihrer Studie das Ziel, die verschiedenen Aspekte der Wahrnehmung
erfolgreichen Alterns durch ältere Menschen in Polen zu rekonstruieren. Durch diese
Ausrichtung auf Bedeutungsvielfalt wird deutlich, dass es sich bei der Studie um einen
qualitativen Survey handelt (auch wenn dieser Begriff in ihrem Artikel nicht explizit
erwähnt wird). Indem sie vor Untersuchungsbeginn gezielt auf der Grundlage eines
Literaturüberblicks Merkmale der Grundgesamtheit identifizierte, die mit dem interessierenden Gegenstandsbereich in Zusammenhang stehen (um auf diese Weise die
angezielte Vielfalt zu erfassen und eine heterogene Stichprobe zu gewinnen), hat sie
in ihrem qualitativen Survey zugleich ein deduktives Vorgehen realisiert: Sie legte
die relevanten Kriterien, hinsichtlich derer die Untersuchungsteilnehmer:innen sich
unterscheiden (sollen), vorab fest.

Für ein konzeptgesteuertes Design beim qualitativen Survey eignen sich zwei Strategien der Fallauswahl: der qualitative Stichprobenplan, bei dem die angezielten Merkmalskombinationen und deren Anzahl vorab festgelegt werden, sowie die Strategie des
Maximum-Variation-Sampling, die Betlej in ihrer Studie verfolgt. Beide Strategien sind
darauf ausgerichtet, aufgrund von Vorüberlegungen eine Heterogenität in Bezug auf
spezifische Merkmale zu generieren. Die Strategie des Maximum-Variation-Sampling
ist dabei offener als der qualitative Stichprobenplan, da die genauen Merkmalskombinationen und deren Anzahl hier nicht vorgegeben sind (s. o. 2.2).


Für die Realisierung eines deduktiv angelegten Prozesses der Fallauswahl beim qualitativen Survey
eignen sich sowohl der qualitative Stichprobenplan als auch das Maximum-Variation-Sampling.


Die Untersuchung von Betlej ist im Hinblick auf die Fallauswahl auch insofern interessant, als sie die deduktive Strategie des Maximum-Variation-Sampling mit dem induk

86


Weiterführende Literatur


tiven Kriterium der Sättigung kombinierte: Sie nahm so lange weitere Personen, die je
anderen Merkmalskombinationen entsprechen, in die Studie auf, als sie weitere Themen in den Interviews identifizieren konnte (zur Sättigung s. u. 4.1).


Weiterführende Literatur


Breuer, Franz, Muckel, Petra, & Dieris, Barbara (2017): _Reflexive Grounded Theory._

_Eine Einführung für die Forschungspraxis_ (4. Aufl.). SpringerVS.
Creswell, John W., & Poth, Cheryl N. (2024). _Qualitative inquiry and research design:_

_Choosing among five approaches_ (5. Aufl.). Sage.
Guetterman, Timothy (2015). Descriptions of sampling practices within five approa
ches to qualitative research in education and the health sciences. _Forum Forum_
_Qualitative Sozialforschung / Forum Qualitative Social Research_, _16_ [(2). https://doi.](https://doi.org/10.17169/fqs-16.2.2290)
[org/10.17169/fqs-16.2.2290](https://doi.org/10.17169/fqs-16.2.2290)
Jansen, Harrie (2010). The logic of qualitative survey research and its position in the field

of social research methods. _Forum Forum Qualitative Sozialforschung / Forum Quali-_
_tative Social Research_, _11_ [(2), Article 2. https://doi.org/10.17169/fqs-11.2.1450](https://doi.org/10.17169/fqs-11.2.1450)
Keller, Rainer (2011). _Diskursforschung. Eine Einführung für SozialwissenschaftlerInnen_

(4. Aufl.). Springer VS.


87


#### **4 Fallauswahl im Kontext qualitativer Daten**

Nicht nur Untersuchungsdesigns, auch verschiedene Arten von Daten und Methoden
der Datenerhebung können mit Anforderungen an die Fallauswahl verbunden sein.
Wir gehen daher in diesem Kapitel auf Erhebungsmethoden und Daten ein, die in der
qualitativen Sozialforschung besonders verbreitet sind: das Interview, Fokusgruppen, Beobachtung, Auswahl von Dokumenten und Auswahl von digitalen Daten. Beim
Interview und in Fokusgruppen werden Daten aktiv im Forschungsprozess erzeugt. Bei
Dokumenten und digitalen Daten treffen die Forschenden dagegen eine Auswahl aus
bereits vorliegendem Datenmaterial, das durchaus umfangreich sein kann. Das hat zur
Folge, dass bei der Auswahl aus bereits vorliegendem Material meist mehr Einheiten in
die Untersuchung einbezogen werden können als sonst in der qualitativen Forschung
üblich. Damit sind dann auch Strategien der Fallauswahl anwendbar, die aus der quantitativen Forschung stammen.


4.1 Interviews


Interviews lassen sich nach verschiedensten Gesichtspunkten unterteilen, beispielsweise nach dem Grad der Strukturiertheit oder der Standardisierung (strukturiertes,
teilstrukturiertes/teilstandardisiertes und offenes bzw. Tiefeninterview) oder der
Anzahl der interviewten Personen (Einzel- versus Gruppeninterview). In der qualitativen Forschung ist das _teilstandardisierte_ bzw. _Leitfadeninterview_ mit einzelnen
Personen am weitesten verbreitet, worunter wir im Folgenden auch das problemzentrierte und das episodische Interview fassen (obwohl diese Interviewformen auch
offene Elemente beinhalten). Auf diese Form des Interviews beziehen wir uns im Folgenden, wobei wir uns insbesondere auf die Anwendung des Konzepts der Sättigung
konzentrieren. Abschließend gehen wir außerdem kurz auf das Experteninterview
als Sonderform des Leitfadeninterviews sowie auf die Fallauswahl beim narrativen
Interview ein.


4.1.1 Fallauswahl beim Leitfadeninterview: Das Konzept der Sättigung


Grundsätzlich lässt sich das gesamte Spektrum an Strategien der Fallauswahl, das wir
in Kapitel 2 skizziert haben, auf Interviewstudien anwenden. Möglich sind sowohl
konzept- wie auch datengesteuerte Formen der Fallauswahl sowie Mischformen, bei
denen die Fallauswahl zunächst nach vorab definierten Kriterien durchgeführt und


88


4.1 Interviews


dann im Untersuchungsverlauf angepasst wird. Besonders häufig finden sich das kriterienorientierte Maximum-Variation-Sampling, das auf eine heterogene Stichprobe
ausgerichtet ist. Ebenso verbreitet sind homogene Stichproben im Rahmen phänomenologischer Untersuchungen; und Interviews finden auch häufig in Studien im Rahmen der Grounded-Theory-Methodologie Anwendung, die der datengesteuerten Logik
des Theoretical Sampling folgen.


In Interviewstudien ist man flexibel in Bezug auf die Strategie der Fallauswahl. Es kommen sämtliche Strategien der Fallauswahl in Frage.


Überlegungen zur Fallauswahl bei Interviews finden sich insbesondere im Zusammenhang mit der Frage, wie viele Interviews jeweils ausreichend sind. Und diese
Frage wird wiederum in erster Linie mit dem Kriterium der _Sättigung_ diskutiert.
Dahinter steht die Überlegung, dass die Fallauswahl dann abgeschlossen werden
kann, wenn das Datenmaterial gesättigt ist. Daran zeigt sich zugleich, dass Überlegungen zur Fallauswahl unter dem Gesichtspunkt der Sättigung nur dann weiterführend sind, wenn die Untersuchungseinheiten zumindest teilweise datengesteuert ausgewählt werden. Wenn man die Einheiten konzeptgesteuert auswählt, dann
legt man auch die Fallanzahl schon im Voraus aufgrund konzeptueller Überlegungen
oder Erfahrungen fest, und eine Überprüfung des Sättigungsgrades des Datenmaterials erübrigt sich damit.


Die erforderliche Anzahl der Fälle bei Interviewstudien wird oft im Zusammenhang mit Sättigung
diskutiert. Das Konzept der Sättigung ist aber nur anwendbar, wenn die Fallauswahl wenigstens
teilweise datengesteuert erfolgt.


Der Begriff der Sättigung wird in der Praxis allerdings sehr unterschiedlich definiert
und angewandt. Saunders et al. (2018) haben vier verschiedene Konzeptualisierungen von Sättigung identifiziert. Allen ist gemeinsam, dass sie auf dem Prinzip der _Red-_
_undanz_ basieren: Die Untersuchung wird so lange fortgeführt, bis keine neuen Informationen mehr gewonnen werden. In der Praxis finden sich die _Theoretische Sättigung_
sowie die datenbezogene / induktive Sättigung am häufigsten. Die Theoretische Sättigung im Kontext der Grounded-Theory-Methodologie (GTM) bemisst sich daran,
inwieweit das Datenmaterial es erlaubt, die Eigenschaften der Kategorien in der Theorie auszuarbeiten und zu entwickeln (s. o. 3.1). Diese Variante der Sättigung greift in
Interviews, die innerhalb eines Grounded-Theory-Designs stattfinden. In Interviews
im Rahmen anderer Forschungstraditionen findet die datenbezogene / induktive Sät

89


4 Fallauswahl im Kontext qualitativer Daten


tigung Anwendung. Nach dieser Variante des Konzepts gilt eine Sättigung als erreicht,
wenn weiteres Datenmaterial oder eine Fortsetzung der Auswertung keine neuen
Informationen bzw. keine neuen Codes oder Kategorien mehr ergibt.


Es lassen sich verschiedene Formen von Sättigung unterscheiden. Allen ist gemeinsam, dass sie
auf dem Prinzip der Redundanz basieren. In der Forschungspraxis finden vor allem die Theoretische und die datenbezogene / induktive Sättigung Anwendung.


In der Forschungspraxis wird zwischen diesen verschiedenen Formen von Sättigung
nicht immer klar unterschieden, und auch die Kriterien dafür, wann eine Sättigung als
erreicht gilt, werden oft nicht deutlich. Deshalb wird Sättigung als Kriterium für die
induktive Bestimmung der Fallanzahl durchaus auch kritisch gesehen (z. B. Braun &
Clarke, 2019). Als Reaktion auf diese Kritik haben Forschende versucht, spezifischere
Kriterien dafür zu entwickeln, wann Sättigung als erreicht gelten kann. Hennink und
Kaiser (2022) unterscheiden drei solcher Ansätze: Operationalisierung von Sättigung
unter Rückgriff auf Codehäufigkeiten; Operationalisierung von Sättigung unter Rückgriff auf die Bedeutungshaltigkeit von Codes; und statistische Formeln zur Bestimmung der erforderlichen Fallanzahl. Wir gehen im Folgenden auf die ersten beiden
Ansätze genauer ein, nicht dagegen auf die Verwendung statistischer Formeln. Denn
diese werden vor Untersuchungsbeginn zur Bestimmung der erforderlichen Stichprobengröße angewandt und stehen somit im Widerspruch zu dem Grundgedanken, dass
Sättigung in einem iterativen, datengesteuerten Prozess verankert ist. Weiterhin basieren solche Formeln auf Annahmen wie beispielsweise einer Normalverteilung von
Codehäufigkeiten, die in der Forschungspraxis häufig nicht erfüllt sind. Wir stimmen
daher mit Hennink und Kaiser darin überein, dass solche Formeln sich nicht zur Operationalisierung von Sättigung eignen.


Es gibt drei Methoden, um zu bestimmen, ob eine Interviewstudie gesättigt ist: Rückgriff auf die
Häufigkeiten von Codes; Rückgriff auf die Bedeutungshaltigkeit von Codes; statistische Formeln.
Statistische Formeln basieren jedoch auf Annahmen, die in der qualitativen Forschung nicht erfüllt
sind. Diese Methode ist daher nicht gut geeignet.


Das häufigste Kriterium für die Operationalisierung von Sättigung in Interviewstudien ist die _Codehäufigkeit_ . Um zu bestimmen, wann die Auswertung als gesättigt
gelten kann, nutzen Autor:innen bereits abgeschlossene Studien mit einem vorliegenden Codesystem. Es wird ausgezählt, welcher Prozentsatz der Codes zu welchem
Zeitpunkt im Verlauf der Auswertung entwickelt wurde. Daraus werden Empfehlun

90


4.1 Interviews


gen abgeleitet, wie viele Interviews im Schnitt erforderlich sind, um welchen Grad der
Sättigung zu erreichen. Auf dieser Grundlage kommen mehrere Autor:innen übereinstimmend zu dem Schluss, dass eine Sättigung der Auswertung nach etwa zwölf Interviews erwartbar ist: Zu diesem Zeitpunkt waren 97 Prozent des Codesystems bereits
entwickelt (Francis et al., 2010; Guest et al., 2006; Guest et al., 2020). Diesen Studien
lag allerdings eine relativ homogene Grundgesamtheit mit eng umrissener Thematik
zugrunde.


In Interviewstudien mit einer homogenen Grundgesamtheit reichen etwa zwölf Interviews aus, um
eine Sättigung von Codes zu erreichen. Ob das tatsächlich der Fall ist, sollte man aber in einer
eigenen Studie auf jeden Fall überprüfen.


Solche Operationalisierungen von Sättigung über Codehäufigkeiten lassen sich nutzen, um vor Untersuchungsbeginn einen Rahmen für die erwartbare Fallanzahl abzustecken, die für das Erreichen von Sättigung voraussichtlich erforderlich ist. Dies ist
gerade im Kontext von Qualifikationsarbeiten oder von Anträgen hilfreich, wo meist
eine Angabe zur Stichprobengröße benötigt wird. Sie geben außerdem klare Kriterien
an die Hand, um im Rahmen eines datengesteuerten, induktiven Vorgehens zu bestimmen, ob eine hinreichende Sättigung erreicht wurde. Allerdings wurden die Operationalisierungen auch kritisiert, und zwar vor allem im Hinblick darauf, dass die verschiedenen Codes oder Themen dabei als gleichwertig betrachtet werden; der konzeptuelle
Gehalt der Codes wird nicht berücksichtigt (vgl. kritisch Braun & Clarke, 2019; Hennink et al. 2017).

Ausgehend von dieser Kritik unterscheiden Hennink et al. (2017) zwischen der Sättigung in Bezug auf Codes und der Sättigung in Bezug auf Bedeutung. Die _Sättigung_
_in Bezug auf Codes_ definieren sie, vergleichbar den gerade beschriebenen Vorschlägen,
als denjenigen Zeitpunkt, zu dem die Einbeziehung weiteren Datenmaterials keine
Hinweise auf neue Codes ergibt. Ihre Analyse zeigt, ebenfalls in Übereinstimmung mit
bisherigen Untersuchungen, dass die Mehrzahl der Codes bereits bei der Auswertung
der ersten neun Interviews generiert wurden, dass diese frühen Codes auch zahlenmäßig die häufigsten über alle Interviews hinweg waren, und dass die Definitionen der
Codes sich nach dem neunten Interview nicht mehr wesentlich veränderten.

Allerdings handelte es sich bei diesen früh generierten meist auch um eher konkrete
Codes. Die Autor:innen gingen daher außerdem der Frage nach, ob eine Sättigung in
Bezug auf Codes, operationalisiert durch Codehäufigkeiten, auch für ein tiefergehendes Verständnis hinreichend ist. Diese tiefer gehende, _auf Bedeutung bezogene Form der_
_Sättigung_ betrachteten sie zu dem Zeitpunkt als erreicht, an dem eine letzte Veränderung der Eigenschaften und Dimensionen eines Codes vorgenommen wurden. Bedeutungsbezogene Sättigung liegt nach dieser Definition also vor, wenn die Codes und


91


4 Fallauswahl im Kontext qualitativer Daten


ihre Dimensionen soweit ausgearbeitet sind, dass keine weiteren Änderungen mehr
erforderlich sind. Ihre Analyse an Hand einer Beispielstudie zeigt, dass der Zeitpunkt
der bedeutungsbezogenen Sättigung für die verschiedenen Codes unterschiedlich ausfiel; für manche Codes konnte eine Sättigung erst nach der Analyse von 24 Interviews
erreicht werden. Diese Codes waren eher konzeptuell-analytisch angelegt; sie wurden
teilweise erst zu einem späteren Zeitpunkt in der Analyse entwickelt; und die konzeptuell reichhaltigen Codes waren nicht unbedingt diejenigen, die am häufigsten verwendet wurden. Henning et al. schließen daraus, dass eine Sättigung in Bezug auf
Codes für ein tiefer gehendes Verständnis des Datenmaterials nicht ausreicht.


Codebezogene Sättigung ist nicht gleichbedeutend mit bedeutungsbezogener Sättigung. Um relevante Themen und Kategorien hinreichend auszuarbeiten, sind meist deutlich mehr als zwölf Interviews erforderlich. Auch sind dabei vor allem konzeptuelle Codes von Bedeutung, die erst später
im Analyseverlauf entstehen.


Für die Forschungspraxis ist dieser Befund nicht gleichbedeutend damit, dass die
code-bezogene Form der Sättigung, die sich auf Codehäufigkeiten stützt, wertlos
wäre. Vielmehr wird deutlich, dass es wichtig ist, sich darüber im Klaren zu sein, welches Modell von Sättigung man in der eigenen Interviewstudie heranzieht. Die bedeutungsbezogene Form der Sättigung nach Hennink et al. erinnert stark an die Theoretische Sättigung im Rahmen der GTM (s. o. 3.1). Und es leuchtet unmittelbar ein,
dass bloße Codehäufigkeiten nicht ausreichen, um festzustellen, ob eine solche Theoretische Sättigung erreicht ist. Wenn man sich dagegen an der datengesteuerten Sättigung orientiert, dann können die vorgeschlagenen Operationalisierungen codebezogener Sättigung durchaus wertvolle Hinweise bieten. Untersuchungen wie die von
Guest et al., Francis et al. oder Hennink et al. können außerdem die Vermutung stützen, dass diejenigen Codes oder Themen, die nach neun bis zwölf Interviews generiert wurden, auch die Mehrzahl der relevanten Codes darstellen. Dabei sollte man
allerdings berücksichtigen, dass diese Zahlen aus Untersuchungen mit eng umrissener Fragestellung und eher homogenen Grundgesamtheiten stammen. Es ist zu vermuten, dass die Anzahl an Interviews, die für eine codebezogene, datengesteuerte
Sättigung erforderlich sind, bei heterogenen Grundgesamtheiten oder breiter angelegten Fragestellungen höher ausfallen dürfte. Auch sollte man bei der Wahl eines
Sättigungsmodells prüfen, inwieweit das Modell mit den Grundannahmen übereinstimmt, die dem Forschungsdesign oder dem Auswertungsverfahren zugrunde liegen. Wenn man beispielsweise ein GTM-Design ansetzt, wäre es verfehlt, sich nur auf
die datengesteuerte Sättigung zu beschränken. Braun und Clarke (2019) lehnen eine
rein datengesteuerte Sättigung im Rahmen einer Auswertung mittels reflexiver thematischer Analyse ebenfalls ab.


92


4.1 Interviews


Wenn man in einer Interviewstudie das Kriterium der Sättigung heranzieht, um zu bestimmen,
wann eine hinreichende Fallanzahl erreicht ist, sollte man:


(1) Sich für ein spezifisches Modell der Sättigung entscheiden und

(2) Prüfen, inwieweit das Modell mit den Grundannahmen des Untersuchungsdesigns verein
bar ist.


4.1.2 Fallauswahl beim Experten- und beim narrativen Interview


Abschließend wollen wir hier noch auf Besonderheiten der Fallauswahl von zwei Interviewformen genauer eingehen, dem Experteninterview sowie dem narrativen Interview.
Beim _Experteninterview_ handelt es sich in der Regel um ein Leitfadeninterview, das sich
durch die spezielle Zielgruppe der Expert:innen auszeichnet. Als Expert:innen werden
mit Przyborski und Wohlrab-Saar (2008, S. 133) Personen mit ganz bestimmtem Rollenwissen und auf diesem Wissen basierenden Kompetenzen verstanden. Aus dieser Definition folgt, dass es sich bei Expert:innen vielfach um Personengruppen handelt, die nur
schwer zugänglich und erreichbar sind – man denke beispielsweise an Bundestagsabgeordnete oder die CEOs von DAX-Unternehmen. Für solche Personengruppen wurde
oben (2.5) das Schneeballverfahren als geeignete Vorgehensweise bei der Fallauswahl
beschrieben. Besonders hilfreich ist es dabei, wenn bestimmte Expert:innen wiederholt von anderen Expert:innen genannt werden. Solche Personen, denen im Feld besonders hohe Kompetenz zugeschrieben wird, sollten möglichst in die Stichprobe einbezogen werden. Ob dabei eine homogene oder eine heterogene Stichprobe angestrebt wird,
hängt jeweils von der Fragestellung ab. Wenn die interessierende Gruppe von Expert:innen gut zugänglich ist, können auch andere Verfahren der Fallauswahl und Vorgehensweisen zur Anwendung kommen; Bogner et al. (2009, S. 34ff.) empfehlen beispielweise
auch das Theoretical Sampling im Rahmen eines GTM-Ansatzes.


Beim Interview mit Expert:innen eignet sich besonders das Schneeballverfahren für die Fallauswahl.


Auch beim _narrativen_ und biographischen Interview sind bei der Fallauswahl Besonderheiten zu beachten. Im Vergleich zum Leitfadeninterview sind diese Interviews
offener konzipiert, decken einen umfangreicheren Gegenstandsbereich ab (bis hin zur
ganzen Lebensgeschichte der Interviewpartner:innen) und erstrecken sich teilweise
über mehrere Sitzungen. Damit sind sowohl für die Interviewpartner:innen als auch
die Forschenden höhere Anforderungen verbunden. Für die Untersuchungsteilnehmer:innen bedeutet dieser größere Umfang narrativer Interviews, dass sie die erfor

93


4 Fallauswahl im Kontext qualitativer Daten


derliche Bereitschaft und auch Zeit mitbringen müssen; dadurch schränkt sich der
Kreis in Frage kommender Interviewpartner:innen ein. Auch forschungsseitig ist mit
der Durchführung und Auswertung narrativer Interviews ein höherer Aufwand verbunden. Das hat wiederum Auswirkungen darauf, wie viele Teilnehmer:innen realistischerweise in die Untersuchung einbezogen werden können. Wir haben oben beschrieben (1.4), dass die Fallauswahl immer einen Kompromiss zwischen Tiefe und Breite
beinhaltet. Narrative Interviews sind auf eine größere Tiefe hin angelegt; das bedeutet
zugleich, dass sie hinsichtlich der Breite eingeschränkt sind: Es können meist weniger
Personen in die Untersuchung einbezogen werden als beim Leitfadeninterview, teilweise sogar nur ein oder zwei (Creswell & Poth, 2024, S. 188ff.; Guettermann, 2015
nennt allerdings höhere Fallzahlen). Bei der Fallauswahl können sämtliche Strategien
und Verfahren zur Anwendung kommen, die wir oben beschrieben haben (Kap. 2).
Gerade bei geringen Fallzahlen bieten sich insbesondere Überlegungen an, wie sie
auch Auswahlentscheidungen bei der Fallstudie zugrunde liegen. Außerdem sind bei
narrativen Interviews Gesichtspunkte der internen Validität von Bedeutung (s. u. 5.5).
Es ist also darauf zu achten, ob das narrative Interview – über eine oder mehrere Sitzungen hinweg – auch tatsächlich alle relevanten Aspekte der Erzählung einer Person
abdeckt. Wenn daran Zweifel bestehen, sollten weitere Gespräche mit derselben Person stattfinden, soweit dies möglich ist.


Beim narrativen Interview kommt der internen Validität des Interviews eine besondere Bedeutung

zu. Man sollte daher darauf achten, auch wirklich alle Aspekte einer Erzählung abzudecken. Das kann

bedeuten, dass mehrere Interviews mit derselben Person in Folge durchgeführt werden müssen.


4.2 Fokusgruppen


In Fokusgruppen diskutieren meist zwischen sechs und zwölf Personen an Hand eines
thematischen Leitfadens und unter der Leitung eines Moderators oder einer Moderatorin Aspekte der Forschungsfrage. Fokusgruppen sind mehr als Gruppeninterviews,
denn neben den Erfahrungen, Meinungen und Argumenten, die die Teilnehmer:innen
im Diskussionsverlauf äußern, sind hier auch die Interaktionsdynamiken innerhalb
der Gruppe von Interesse. Fokusgruppen eignen sich daher besonders für die Untersuchung kollektiver Phänomene und für die Einbeziehung unterschiedlicher Perspektiven auf ein Phänomen.

Bei der Fallauswahl für die Durchführung von Fokusgruppen sind vier Entscheidungen zu treffen. Erstens ist festzulegen, welche Personengruppen überhaupt für die Teilnahme in Frage kommen. Zweitens sind Entscheidungen darüber zu treffen, wie groß
die Fokusgruppen jeweils sein sollen bzw. wie viele Personen jeweils an einer Fokus

94


4.2 Fokusgruppen


gruppe teilnehmen sollen. Eng mit dieser zweiten Entscheidung verknüpft ist auch die
Frage nach der Zusammensetzung der Gruppen. Drittens ist zu überlegen, wie viele
Fokusgruppen insgesamt durchgeführt werden sollen; damit ist wiederum eine Entscheidung über die Gesamtzahl der Teilnehmer:innen verbunden. Und viertens stellt
sich die Frage, wie die Teilnehmer:innen konkret ausgewählt werden sollen, welche
Vorgehensweise also zur Anwendung kommt.


Bei der Durchführung von Fokusgruppen sind vier Entscheidungen zu treffen, die mit der Fallauswahl zusammenhängen, und zwar hinsichtlich:


(1) Relevanter Personen(gruppen)
(2) Umfang und Zusammensetzung der Gruppen
(3) Anzahl der Teilnehmer:innen insgesamt
(4) Vorgehensweise bei der Auswahl.


In Bezug auf die erste Frage nach relevanten Personengruppen geht es um die _Festle-_
_gung einer Zielpopulation_ bzw. darum, welche Kriterien die Personen erfüllen müssen,
die für eine Teilnahme in Frage kommen. Diese Entscheidung ist in allen (qualitativen)
empirischen Studien zu treffen und ist somit keine Besonderheit der Verwendung von
Fokusgruppen als Methode der Datenerhebung. Allerdings zeichnet sich die Nutzung
von Fokusgruppen dadurch aus, dass oft mehrere Perspektiven auf ein Phänomen einbezogen werden sollen, so dass genau genommen nicht nur eine, sondern mehrere Zielpopulationen zu berücksichtigen sind. In manchen Untersuchungen ist nur eine Zielpopulation thematisch, wie beispielsweise in einer Untersuchung von Woods-Giscombé
(2010) zu der Frage, wie afroamerikanische Frauen mit Stress umgehen und welche
Rolle dabei das Black-Superwoman-Rollenbild spielt. Zielpopulation waren hier afroamerikanische Frauen. Wenn es aber beispielsweise um die Evaluation einer gesundheitsfördernden Intervention in Wohneinrichtungen für ältere Menschen geht, wie in
der Studie von Giné-Garriga et al. (2019), dann kommen _mehrere Zielpopulationen_ in
Frage: die älteren Menschen, Familienmitglieder, das Personal in den Wohneinrichtungen sowie Entscheidungsträger:innen in den Wohneinrichtungen. In der Regel werden
diese Personengruppen und weitere relevante Kriterien (insbesondere soziodemographische wie Alter oder Geschlecht) vor Untersuchungsbeginn konzeptgesteuert festgelegt. Aber es können auch im Untersuchungsverlauf weitere Gruppen und Kriterien einbezogen werden, die sich während der Durchführung als relevant erweisen.


In Studien mit Fokusgruppen sind häufig mehrere Zielpopulationen zu berücksichtigen.


95


4 Fallauswahl im Kontext qualitativer Daten


Was den _Umfang der Fokusgruppen_ betrifft, so lautet die Faustregel, dass die Gruppen
aus ca. sechs bis zwölf Personen bestehen sollten. Dahinter steht die Überlegung, dass
es in kleineren Gruppen oft schwieriger ist, eine Diskussion in Gang zu bringen. Auch
können problematische Interaktionsdynamiken zwischen einzelnen Personen (etwa
eine Argumentation, die sich aufschaukelt) die gesamte Gruppe überschatten. Morgan
(1997) empfiehlt kleine Gruppen nur dann, wenn die Teilnehmer:innen ein starkes
Interesse am Thema haben und respektvoll miteinander umgehen. Bei größeren Gruppen kann es dagegen dazu kommen, dass die Diskussion in der Gesamtgruppe auseinanderbricht und mehrere kleinere Gruppen entstehen. Auch kann es sein, dass eher
schüchterne Teilnehmer:innen in einer größeren Gruppe gar nicht erst die Gelegenheit haben, zu Wort zu kommen. Und schließlich ist auch die Leitung größerer Gruppen für die Forschenden deutlich anspruchsvoller. Aus diesen Überlegungen zur Arbeit
mit kleineren und größeren Gruppen leitet sich die Empfehlung für eine ideale Gruppengröße von sechs bis zwölf Teilnehmer:innen her. Es handelt sich aber dabei lediglich um erfahrungsbasierte Anhaltspunkte, die an die jeweilige Fragestellung und den
Kontext anzupassen sind.

Mit der Gruppengröße ist die Frage nach der _Zusammensetzung der Gruppen_ verbunden. Dabei geht es zunächst darum, ob die Gruppen in sich homogen oder heterogen sein sollen; außerdem ist zu überlegen, ob die Fokusgruppen aus natürlichen oder
sogenannten Ad-hoc-Gruppen bestehen sollen. Die Frage der Homogenität bezieht
sich darauf, ob sich innerhalb der Zielpopulation weitere Kriterien identifizieren lassen, die vermutlich im Zusammenhang damit stehen, wie die Teilnehmer:innen das
interessierende Phänomen erleben. Woods-Giscombé (2010) ging in ihrer Untersuchung zum Umgang afroamerikanischer Frauen mit Stress auf der Grundlage früherer Untersuchungen davon aus, dass das Alter und der Bildungsstand der Frauen in
Zusammenhang mit deren Stresserleben und Copingstrategien stehen. Sie legte ihre
Fokusgruppen daher so an, dass sie in Bezug auf Alter und Bildungsstand jeweils
homogen waren. In der Literatur zur Fallauswahl bei der Durchführung von Fokusgruppen wird empfohlen, die Gruppen so zusammenzusetzen, dass die Teilnehmer:innen mindestens ein zentrales Kriterium gemeinsam haben, um einen gemeinsamen
Erfahrungshintergrund sicherzustellen. So fällt es den Teilnehmer:innen leichter, sich
in der Gruppe zu äußern, und die Kontrastierung der Gruppen in Bezug auf ausgewählte Merkmale erleichtert den Forschenden den anschließenden Vergleich und die
Auswertung. Dieses Vorgehen – Homogenisierung innerhalb der Gruppen und Kontrastierung zwischen den Gruppen – wird in der Literatur auch als _Segmentierung_
bezeichnet (Morgan, 1997). Genau genommen handelt es sich dabei um die Erstellung
eines qualitativen Stichprobenplans, angewandt auf die Verwendung von Fokusgruppen zur Datenerhebung. Wie beim qualitativen Stichprobenplan ist es bei der Segmentierung ebenfalls möglich, im Untersuchungsverlauf weitere Kriterien zu ergänzen.

Wichtiger als die zielgenaue Segmentierung von Zielpopulationen und die entsprechende Zusammensetzung der Gruppen sind allerdings Überlegungen zu den _Konse-_


96


4.2 Fokusgruppen


_quenzen der Gruppenzusammensetzung_ für die Gruppendynamik und das Gesprächsklima. Morgan (1997) gibt die hilfreiche Empfehlung, dass Fokusgruppen im
Hinblick auf den (soziodemographischen) Hintergrund der Teilnehmer:innen homogen zusammengesetzt sein sollten, aber heterogen in Bezug auf deren Einstellungen.
Denn wenn die Teilnehmer:innen auch in ihren Einstellungen weitgehend übereinstimmen, dann ergeben sich letztlich kaum Anhaltspunkte für eine Diskussion: Man
ist sich einig; und dabei wird vieles vorausgesetzt und gar nicht erst diskutiert, was
für das Verständnis seitens der Forschenden gerade wichtig wäre. Wenn die Teilnehmer:innen an einer Fokusgruppe aber zu unterschiedlich sind, dann kann es entweder sein, dass auch hier gar nicht erst eine Diskussion zustande kommt und sie aneinander vorbei reden. Oder die Diskussion gerät aus der Hand, und der Fokus ist nicht
mehr aufrechtzuerhalten. Wichtig ist außerdem, dass zwischen den Teilnehmer:innen innerhalb einer Gruppe _kein Machtgefälle_ besteht. Es sollten also beispielsweise
in institutionellen Kontexten nicht Vorgesetzte und Mitarbeiter:innen an denselben
Gruppen teilnehmen. Denn in einer solchen Konstellation besteht die Gefahr, dass
sich die Teilnehmer:innen in einer hierarchie-niedrigeren Position nicht frei äußern
können, weil sie Sanktionen befürchten.


Fokusgruppen sollten aus sechs bis zwölf Personen bestehen. Sie sollten außerdem so zusammengesetzt sein, dass die Gruppen in Bezug auf soziodemographische Merkmale homogen, in
Bezug auf Einstellungen dagegen heterogen sind.


Überlegungen zur Zusammensetzung der Fokusgruppen betreffen auch die Frage, ob
die Gruppen aus natürlichen oder für die Untersuchungszwecke zusammengesetzten
Gruppen bestehen sollen. Unter _natürlichen Gruppen_ versteht man Personengruppen,
die auch unabhängig von der Untersuchung bestehen und deren Mitglieder miteinander interagieren (etwa die Lehrer:innen und Schüler:innen an einer Schule). _Ad-_
_hoc-Gruppen_ bestehen dagegen aus Personen, die einander vor Untersuchungsbeginn
nicht kennen und nur zum Zweck der Untersuchung zusammenkommen. Beide Arten
von Gruppen sind möglich. Dabei ist nur zu berücksichtigen, dass mit jeder der beiden
Gruppenarten ein je spezifischer Kontext verbunden ist und sich auf den Ablauf der
Fokusgruppen auswirkt. Wenn die Mitglieder einer Gruppe einander bereits kennen,
dann entfällt die Aufwärmphase im Diskussionsverlauf, und es fällt den Teilnehmer:innen möglicherweise leichter, sich frei zu äußern. Wenn aber innerhalb der Gruppe
Spannungen und Machtgefälle bestehen, dann kehrt sich dieser Vorteil gerade um:
Die Teilnehmer:innen fühlen sich dann in ihren Äußerungen nicht frei und die Diskussion verläuft möglicherweise schleppend. Natürliche Gruppen werfen außerdem Probleme hinsichtlich der Vertraulichkeit auf: In natürlichen Kontexten ist es wahrscheinlicher, dass Äußerungen innerhalb der Gruppe nach außen getragen werden und die


97


4 Fallauswahl im Kontext qualitativer Daten


­Sprecher:innen identifizierbar sind. Die Vor- und Nachteile von Ad-hoc-Gruppen sind
komplementär zu denen für die natürlichen Gruppen. Hier ist eine Aufwärmphase
nötig; zugleich besteht aber auch nicht die Gefahr, dass vorab bestehende Spannungen
die Gesprächsatmosphäre beeinträchtigen.

Als nächstes stellt sich bei der Fallauswahl in Untersuchungen mit Fokusgruppen
die Frage, _wie viele Gruppen_ durchgeführt werden sollen. Dazu gibt es keine verbindlichen Vorgaben. Die Anzahl der Gruppen richtet sich zum einen danach, wie viele Kriterien für die Segmentierung bzw. Kontrastierung der Gruppen herangezogen werden:
Je größer die Variabilität in der Grundgesamtheit, desto höher die Anzahl der Kriterien
und desto höher die erforderliche Anzahl der Gruppen. Idealerweise sollten für jedes
Segment, also jede Kombination von Kriterien, mindestens zwei Gruppen durchgeführt werden, um auszuschließen, dass die Äußerungen und die gruppendynamischen
Prozesse rein spezifisch für diese eine Gruppe sind. Auch in Bezug auf die Anzahl der
Gruppen ist zu überlegen, ob ein konzeptgesteuertes oder ein induktives Vorgehen das
angemessenere ist. Bei einem konzeptgesteuerten Vorgehen wird die Anzahl der Gruppen vor Untersuchungsbeginn festgelegt und im Untersuchungsverlauf ggf. induktiv ergänzt. Bei einem induktiven Vorgehen werden so lange Fokusgruppen durchgeführt, bis eine Sättigung erreicht ist. Guest et al. konnten zeigen, dass dies bereits
nach drei bis sechs Fokusgruppen der Fall ist (2016). Hennink et al. (2019) weisen
allerdings darauf hin, dass es auch für die erforderliche Anzahl an Fokusgruppen darauf ankommt, ob eine code- oder eine bedeutungsbezogene Form der Sättigung angestrebt wird, wobei eine bedeutungsbezogene Sättigung deutlich mehr Gruppen erfordert (s. o. 4.1). Nicht zuletzt richtet sich die konkrete Entscheidung hinsichtlich der
Anzahl an Gruppen aber auch nach den verfügbaren Ressourcen. Ein Team von zwei
Forschenden wird sich beispielsweise schwer damit tun, 15 Gruppen à acht Personen
durchzuführen und auszuwerten. Die Anzahl an Gruppen stellt also letztlich einen
Kompromiss aus der Berücksichtigung von Variabilität in den Zielpopulationen und
den verfügbaren Ressourcen dar.


Die Anzahl durchzuführender Fokusgruppen richtet sich nach der Anzahl der Kriterien zur Segmentierung und nach den forschungspraktischen Ressourcen.


Was schließlich die konkrete Auswahl von Personen betrifft – also das Sampling
Scheme –, so können in Untersuchungen mit Fokusgruppen beliebige Auswahlverfahren zur Anwendung kommen. Eine Ad-hoc-Auswahl ist ebenso möglich wie eine
Zufallsauswahl oder die Nutzung des Schneeballverfahrens.


98


4.2 Fokusgruppen


**Untersuchungsbeispiel: Warnhinweise auf Packungen für Zigaretten und E-Zigaretten**


Rosemary Avery und Kolleg:innen (2023) gingen in einer Studie mit Fokusgruppen zur Datenerhebung der Frage nach, wie Jugendliche und Erwachsene verschiedene Arten von Warnhinweisen auf den Packungen von Zigaretten und E-Zigaretten verstehen und wie sie auf diese Hinweise
reagieren. Sie führten insgesamt 16 Fokusgruppen durch, jeweils acht Gruppen mit Erwachsenen und mit Jugendlichen. Die Gruppen mit Erwachsenen waren in Bezug auf das Rauchverhalten geschichtet: zwei Gruppen mit Personen, die sowohl reguläre als auch E-Zigaretten rauchten; zwei Gruppen mit Personen, die von regulären auf E-Zigaretten gewechselt waren; und
vier Gruppen von Personen, die ausschließlich reguläre Zigaretten rauchten. Die Gruppen der
Jugendlichen waren in einem ersten Schritt in Bezug auf das Geschlecht homogen zusammengesetzt; es wurden also getrennte Gruppen für junge Männer und junge Frauen durchgeführt.
Außerdem waren die Gruppen in Bezug auf das Rauchverhalten ebenfalls homogen: Es wurden
je zwei Gruppen mit (ausschließlich) männlichen und (ausschließlich) weiblichen Jugendlichen
durchgeführt, die schon einmal E-Zigaretten ausprobiert hatten oder sie auch derzeit konsumierten, sowie je zwei solcher Gruppen mit Jugendlichen, die bisher weder reguläre noch E-Zigaretten konsumiert hatten. Außerdem achteten die Forschenden darauf, dass die Gruppen in Bezug
auf Einkommen, ethnische Zugehörigkeit und Bildungsstand heterogen zusammengesetzt waren.
Es konnten nur Personen teilnehmen, die mindestens über einen Highschool-Abschluss (damit
ein Mindestmaß an Lesekompetenz gegeben war, um die Warnhinweise auf den Etiketten lesen
und verstehen zu können) und über ein Mindesteinkommen von 25.000 US Dollar im Jahr verfügten. Personen, die in irgendeinem Zusammenhang mit der Tabakindustrie standen, waren von
der Teilnahme ausgeschlossen.


Avery et al. (2023) bezogen somit zwei Zielpopulationen in ihre Untersuchung ein:
Erwachsene und Jugendliche mit je unterschiedlichem Rauchverhalten, die über
ein Mindesteinkommen sowie einen Highschool-Abschluss verfügten und nicht mit
der Tabakindustrie in Verbindung standen. Die Gruppen mit Erwachsenen waren in
Bezug auf das zentrale Merkmal des Rauchverhaltens innerhalb der Gruppen homogen, zwischen den Gruppen dagegen heterogen; die Gruppen mit Jugendlichen waren
in Bezug auf Geschlecht und Rauchverhalten innerhalb der Gruppen homogen und
zwischen den Gruppen heterogen. Außerdem achteten die Forschenden darauf, dass
die Gruppen in Bezug auf verschiedene soziodemographische Merkmale heterogen
zusammengesetzt waren. Zur Gruppengröße finden sich keine direkten Angaben,
sie lässt sich jedoch erschließen: Bei 47 Erwachsenen verteilt auf acht Fokusgruppen
ergibt sich eine durchschnittliche Gruppengröße von fünf bis sechs Personen und bei
32 Jugendlichen ebenfalls verteilt auf acht Fokusgruppen bestehen die Gruppen aus
durchschnittlich vier Personen. Es handelt sich somit um eher kleine Gruppen, und
die Untersuchung zeigt, dass auch Gruppen mit weniger als sechs Personen erfolgreich


99


4 Fallauswahl im Kontext qualitativer Daten


durchgeführt werden können. Weiterhin handelte es sich um Ad-hoc-Gruppen mit Personen, die einander vor der Untersuchung nicht kannten.

Die Untersuchung verdeutlicht das Ausmaß an Planung, das bei der Nutzung von
Fokusgruppen für die Auswahl der Teilnehmer:innen und ihrer Zuordnung zu den verschiedenen Gruppen erforderlich sein kann. Sie zeigt auch, dass es sich bei der Umsetzung eines solchen Fokusgruppen-Designs wesentlich um ein konzeptgesteuertes
Vorgehen handelt – das aber, wie oben erwähnt, im Untersuchungsverlauf durchaus
induktiv um weitere Kriterien ergänzt werden kann.


4.3 Beobachtung


In der qualitativen Forschung kommt meist eine _offene_, oft auch _teilnehmende_ Form
der Beobachtung zur Anwendung, insbesondere in ethnografischen Studien (s. o. 3.3).
Sie eignet sich besonders, um das Handeln von Individuen in sozialen Situationen zu
untersuchen. Bei der teilnehmenden Beobachtung kann es sein, dass Forschende ganz
im Feld aufgehen (wenn sie beispielsweise bei der Untersuchung von Kleingärtnervereinen selbst Eigentümer:in einer Parzelle sind und auch so auftreten: Schuster, 2024);
es kann aber auch sein, dass sie eine eher marginale Rolle einnehmen (etwa bei der
Untersuchung der Interaktionen von Pflegekräften und Bewohner:innen von Seniorenheimen: Declercq, 2000). Dabei wird die Beobachtung meist nicht als alleiniges
Verfahren der Datenerhebung eingesetzt, sondern mit Methoden kombiniert, die einen
Zugang zum Erleben der Personen im Feld ermöglichen, wie etwa das Interview.

Auch die Beobachtung in der qualitativen Forschung wird von einer Forschungsfrage geleitet, die wesentlichen Einfluss auf die Auswahlentscheidungen hat, die im
Folgenden zu treffen sind. In einem ersten Schritt ist das Feld festzulegen, in dem die
Untersuchung erfolgen soll; dieses ergibt sich meist unmittelbar aus der Forschungsfrage. Zweitens sind die konkreten Schauplätze bzw. Settings auszuwählen, an bzw. in
denen beobachtet werden soll. Drittens ist zu bestimmen, zu welchen Zeiten, für wie
lange und ggf. in welchen Intervallen die Beobachtung stattfinden soll. Und viertens
sind Überlegungen dazu erforderlich, was genau innerhalb der Settings Gegenstand
der Beobachtung sein soll: welche Interaktionen, Verhaltensweisen, Ereignisse oder
auch Personen. Beobachtungseinheiten sind hier also meist nicht Personen, sondern
Situationen oder Interaktionen.

Dabei werden drei Phasen der Beobachtung unterschieden: die Einstiegs-, die
Explorations- und die Ausarbeitungsphase. In der Einstiegsphase steht zunächst ggf.
nur das Feld fest, und erste sehr offene Beobachtungen dienen dazu, geeignete Schauplätze, Zeiten und Gegenstände zu identifizieren. Über die drei Phasen hinweg werden
die Auswahlentscheidungen dann zunehmend konkreter und spezifischer. Dabei spielen dann nicht zuletzt auch Fragen der Zugänglichkeit eine Rolle.


100


4.3 Beobachtung


In Beobachtungsstudien sind folgende Auswahlentscheidungen zu treffen:


(1) Auswahl des Feldes
(2) Auswahl der Settings im Feld, in denen beobachtet werden soll
(3) Bestimmung der Zeiten, zu denen beobachtet werden soll
(4) Was beobachtet werden soll.


Zu Beginn der Untersuchung ist die Beobachtung oft eher frei, und Auswahlentscheidungen werden über den Untersuchungsverlauf hinweg zunehmend konkreter.


**Untersuchungsbeispiel: Handlungsspielräume von Kindern auf der Flucht**


Bernadette van Berk (2024) befasste sich in ihrer Forschung mit dem Alltag von Kindern in Auffanglagern für Geflüchtete. Sie führte eine qualitative Beobachtungsstudie durch, um zu untersuchen, welche Handlungsspielräume den Kindern im Rahmen sogenannter Child Friendly Spaces in
Flüchtlingslagern ermöglicht werden und wie die Kinder diese Spielräume gestalten. Die Beobachtung erfolgte teilnehmend, wobei van Berk keine genaueren Angaben zu der Art ihrer Teilnahme
macht; vermutlich war sie an der Betreuung der Kinder beteiligt.
Mit der Forschungsfrage ist in diesem Beispiel zugleich auch das Feld festgelegt, nämlich Child
Friendly Spaces in Auffanglagern für Geflüchtete. Van Berk macht keine Angaben dazu, wie viele
solcher Räume speziell für Kinder zum Zeitpunkt ihrer Untersuchung im Jahr 2019 existierten.
Sie wählte als Schauplatz ein Lager in Griechenland, das einen solchen Raum anbietet, wobei sie
zugleich herausarbeitet, dass die Auffanglager in Griechenland intrinsisch relevant sind. Der Raum
für die Kinder war viermal pro Woche für je zwei Stunden geöffnet. Zu diesen Zeiten hielt sich die
Forscherin über einen Zeitraum von vier Wochen jeweils für die gesamten zwei Stunden in dem
Raum auf; außerdem beobachtete sie auch die Vor- und Nachbereitungen, so dass die Beobachtungszeit pro Tag insgesamt etwa fünf bis sechs Stunden umfasste. Der Zeitraum von vier Wochen
war vermutlich ad hoc gewählt.
Die Beobachtung verlief in den drei oben genannten Phasen. In der ersten Phase war die Beobachtung zunächst offen; sie diente der Identifikation relevanter Interaktionsformen. In der zweiten
Phase war die Beobachtung auf solche Interaktionen fokussiert, bei denen Routinen und / oder
Formen der Mitbestimmung der Kinder im Mittelpunkt standen. In der dritten Phase lehnte die Forscherin ihr Vorgehen an das Theoretical Sampling an und nutzte das Prinzip der Kontrastierung,
um gezielt eventuelle Gegenbeispiele zu beobachten. Die Beobachtungen wurden in Beobachtungsprotokollen festgehalten. Außerdem führte van Berk ein Forschungstagebuch und sammelte
Dokumente wie Liedtexte, die als Kontextinformationen über die Gestaltung der Child Friendly
Spaces dienen konnten.


101


4 Fallauswahl im Kontext qualitativer Daten


Die obige Studie verdeutlicht sowohl die verschiedenen Auswahlentscheidungen, die
bei einer Beobachtungsstudie zu treffen sind, als auch das zunehmend stärker fokussierte Vorgehen bei der Beobachtung in der qualitativen Forschung. Zugleich handelt
es sich um eine Studie, in der die Beobachtung unvermittelt erfolgt.

Von der _unvermittelten_ ist die _technisch vermittelte Beobachtung_ zu unterscheiden,
bei der die Forschenden nicht selbst anwesend sind, sondern das Geschehen im Feld
aufzeichnen. Im Zusammenhang mit der Gesprächsforschung und der Konversationsanalyse sind natürliche Gespräche zu bestimmten Themen, etwa zwischen Partner:innen oder in Familien von Interesse. Heute ist die _Videographie_ gebräuchlicher, d. h. die
Aufzeichnung des Geschehens im Feld mit Bild und Ton mittels Videokamera. Die Nutzung einer Videoaufzeichnung erlaubt einerseits längere Beobachtungszeiträume im
Vergleich zur unvermittelten Beobachtung durch einzelne Forschende. Das wirft allerdings zugleich auch ethische Bedenken auf, da Fragen von Einwilligung und Transparenz durch die längeren Beobachtungszeiträume schwieriger zu handhaben sind.
Mit den längeren Zeiträumen sind außerdem weitere Entscheidungen im Hinblick auf
den Beobachtungsgegenstand verbunden (Tuma & Schnettler, 2019). Denn anders
als menschliche Beobachter:innen ist eine Kamera stationär. Das bedeutet, dass vorab
festzulegen ist, mit wie vielen Kameras beobachtet, wo und in welchem Winkel diese
aufgestellt werden sollen. Das bedeutet außerdem, dass bei der technisch vermittelten Beobachtung deutlich mehr Material anfällt als bei einer unvermittelten Beobachtung, so dass Auswahlentscheidungen nicht nur vor Beginn der Datenerhebung, sondern auch vor Beginn der Auswertung zu treffen sind: Welche Teile des umfangreichen
Materials sollen in die Auswertung einbezogen werden? Hierfür werden in der Regel
besonders informationshaltige und dichte Sequenzen herangezogen.


Die technisch vermittelte unterscheidet sich in zweierlei Hinsichten von der unvermittelten Beobachtung:


  - Es sind teilweise andere Entscheidungen zu treffen, beispielsweise über die Positionierung von

Kameras.

  - Es fällt mehr Material an, so dass vor der Auswertung weitere Auswahlentscheidungen zu tref
fen sind. Dabei sind vor allem dichte Materialsequenzen von Interesse.


Eine weitere Form der Beobachtung kommt in der _Digitalen Ethnografie_ zur Anwendung, also in einer Variante der Ethnografie, bei der sich zumindest ein Teil des Feldes
im digitalen Raum befindet, beispielsweise bei der Untersuchung von Online-Gemeinschaften. Dies beeinflusst die Auswahlentscheidungen, die zu treffen sind, in mehrfacher Weise. Zunächst ist zu berücksichtigen, dass das Feld sich im digitalen Raum
schwerer bestimmen lässt als in der traditionellen Ethnografie. Vielmehr ist es typisch,


102


4.4 Auswahl aus Dokumenten


dass mehrere Felder von Bedeutung sind und teilweise ineinander übergehen ( _Multi-_
_Sited Ethnography_ ). Heike Greschke (2007) bezog in ihre Untersuchung eines Diskussionsforums für Paraguyaner:innen in der Migration beispielsweise auch offline-Treffen
mit ein, um gerade die Relation von online- und offline-Kommunikation und Kontakten genauer zu explorieren. Damit wird zugleich auch deutlich, dass ein Feld nicht einfach außerhalb der Beobachter:innen an sich existiert, sondern dass die Forschende in
ihren Auswahlentscheidungen dieses Feld aktiv mitkonstituieren.

Ein weiterer Unterschied zwischen der Beobachtung im digitalen Raum und der
Beobachtung in offline-Umgebungen besteht in der Art der Daten. Offline fertigen
die Beobachter:innen Protokolle und Feldnotizen an; die Beobachter:innen sind somit
selbst das Beobachtungsinstrument, zumindest bei der unvermittelten Beobachtung.
Bei der Beobachtung in digitalen Räumen können die Forschenden dagegen auf ganz
andere Arten von Daten zurückgreifen (Purdam & Elliott, 2015). Meist handelt es sich
dabei um vorgefundene Daten, die unabhängig von der Forschungssituation entstanden und öffentlich verfügbar sind, wie beispielsweise Webseiten oder Blogs. Bedeutsam sind ebenfalls Daten aus sozialen Medien, etwa Posts auf Instagram, TikTok, Facebook usw. sowie Likes und Kommentare zu diesen Posts (Diskussionsthreads: s. u. 4.5).
Bei der Nutzung von vorgefundenen Daten handelt es sich um eine Form der _non-reak-_
_tiven Beobachtung_ (weil die Daten in keiner Weise durch eine Reaktion auf die Anwesenheit von Forschenden im Feld geformt sind). Die Daten lassen sich als eine spezielle
Form von Dokumenten auffassen, auf die wir in Abschnitt 4.4 genauer eingehen. Auch
Auswahlentscheidungen bei der Nutzung von Daten aus sozialen Medien besprechen
wir in einem separaten Abschnitt (4.5) genauer.


Die Digitale Ethnografie zeichnet sich dadurch aus, dass das Feld hier schwerer einzugrenzen ist
als in der traditionellen Ethnografie. Außerdem stehen den Forschenden zusätzliche, vorgefundene
Daten zur Verfügung.


4.4 Auswahl aus Dokumenten


Unter _Dokumenten_ verstehen wir hier mit Grant (2019) Inhalte oder Gegenstände, die
schriftliches, bildliches oder anderes Material umfassen, mit dem Ziel, Informationen
oder Bedeutungen aufzubewahren oder zu übertragen. Im Alltag denken wir bei Dokumenten vielleicht an Geburtsurkunden, Gesetzestexte oder Briefe bedeutsamer historischer Persönlichkeiten. In den Sozialwissenschaften – und das wird an Hand dieser
Definition deutlich – ist der Dokumentbegriff jedoch deutlich weiter gefasst: Nicht
nur Texte gelten als Dokumente, sondern auch Bilder in Fotoalben, Kinofilme, NetflixSerien, Computerspiele oder sogar Gegenstände haben dokumentarischen Charakter.


103


4 Fallauswahl im Kontext qualitativer Daten


Eine Vielzahl von Dokumenten findet sich auch im digitalen Raum: Inhalte von Webseiten, Blogs, Facebook-Posts usw. Da digitale Dokumente sich jedoch durch zusätzliche Eigenschaften auszeichnen, die auch Konsequenzen für die Fallauswahl haben,
werden digitale Materialien in einem eigenen Unterkapitel behandelt (s. u. 4.5). Im
Folgenden konzentrieren wir uns auf die Nutzung nicht-digitaler Dokumente als zentraler Datenquelle (Rapley & Reese, 2018).


4.4.1 Auswahl von textbasierten öffentlichen Dokumenten


Traditionell wird zwischen öffentlichen und Egodokumenten unterschieden (zu Egodokumenten s.u.). _Öffentliche Dokumente_ lassen sich noch einmal weiter unterteilen in
mediale (Zeitungen, Zeitschriften, Bücher, Filme, TV-Serien usw.), offizielle (z. B. Jahrbücher, Broschüren, Flugblätter, Gesetzestexte, Parteiprogramme usw.) und interne
Dokumente (Verwaltungsnotizen, Gesprächsprotokolle usw.). Eine Vielzahl von öffentlichen Dokumenten ist heutzutage _digitalisiert_ und über Online-Archive auffindbar und
aufrufbar.

_Mediale Dokumente_, insbesondere Ausgaben von Zeitungen und teilweise auch Zeitschriften, liegen vielfach auf Mikrofiche vor und können, wenn sie nicht bereits digitalisiert sind, in Archiven vor Ort eingesehen werden. In Studien mit Material aus Zeitungen sind, ausgehend von der Forschungsfrage, in einem ersten Schritt relevante
Zeitungen auszuwählen. Dabei wird – wiederum abhängig von der Forschungsfrage –
meist versucht, ein eher breites Spektrum abzudecken, also beispielsweise Zeitungen sowohl aus dem linken Meinungsspektrum, dem rechten und dem in der Mitte.
In einem zweiten Schritt ist der Untersuchungszeitraum festzulegen. Diese Auswahl
erfolgt meist kriterienorientiert, d. h. es wird ein Zeitraum ausgewählt, in dem möglichst viele relevante Artikel zu erwarten sind. In einem dritten Schritt findet schließlich die Auswahl der Artikel selbst statt. Hierfür ist zunächst die Grundgesamtheit aller
in Frage kommenden Artikel zu bestimmen, also der Artikel, die innerhalb des ausgewählten Zeitraums innerhalb der ausgewählten Publikationen veröffentlicht wurden.
Wenn das Material digitalisiert wurde, stellt die kommerzielle Datenbank LexisNexis
eine gute Möglichkeit dar, diese Artikel mittels relevanter Suchbegriffe zu identifizieren. Das weitere Vorgehen richtet sich nach der Anzahl relevanter Artikel. Wenn viele
Artikel gefunden wurden, muss die Stichprobe weiter eingeengt werden. Eine Strategie, die bei der Nutzung von Tageszeitungen Anwendung findet, ist die Auswahl einer
sogenannten künstlichen Woche. Für Woche eins werden beispielsweise alle Artikel
berücksichtigt, die an einem Montag erschienen sind, für Woche zwei alle Artikel
an einem Dienstag usw. So können Verzerrungen vermieden werden, wie sie durch
Schwerpunkte der Berichterstattung an bestimmten Wochentagen zustande kommen
können. Aber andere Vorgehensweisen sind ebenso möglich, etwa eine Zufallsauswahl
oder auch die kriterienorientierte Auswahl besonders einschlägiger Artikel.


104


4.4 Auswahl aus Dokumenten


Bei der Auswahl medialer Dokumente, hier am Beispiel von Zeitungen, sind folgende Auswahlentscheidungen zu treffen:


  - Auswahl der Zeitungen

  - Auswahl eines Untersuchungszeitraums

  - Auswahl von Artikeln.


**Untersuchungsbeispiel: Berichterstattung über Trauerfälle in der Corona-Pandemie**


Ryann Sowden, Erica Borgstrom und Lucy Selman (2021) beschäftigten sich in ihrer Dokumentenanalyse mit der Berichterstattung über Trauer und Verlust zu Beginn der Corona-Pandemie in
Zeitungen im Vereinigten Königreich. Die Autor:innen listeten die verfügbaren Zeitungen zunächst
nach der Größe ihrer Leserschaft auf und wählten sieben Zeitungen mit der größten Leserschaft
innerhalb bestimmter Populationssegmente für die weitere Analyse aus. Dabei waren sie von der
Annahme geleitet, dass Zeitungen mit einer größeren Leserschaft auch vermehrt dazu beitragen,
das Bild über Todesfälle, Trauer und Verlust in der Öffentlichkeit zu formen. Bei der Bestimmung
relevanter Populationssegmente achteten sie darauf, dass Zeitungen mit hoher Leserschaft für
verschiedene Altersgruppen und verschiedene ethnische Gruppierungen in ihrer Stichprobe vertreten waren. Weiterhin wählten sie die Zeitungen so aus, dass sie ein breites Spektrum politischer Orientierungen abdeckten. Der Untersuchungszeitraum wurde nach dem Prinzip der Relevanz bestimmt, nämlich vom 18.3. bis 20.4.2020. Diese vier Wochen umfassten die Zeit kurz vor
dem ersten Lockdown, die Zeit unmittelbar nach dem ersten Lockdown sowie die Zeit kurz vor der
Verlängerung des ersten Lockdowns.
Im nächsten Schritt wurde online innerhalb der ausgewählten Zeitungen und des ausgewählten
Zeitraums eine Stichwortsuche unter Verwendung der Suchbegriffe „grief“ oder „bereavement“
in Kombination mit „Covid-19“ durchgeführt (und vergleichbaren Suchbegriffen, die sich auf die
Erkrankung beziehen). Die Suchergebnisse wurden von den Autor:innen in Bezug auf Relevanz
durchgesehen, und nicht relevante Ergebnisse (wie etwa Todesanzeigen) wurden von der weiteren
Analyse ausgeschlossen. Danach verblieben noch 111 relevante Artikel – zu viele für eine detaillierte qualitative Analyse. Die Autor:innen trafen daher eine weitere Auswahl basierend auf dem
Zeitpunkt der Veröffentlichung: Sie konzentrierten sich in ihrer Analyse ausschließlich auf die erste
und die vierte Woche des relevanten Zeitraums und somit auf 55 Artikel.


Diese Untersuchung von Sowden et al. (2021) verdeutlicht die Schritte, die bei der Auswahl aus Printmedien für eine Dokumentenanalyse zu beachten sind. Sie stellt außerdem
ein Beispiel dafür dar, dass die Anzahl an einschlägigen verfügbaren Quellen oft die Möglichkeiten der Forschenden übersteigt, so dass hier eine weitere Auswahl zu treffen ist.


105


4 Fallauswahl im Kontext qualitativer Daten


Neben medialen zählen auch _offizielle_ und _interne_ Dokumente wie Handbücher,
Gesetzestexte usw. zu den öffentlichen Dokumenten, die meist online oder auch in
Archiven verfügbar sind. Bei zeitgenössischen Dokumenten ist allerdings darauf zu
achten, ob die interessierenden Dokumente auch für die Öffentlichkeit zugänglich
sind. Vor dem Besuch eines Archivs sind daher die Zugangsmöglichkeiten abzuklären
und es ist ggf. ein Nutzungsantrag zu stellen (manchmal Monate im Voraus). Sinnvoll
ist es auch, sich vorab mit den sogenannten. Findmitteln eines Archivs, d. h. mit den
Verzeichnissen des Bestands von Dokumenten in einem Archiv, (digitalisierten) Katalogen usw. zu befassen. Die Verzeichnisse geben Aufschluss darüber, welche Dokumente im Archiv verfügbar sind und stellen somit den Ausgangspunkt für die Zusammenstellung einer Stichprobe dar (Franken, 2022).


Öffentliche Dokumente sind, trotz ihrer Bezeichnung, nicht immer online oder in Archiven zugänglich. Vor dem Besuch eines Archivs sollte man daher die Zugangsmöglichkeiten abklären und ggf.
einen Zugang beantragen.


Rapley und Reese (2018) raten dazu, bei der Auswahl von (offiziellen) Dokumenten auch deren Qualität mit zu berücksichtigen. Diese bemisst sich an den folgenden
Kriterien: Authentizität, Glaubhaftigkeit, Repräsentativität und Bedeutung. _Authen-_
_tizität_ bezieht sich auf die Frage, ob es sich tatsächlich um ein originales Dokument
handelt, ob der Text vollständig verfügbar ist, und ob sich die Autorschaft eindeutig
feststellen lässt. _Glaubhaft_ ist ein Dokument in dem Maß, in dem man davon ausgehen
kann, dass der/die Autor:in aufrichtig bzw. wahrheitsgemäß schreibt. _Repräsentati-_
_vität_ bezieht sich darauf, inwieweit die noch verfügbaren Dokumente das tatsächliche Spektrum an Dokumenten für den jeweiligen Untersuchungszeitpunkt abdecken;
Ziel der Auswahl öffentlicher Dokumente ist es in der Regel, das gesamte Spektrum
an Dokumenten abzubilden, soweit diese noch verfügbar sind. Mit dem letzten Qualitätskriterium, der _Bedeutung_, ist die Frage thematisch, inwieweit es – gerade bei historischen Dokumenten – den Forschenden möglich ist, deren Bedeutung in ihrem
jeweiligen soziohistorischen Kontext zu verorten und zu erschließen. Ziel ist es, die
Dokumente für die weitere Analyse so auszuwählen, dass sie diese Qualitätskriterien
möglichst gut erfüllen.

Gerade im Hinblick auf die Repräsentativität der Dokumente ist auch zu berücksichtigen, dass die verfügbaren Dokumente notwendig _selektiv_ sind: Es wird nicht
alles aufbewahrt, und Entscheidungen darüber, was aufbewahrt wird, sind strategisch motiviert (man denke nur an die letzten Wochen der DDR und die massenhafte
Zerstörung von Akten der Staatssicherheit). Bei organisationsinternen Dokumenten
(etwa geschäftliche Korrespondenz) ist außerdem zu berücksichtigen, dass die Organisation möglicherweise ein Interesse daran hat, den Forschenden nicht alle Materia

106


4.4 Auswahl aus Dokumenten


lien zugänglich zu machen, was ebenfalls zur Selektivität des Datenmaterials beiträgt.
Auch kann es bei der Erstellung von Dokumenten zu Übertragungsfehlern kommen.
All dies sind Aspekte des Kontextes, in den Dokumente zu stellen sind und der bei der
anschließenden Analyse und Interpretation zu berücksichtigen ist.


Bei der Auswahl öffentlicher, insbesondere offizieller Dokumente sollte man auf deren Qualität
achten. Diese hängt von der Authentizität, der Glaubhaftigkeit und der Möglichkeit ab, ihre Bedeutung in ihrem historischen Kontext zu verstehen und zu erschließen. In Bezug auf die Repräsentativität ist zu beachten, dass verfügbare Dokumente häufig selektiv sind: Es ist nur eine Auswahl
aus der Gesamtheit der Dokumente auch tatsächlich zugänglich.


Neben den öffentlichen kommt auch _Ego-Dokumenten_ ein wichtiger Stellenwert in
der sozialwissenschaftlichen Forschung zu, wie beispielsweise Briefen, Tagebüchern,
familiären Fotoalben usw. Wenn es sich nicht um die Ego-Dokumente von Personen
des öffentlichen Interesses handelt (die, wie öffentliche Dokumente, in Archiven verfügbar sind), ist ein Zugang hier in der Regel nur möglich, indem Forschende gezielt
Personen kontaktieren, die im Besitz entsprechender Dokumente sind. Soweit überhaupt genügend Material verfügbar ist, um eine Auswahl zu treffen, greifen hier dieselben Qualitätskriterien wie bei der Auswahl öffentlicher Dokumente.


4.4.2 Auswahl von visuellem Material


Wie zu Beginn dieses Abschnitts beschrieben, umfassen Dokumente nicht nur schriftliche Materialien; auch Bilder, Filme, multimodales Material (also Material, das mehrere Modalitäten in sich vereint, etwa Bild, Ton und Text), Gegenstände oder Töne
können als Dokumente von Interesse sein. Da Bild- und Filmmaterial unter diesen
verschiedenen Modalitäten von Dokumenten der höchste Stellenwert zukommt, konzentrieren wir uns im Folgenden auf solche _visuellen Dokumente_ . Für _Fotos_ gilt dabei
dasselbe wie für schriftliche Dokumente: Es kann sich um öffentliche Dokumente handeln oder um persönliche Ego-Dokumente. Öffentliche Bilddokumente sind ebenso
wie Textdokumente online oder in Archiven verfügbar, während persönliche Dokumente meist nur über den direkten Kontakt mit einschlägigen Personen zugänglich
sind (oder über Haushaltsauflösungen u. ä.). Die Bilderkennung ist inzwischen soweit
fortgeschritten, dass eine Online-Suche nach Bildern zu ausgewählten Themen problemlos möglich und meist auch ergiebig ist – teilweise so ergiebig, dass die Materialfülle anschließend durch weitere Kriterien wie Spezifikation des Untersuchungszeitraums oder auch eine Zufallsauswahl weiter einzuschränken ist. Allerdings sind die
Algorithmen nicht öffentlich verfügbar, nach denen Bildmaterial von Suchmaschinen


107


4 Fallauswahl im Kontext qualitativer Daten


ausgewählt und aufgelistet wird. Dies ist bei der Beurteilung der Repräsentativität des
Materials als Einschränkung zu berücksichtigen.


Bei der Auswahl von Fotos gelten dieselben Überlegungen wie bei der Auswahl von Textdokumenten.


_Filme_ können ebenfalls öffentliche oder persönliche Dokumente darstellen; sofern
es sich nicht um Online-Material handelt (s. u. 4.5), ist allerdings die Untersuchung
öffentlicher, kommerzieller Filme häufiger, weshalb wir uns hier auf solche Filme
konzentrieren. Dabei ist in einem ersten Schritt ein Korpus von Filmen zu erstellen,
das für die Untersuchung der Forschungsfrage geeignet ist. Die Erstellung kann sich
an zeitlichen Kriterien orientieren (beispielsweise Filme, die in der Nachkriegszeit
von Juni 1945 bis Dezember 1949 produziert wurden), an räumlichen (etwa dem
französischen Kino) oder inhaltlichen (Filme mit neurodiversen Hauptfiguren). In
einem nächsten Schritt sind aus dem Korpus die zu analysierenden Filme auszuwählen. Dabei können, je nach Umfang des Korpus, sämtliche Strategien der Fallauswahl
zur Anwendung kommen, wie wir sie in Kapitel 2 dargestellt haben. Anders als bei
den anderen Dokumenten, deren Auswahl wir bisher beschrieben haben, schließt
sich bei der Analyse von Filmen nun noch ein dritter Schritt an: Es ist zu entscheiden,
für welche Einheiten die Analyse durchgeführt werden soll. Es ist möglich, Filme als
Ganzes zu analysieren, oder sie in kleinere Analyseeinheiten zu unterteilen, wobei
die Einheit so gewählt sein sollte, dass sie zur Fragestellung passt. Akremi (2019b)
unterscheidet die folgenden kleineren Einheiten: Einzelbilder, Einstellungen, Szenen
oder Sequenzen, die allerdings mehrheitlich nicht eindeutig definiert und gegeneinander abgegrenzt sind.


Die Auswahl von Filmen vollzieht sich in den folgenden Schritten:


(1) Erstellung eines Filmkorpus unter Berücksichtigung von zeitlichen, räumlichen oder inhalt
lichen Kriterien
(2) Auswahl der zu analysierenden Filme unter Anwendung beliebiger Strategien
(3) ggf. Unterteilung der Filme in kleinere Analyseeinheiten.


108


4.5 Auswahl aus digitalen Daten


4.5 Auswahl aus digitalen Daten


Der Begriff der digitalen Daten umfasst ein breites Spektrum an Datenformaten, unter
anderem Blogs, Webseiten, Instagram-Reels, Facebook-Profile und Kommentare oder
Chat-Nachrichten. Dabei handelt es sich um vorgefundene Daten (die also nicht speziell zu Forschungszwecken verfasst sind), die von Nutzer:innen kontinuierlich hergestellt und modifiziert werden. Um diese Charakteristik des Produktionsflusses abzubilden, werden digitale Daten auch als prozessproduziert bezeichnet (Franken, 2022,
S. 66ff.). Weitere wichtige Merkmale digitaler Daten werden unter den drei Vs zusammengefasst: Volume, Velocity, Variability: Sie liegen in großen Mengen vor (daher
auch die Bezeichnung als Big Data); sie entstehen mit großer Geschwindigkeit; und sie
sind ständigen Modifikationen und Veränderungen unterworfen.

Aus diesen Merkmalen digitaler Daten ergeben sich schon erste Konsequenzen für
die Fallauswahl. Aus der großen Menge folgt, dass die Stichproben – je nachdem, wie
viele Ressourcen auf Seiten der Forschenden zur Verfügung stehen – umfangreicher
sein können als sonst in der qualitativen Forschung üblich. Und die Variabilität digitaler Daten hat zur Konsequenz, dass das Material zum Zeitpunkt der Auswahl sorgfältig abgespeichert werden muss. Denn der Text auf der Webseite kann morgen schon
anders lauten, und der interessante Facebook-Kommentar wurde seit dem letzten
Zugriff vielleicht gelöscht. Digitale Daten zeichnen sich außerdem durch eine je spezifische Struktur aus. Webseiten weisen beispielsweise eine Hyperlinkstruktur auf und
sind durch eine URL identifizierbar, und viele soziale Medien-Plattformen wie Facebook oder Instagram beinhalten eine Kommentarfunktion. Diese Struktur ist bei der
Auswahl zu berücksichtigen: Sie kann die Auswahl unterstützen (s. u.); außerdem
ist zu überlegen, welche Datenarten in die Erhebung einbezogen werden sollen (beispielsweise nur der Facebook-Post oder auch die Kommentare).


Digitale Daten sind meist vorgefunden und prozessproduziert. Drei wichtige Merkmale sind:
Volume, Velocity, Variability. Diese Merkmale haben auch Konsequenzen für die Fallauswahl.


Innerhalb der Gruppe der digitalen Daten lässt sich weiter zwischen Trace Data,
Internetdaten diversen Ursprungs sowie Daten aus den sozialen Medien unterscheiden (Franken, 2022, S. 66). Als Trace Data werden die Spuren bezeichnet, die Menschen bei ihren Online-Aktivitäten erzeugen, oft ohne sich dessen bewusst zu sein, wie
etwa Logfiles oder Cookies. Diese Daten sind oft quantitativ und daher für die qualitative Forschung nicht weiter interessant, weshalb wir hier nicht genauer darauf eingehen. Im Folgenden befassen wir uns zunächst mit der Fallauswahl bei Internetdaten;
anschließend mit dem Auswahlprozess bei Daten aus den sozialen Medien.


109


4 Fallauswahl im Kontext qualitativer Daten


4.5.1 Auswahl von Internetbasierten Daten


Internetdaten diversen Ursprungs umfassen unter anderem Webseiten, Blogs, Datenarchive usw. Dabei lässt sich weiter unterscheiden zwischen retrodigitalisierten und
Born Digital Data. _Retrodigitalisierte_ _Daten_ sind solche, die ursprünglich in analoger
Form vorlagen und anschließend digitalisiert wurden, um sie so einer breiten Öffentlichkeit zugänglich zu machen. Darunter fallen beispielsweise Archive von Zeitungen, digitalisierte Manuskripte, andere Dokumente oder Online-Sammlungen von
Museen. _Born Digital Data_ wurden dagegen von vornherein in digitaler Form erstellt.
Diese Unterscheidung ist wichtig im Hinblick auf die Datenstruktur und damit wiederum für die Suchmöglichkeiten: Retrodigitalisierte Daten werden in einem ersten
Schritt erfasst und in einem zweiten Schritt erschlossen und dabei mit Metadaten versehen, also mit Informationen über diese Daten. Metadaten können bei Büchern etwa
der Name der Autor:innen, Erscheinungsjahr, ISBN usw. sein; bei Bilddaten sind beispielsweise das Format oder die Geodaten des Aufnahmeorts relevant. Metadaten
beinhalten in der Regel auch eine Beschreibung des Dokuments bzw. entsprechende
Stichworte, manchmal auch eine Verschlagwortung gemäß einem Schlagwortkatalog
(Franken, 2022, S. 79).

Eine Suche nach retrodigitalisierten Daten ist nur anhand der Metadaten möglich.
Man kann also nicht direkt in den Dokumenten suchen, sondern nur vermittelt über
entsprechende Schlagwörter oder andere Metadaten. Abgesehen von der Identifikation relevanter Metadaten unterscheidet sich die Fallauswahl bei retrodigitalisierten
Daten jedoch nicht von der Auswahl bei Dokumenten im Allgemeinen. Dabei ist allerdings zu berücksichtigen, dass Museen und Archive ihre Sammlungen erst allmählich
digitalisieren. Forschende haben daher online meist nicht auf den gesamten Bestand
Zugriff, sondern nur auf einen Teilbereich. Inwieweit die Online-Suche daher durch
einen Archivbesuch vor Ort zu ergänzen ist, ist von der Forschungsfrage abhängig.


Retrodigitalisierte Daten lagen ursprünglich in analoger Form vor. Sie wurden erst später digitalisiert und mit Metadaten versehen. Die Suche nach retrodigitalisierten Daten ist nur anhand der
Metadaten möglich, nicht in den Dokumenten selbst.


Unter den Born Digital Data sind Webseiten und Blogs am häufigsten Gegenstand sozialwissenschaftlicher Forschung. Dabei sind _Webseiten_ über eine URL eindeutig identifizierbar und eher statisch angelegt; Schünzel und Traue (2019) schreiben, dass Webseiten sozusagen an der Schnittstelle zwischen archivierten und dynamischen Dokumenten
angesiedelt sind. Auch beinhalten sie meist keine Kommentarfunktion, sind also eher
nicht auf Kommunikation ausgerichtet. _Blogs_ ist ebenfalls jeweils eine URL zugeordnet. Allerdings sind sie, anders als Webseiten, eher dynamisch angelegt und, vermittelt


110


4.5 Auswahl aus digitalen Daten


über die Kommentarfunktion, stärker auf Kommunikation orientiert (Schmidt, 2019).
Je nachdem, ob Kommentare möglich sind und wie umfangreich diese ausfallen, können die Kommentare, mit Antworten auf Kommentare sowie Antworten auf diese Antworten, ähnlich wie Internetforen auch als Threads strukturiert sein. Durch die Kombination aufeinander folgender Blogbeiträge mit Kommentaren ergibt sich die für Blogs
spezifische Datenstruktur. Die Fallauswahl ist bei diesen beiden Formen von Born Digital Data in zwei Schritten vorzunehmen; Schünzel und Traue (2019) sprechen in diesem Zusammenhang auch vom externen und internen Sampling.


Die wichtigsten Formen von Born Digital Data sind Webseiten und Blogs. Die Fallauswahl beinhaltet zwei Schritte: das externe und das interne Sampling.


Der Schritt des _externen Sampling_ bezieht sich darauf, unter den in Frage kommenden
digitalen Dokumenten diejenigen auszuwählen, die in die Untersuchung einbezogen
werden sollen. Dies erfolgt in der Regel durch die Eingabe einschlägiger Suchbegriffe
in eine Suchmaschine, wobei die Suchbegriffe inhaltliche Kriterien spezifizieren, die
die Dokumente erfüllen müssen. Anschließend werden die Suchergebnisse gesichtet und die Suchbegriffe ggf. angepasst, woran sich weitere Runden des Suchens und
Sichtens anschließen können. Auf der Grundlage der ersten Suchergebnisse kann das
kriterienorientierte Vorgehen außerdem mit einer Form des Schneeballverfahrens verbunden werden. Die angezeigten Webseiten beinhalten oft Verweise auf andere relevante Seiten, und manchmal lassen sich Zusammenstellungen thematisch einschlägiger Blogs finden, die ebenfalls gesichtet werden und wiederum Verweise auf weitere
Blogs enthalten können. Bei der Suche ist allerdings das Phänomen der technischen
Reaktanz zu berücksichtigen (Traue & Schünzel, 2019): Die Suchergebnisse sind von
der bisherigen eigenen Suchhistorie in der entsprechenden Suchmaschine beeinflusst.
Es ist daher sinnvoll, die Suche von einem privaten Tab ohne den Kontext der Suchhistorie aus zu starten.

Alternativ ist, gerade wenn große Datenmengen abgespeichert werden sollen, die
Nutzung von _Webcrawlern_ zu empfehlen. Dabei handelt es sich um Programme zur
automatisierten Suche nach Webseiten, die von einer ersten Ausgangs-Webseite aus
verlinkt sind. Wichtig für die Fallauswahl ist dabei zum einen, ob eher in die Tiefe oder
in die Breite gehend gesucht wird. Auch ist ein Abbruchkriterium festzulegen. An die
Identifikation relevanter Webseiten mittels Webcrawler schließt sich bei einem solchen
automatisierten Vorgehen die Nutzung eines Webscrapers an, d. h. eines Programms,
mit dem die Inhalte der Webseiten automatisch extrahiert und abgespeichert werden
(für eine genauere Beschreibung sowie eine Zusammenstellung gängiger Webcrawler
und Scraper s. Franken, 2022, S. 108–112). Nach der Extraktion und Speicherung ist


111


4 Fallauswahl im Kontext qualitativer Daten


meist eine Bereinigung der Inhalte und Aufbereitung für die weitere Analyse erforderlich. Auch für diesen Arbeitsschritt lassen sich teilweise Webscraper heranziehen.


Das externe Sampling dient dazu, eine Grundgesamtheit relevanter Webseiten oder Blogs zu generieren. Dies kann entweder manuell durch die Eingabe von Suchbegriffen in eine Suchmaschine
erfolgen. Alternativ ist auch eine automatisierte Suche mittels Webcrawler möglich.


Auf diese Weise wird im Rahmen des externen Sampling eine Art Grundgesamtheit
generiert. Daran schließt sich das _interne Sampling_ in zwei Schritten an. In einem ersten Schritt werden aus der Grundgesamtheit Webseiten oder Blogs für die weitere Analyse ausgewählt. Dabei können ganz unterschiedliche Strategien der Fallauswahl zur
Anwendung kommen. Die Auswahl bestimmter Arten von Fällen ist ebenso denkbar
wie beispielsweise ein Maximum-Variation-Sampling oder ein iteratives Vorgehen, bei
dem der Prozess der Fallauswahl dann beendet wird, wenn eine Sättigung erreicht ist.
In der Praxis kommt das letztere Verfahren besonders häufig zur Anwendung: Es werden also so lange weitere Webseiten oder Blogs in die Stichprobe einbezogen, wie dort
neue Themenaspekte angesprochen werden.

In einem zweiten Schritt des internen Sampling ist anschließend festzulegen, welche Unterseiten bzw. Blogbeiträge genauer analysiert werden sollen. Bei der Auswahl
von Material auf Webseiten ist dabei meist die thematische Relevanz ausschlaggebend:
In Untersuchungen zu Blogs und Blogbeiträgen liegt dagegen oft eine so umfangreiche
Anzahl von Blogbeiträgen vor, dass thematische Relevanz als alleiniges Kriterium nicht
ausreichend ist. In solchen Fällen kommen zusätzliche Kriterien zum Tragen. So kann
etwa eine Zufallsauswahl aus dem Gesamt der Beiträge pro Seite sinnvoll sein oder
eine Auswahl je eines Blogbeitrags aus jedem Monat des letzten Jahres oder auch eine
Auswahl der fünf (oder zehn usw.) neuesten Beiträge. Oder es werden, bei Blogs mit
Kommentarfunktion, diejenigen Beiträge ausgewählt, zu denen die meisten Kommentare vorliegen. In Untersuchungen zu Blogs ist außerdem festzulegen, ob lediglich die
Blogbeiträge oder auch die Kommentare Gegenstand der Analyse sein sollen und ggf.
welche (zur Einbeziehung von Kommentaren s. unten zu Daten aus sozialen Medien).


Das interne Sampling dient zur Auswahl des Materials aus der Grundgesamtheit, das konkret analysiert werden soll. Es umfasst zwei Schritte:


(1) Auswahl von ganzen Webseiten oder Blogs mittels beliebiger absichtsvoller Strategien
(2) Auswahl von Unterseiten oder Blogbeiträgen, meist nach dem Kriterium der thematischen

Relevanz.


112


4.5 Auswahl aus digitalen Daten


**Untersuchungsbeispiel: Manisch-depressive Störungen – Selbstbeschreibung in Blogs**


In der Studie von Anika Mandla, Jo Billings und Joanna Moncrieff (2017) ging es um die Frage, wie
Menschen, bei denen eine manisch-depressive Störung diagnostiziert wurde, diese erleben und
beschreiben und wie sie sich selbst wahrnehmen. Als Untersuchungsmaterial zogen die Forscherinnen öffentlich zugängliche Blogs im Internet heran. Im ersten Schritt des externen Sampling
suchten die Autorinnen zunächst auf Google nach „bipolar disorder blogs“; diese Suche erbrachte
5.670000 Fundstellen. Davon fokussierten die Autorinnen die ersten drei: Eine der gefundenen
Seiten umfasste eine Liste von etwa 100 Blogs zu dem Thema; eine zweite Seite beinhaltete
Links zu 13 Blogs, und nur eines der Suchergebnisse führte direkt zum Blog einer Einzelperson. Diese Blogs sahen die Forscherinnen sich genauer im Hinblick auf thematische Relevanz
an. Dabei kamen detailliertere Kriterien zur Anwendung: So wurden nur solche Blogs einbezogen, die von Personen mit einer Diagnose einer manisch-depressiven Störung verfasst waren;
Blogs von engen Bezugspersonen wurden dagegen nicht berücksichtigt. Es wurden außerdem nur
solche Blogs einbezogen, in denen primär eigene Erfahrungen thematisiert wurden. Wenn eine
Person mehrere Blogs verfasst hatte, wurden sämtliche Blogs und Beiträge dieser Person einbezogen; Untersuchungseinheiten waren somit letztlich nicht Blogs, sondern Blogger. Der Prozess
der Sichtung wurde so lange fortgeführt, bis eine thematische Sättigung erreicht war. Auf diese
Weise resultierte eine Stichprobe von 45 Blogs, verfasst von 22 Bloggern, verteilt auf zwölf Blogging-Webseiten. Innerhalb der Blogs wurde keine weitere Auswahl vorgenommen; es fand also
kein internes Sampling statt. Über die Rolle der Kommentarfunktion machen die Autorinnen keine
Aussagen; aus dem Artikel geht jedoch hervor, dass nur die Blogbeiträge einbezogen wurden.


Diese Untersuchung verdeutlicht, wie bei der Auswahl von Born Digital Data unterschiedliche Strategien der Fallauswahl ineinandergreifen. Die Studie veranschaulicht
allerdings auch ein ethisches Problem, das sich bei der Auswahl digitaler Daten stellt,
die einzelnen Personen zugeschrieben werden können – hier den Bloggern. Erstens
hat sich in der Forschung mit solchen Daten die ethische Position etabliert, dass nicht
alles, was öffentlich verfügbar ist, deswegen auch schon für sozialwissenschaftliche
Forschung zur Verfügung steht (Markham & Buchanan, 2015). Dies ignorieren die
Autorinnen jedoch, wenn sie schreiben „Ethical approval was considered to be unnecessary given the blogs are publicly available“ (Mandla et al., 2017, S. 5). Zweitens
belegen Mandla et al. (2017) ihre Analyse und Schlussfolgerungen durch Zitate aus
den Blogs. Zwar schreiben sie, dass die Zitate anonymisiert wurden. Die Anonymisierung von Handles und Nicknames ist allerdings wenig weiterführend, wenn die Quelle
eines Zitats durch einfache Eingabe des Textes in eine Suchmaschine auffindbar ist.
Auch für die Verwendung von wörtlichen Zitaten wäre daher die Zustimmung der
Blogger:innen erforderlich gewesen oder zumindest die Verwendung von Paraphrasen
statt wörtlicher Zitate (Swartz, 2019).


113


4 Fallauswahl im Kontext qualitativer Daten


4.5.2 Auswahl von Daten aus sozialen Medien


Daten aus sozialen Medien sind gegenüber allgemeinen digitalen Daten diversen
Ursprungs dadurch gekennzeichnet, dass hier die Zusammenarbeit zwischen den Nutzer:innen, das Teilen von (selbst generierten) Inhalten und die Kommunikation darüber im Mittelpunkt stehen (McKay Peet & Quan Haase, 2017, S. 17). Dabei hängen die
Arten der möglichen Inhalte (textbasiert, visuell, Umfang usw.) sowie die möglichen
Kommunikationsformen (Kommentare, Emojis usw.) von der jeweiligen Plattform ab.

Bei der Nutzung von Daten aus den sozialen Medien sind einige Besonderheiten
und teils auch Beschränkungen zu berücksichtigen. Zunächst kann der schiere Umfang
an Daten aus sozialen Medien zu dem Schluss verleiten, dass diese Daten auch für die
jeweilige Bevölkerung repräsentativ und dass – bei einer hinreichend großen Stichprobe – entsprechende Verallgemeinerungen möglich sind. Das ist jedoch nicht der
Fall. Nur ein Teil der Bevölkerung nutzt soziale Medien. Weiterhin stellt sich das Problem der _Zuschreibbarkeit_ (Schrape & Siri, 2019). Eine erhebliche Anzahl von Accounts
in den sozialen Medien wurde nicht von einem Menschen erstellt, sondern repräsentiert einen Bot; die Beiträge und Kommentare werden also von einem Computerprogramm erzeugt. Aber auch da, wo man berechtigt davon ausgehen kann, dass das
Konto in der Tat von einem Menschen geführt wird, liegen keine gesicherten Informationen über dessen Identität vor. Insbesondere die soziodemografischen Merkmale der
Person (Geschlecht, Alter usw.) können – je nach Plattform – auch fiktiv sein.

Für die Fallauswahl weitaus am wichtigsten ist jedoch ein weiterer Punkt: Die Plattformen sind in der Hand von Privatfirmen, und nur diese haben Zugang zu den Rohdaten, den sie meist nicht öffentlich machen; Forschende haben dagegen in der Regel keinen direkten Zugriff. Sie haben letztlich nur zwei Möglichkeiten, Zugang zu Daten aus
den sozialen Medien zu erhalten. Der erste Weg besteht darin, gezielt Personen für die
Teilnahme an einer Untersuchung zu gewinnen, die sich bereit erklären, den Forschenden Zugang zu ihren Daten in den sozialen Medien zu gewähren, beispielsweise Mitglieder aus bestimmten Online-Foren oder Gemeinschaften (z. B. Umels Untersuchung
von Posts philippinischer Migrant:innen in einer Facebook-Gruppe: Umel, 2024). Bei
dieser Form der Datengewinnung ist jedoch meist eine manuelle Form der Datensicherung erforderlich, die sehr aufwändig ist.

Der zweite Weg beinhaltet den Zugriff über eine API, eine _Application Programming_
_Interface_ (Franken, 2022, S. 112–117). APIs sind Schnittstellen, mit denen ein maschineller Austausch von Daten möglich ist. Soweit eine Plattform den Zugriff auf Daten
erlaubt, lassen sich die Daten am einfachsten über eine solche API herunterladen. In
der Vergangenheit war Twitter die einzige Plattform, die einen Teil der Daten auf diese
Weise zur Verfügung gestellt hat – jedoch nur einen sehr kleinen Teil; und ein kostenfreier Zugang schloss nur Daten ein, die nicht älter als eine Woche waren. Ältere
Daten konnten gekauft werden – allerdings beinhaltete dies Gebühren, die Forschende
in der Regel nicht aufbringen können. Soweit uns zum jetzigen Zeitpunkt bekannt


114


4.5 Auswahl aus digitalen Daten


ist, bietet auch X eine Option für einen begrenzten kostenfreien Zugang; es ist sogar
möglich, sich mit einem speziellen Forschungsaccount zu registrieren. Aber auch hier
machen die öffentlichen Daten nur einen Bruchteil der Gesamtmenge aus, und es ist
nicht bekannt, nach welchem Algorithmus diese Daten ausgewählt werden. Ein öffentlicher Zugang ist auch zu Subbereichen des Forums Reddit möglich. Andere Plattformen wie Instagram, TikTok oder Facebook stellen dagegen keine Daten zur Verfügung.
Hier bleibt nur der Rückgriff entweder auf öffentlich gestellte Daten (etwa öffentliche
Facebook-Profile), unter Berücksichtigung ethischer Gesichtspunkte, oder Daten, die
von Einzelpersonen oder Gruppen für die Forschenden frei gegeben werden. Zusammengefasst lässt sich sagen, dass eine große Menge an Daten aus den sozialen Medien
existiert, dass diese aber für Forschende nur sehr eingeschränkt zur Verfügung stehen
und, soweit sie zur Verfügung stehen, trotz ihres großen Umfangs nicht als repräsentativ gelten können und hinsichtlich ihrer Zuschreibbarkeit zu überprüfen sind.


In den sozialen Medien existiert eine große Menge an Daten, zu der Forschende jedoch nur
beschränkt Zugang haben. Soweit sie verfügbar sind, können sie nicht als repräsentativ gelten und
sind hinsichtlich ihrer Zuschreibbarkeit zu überprüfen.


Wenn Forschende Zugang zu Daten aus den sozialen Medien erhalten haben, erfolgt
die Auswahl, wie beim externen Sampling von Daten aus dem Internet, über Suchbegriffe. Dabei können auch Hashtags zur Anwendung kommen. Dabei ist allerdings zu
beachten, dass nicht alle Nutzer:innen Hashtags verwenden und dass nicht alle notwendig dieselben Hashtags nutzen. Bei der thematisch orientierten Auswahl von Beiträgen in den sozialen Medien anhand von Suchbegriffen empfiehlt sich daher ein _ite-_
_ratives Vorgehen_ : Das bedeutet, mehrere Suchdurchgänge mit teils unterschiedlichen
Suchbegriffen vorzunehmen und die Ergebnisse immer wieder auf ihre inhaltliche Passung hin zu prüfen, bis eine optimale Kombination von Suchbegriffen gefunden ist.


Bei der Auswahl thematisch einschlägiger Beiträge in den sozialen Medien mittels Suchbegriffen
ist ein iteratives Vorgehen optimal. Das bedeutet, dass mehrere Suchdurchgänge vorgenommen
und die Suchbegriffe immer weiter optimiert werden.


115


4 Fallauswahl im Kontext qualitativer Daten


Weiterführende Literatur


Franken, Lina (2022). _Digitale Methoden für qualitative Forschung._ Waxmann.
Hennink, Monique, & Kaiser, Bonnie N. (2022). Sample sizes for saturation in qualita
tive research: A systematic review of empirical tests. _Social Science & Medicine_, _292_,
[114523. https://doi.org/10.1016/j.socscimed.2021.114523](https://doi.org/10.1016/j.socscimed.2021.114523)
Morgan, David L. (1998). _The focus group guidebook._ Sage.
Rapley, Tim, & Rees, Gethin (2018). Collecting documents as data. In Uwe Flick

(Hrsg.), _The Sage handbook of qualitative data collection_ (S. 392–411). Sage.
Saunders, Benjamin et al. (2018). Saturation in qualitative research: Exploring its con
ceptualization and operationalization. _Quality & Quantity: International Journal of_
_Methodology_, _52_ (4), 1893–1907.
Wästerförs, David (2018). Observations. In Uwe Flick (Hrsg.), _The Sage handbook of_

_qualitative data collection_ (S. 314–326). Sage.


116


#### **5 Verallgemeinerung**

Wie die Fallauswahl wurde auch die Verallgemeinerung in der qualitativen Forschung
lange Zeit vernachlässigt. Historisch betrachtet lassen sich dafür zwei Ursachen ausmachen (Maxwell, 2022): Das ist einmal die implizite Gleichsetzung von Verallgemeinerung mit dem Konzept der Verallgemeinerung, wie es in der quantitativen Forschung
vorherrschend ist und damit einhergehend die Abgrenzung von diesem Begriff. Zweitens fällt qualitativ Forschenden beim Begriff der Verallgemeinerung allzu oft der viel
zitierte Satz von Yvonne Lincoln und Egon Guba ein: „The only generalization is: there
is no generalization“ (2009): Die einzig zulässige Verallgemeinerung lautet: Es gibt
keine Verallgemeinerung.

Paradoxerweise lassen qualitativ Forschende, wenn sie sich auf dieses Zitat berufen,
jedoch oft den Kontext außer Acht. Dies ist paradox, weil qualitative Forschung sich ja
gerade durch ihre Kontextsensitivität und -spezifität auszeichnet und von der quantitativen Forschung abhebt. Und es ist umso mehr paradox, als Lincoln und Guba – trotz
ihrer plakativen Formulierung – keineswegs die Möglichkeit von Verallgemeinerung
in der qualitativen Forschung generell ausschließen. Vielmehr wenden sie sich eben
gegen die Variante von Verallgemeinerung, die in der quantitativen Forschung dominiert, und stellen dieser ein alternatives Konzept gegenüber: das der Übertragbarkeit.

Losgelöst von der quantitativen Forschungstradition bezieht sich Verallgemeinerung
zunächst einmal nur auf die Frage: Was sagen die Ergebnisse meiner Forschung aus?
Sind sie einfach nur, aus sich heraus und für sich genommen, interessant? Oder gibt es
irgendetwas, was ich aus diesen Ergebnissen lernen kann, was über die untersuchten
Personen, Settings oder Zeitpunkte hinausweist und zumindest vorläufige Gültigkeit
besitzt? In den allermeisten Fällen führen wir unsere Forschung nicht einfach nur um
ihrer selbst willen durch, und wir suchen in der Forschung anderer nach Informationen,
die auch in anderen Kontexten anwendbar sind. Und das heißt: In den meisten Fällen
streben wir mit qualitativer Forschung eine Form von Verallgemeinerung an.


Auch qualitativ Forschende möchten aus ihren Ergebnissen meistens Schlussfolgerungen ableiten, die über die untersuchten Fälle hinaus Gültigkeit haben.


Im Folgenden gehen wir zunächst auf den Begriff der Verallgemeinerung in der quantitativen Forschung ein und erläutern, weshalb dieser in der qualitativen Forschung
meist nicht angemessen ist. Anschließend stellen wir drei (Alternativ-)Konzepte von
Verallgemeinerung in der qualitativen Forschung dar: Formen der empirischen Ver

117


5 Verallgemeinerung


allgemeinerung, das Konzept der Übertragbarkeit sowie die analytische Verallgemeinerung. Dabei wird auch deutlich, wie eng die Fallauswahl und die Möglichkeiten der
Verallgemeinerung zusammenhängen. Abschließend thematisieren wir eine Besonderheit der qualitativen Forschung, nämlich die Unterscheidung zwischen externer
und interner Verallgemeinerung, und weshalb auch die interne Verallgemeinerung in
der qualitativen Forschung von Bedeutung ist.


5.1 Hintergrund: Verallgemeinerung in der quantitativen Forschung


In der quantitativen Forschung spielt die Verallgemeinerung in erster Linie im Sinne
eines Schlusses von einer Stichprobe auf die Grundgesamtheit eine Rolle. Dabei wird
die Stichprobe so ausgewählt, dass sie im Hinblick auf relevante Dimensionen für die
Grundgesamtheit _repräsentativ_ ist. Die Stichprobe stellt also idealerweise eine Art
Miniaturbild der Grundgesamtheit dar. Und insofern die Stichprobe die Grundgesamtheit angemessen abbildet, lässt sich auch von der Grundgesamtheit auf die Stichprobe
schließen. Wenn beispielsweise in einer repräsentativen Stichprobe der Wahlberechtigten in Deutschland 35 Prozent Partei X wählen, dann lässt sich daraus schließen,
dass auch in der Bevölkerung insgesamt etwa 35 Prozent der Wahlberechtigten auf
dem Wahlzettel ihre Stimme der Partei X geben. Diese Form der Verallgemeinerung
wird in der Literatur auch als _empirische Verallgemeinerung_ bezeichnet.


Ziel der quantitativen Forschung ist häufig der Schluss von einer Stichprobe auf die Grundgesamtheit.


Der springende Punkt beim Schluss von der Stichprobe auf die Grundgesamtheit liegt
in der Formulierung „insofern die Stichprobe die Grundgesamtheit angemessen abbildet“, also in relevanten Dimensionen für die Grundgesamtheit repräsentativ ist. In
Bezug auf das Wahlverhalten weiß man beispielsweise, dass das Geschlecht, die soziale Schicht, das Bildungsniveau, die Religionszugehörigkeit, das Alter und der Wohnort eine Rolle spielen.

In der quantitativen Forschung wird das Problem der Repräsentativität durch zwei
Hilfsmittel gelöst: die Ziehung einer _Zufallsstichprobe_ und die Nutzung probabilistischer Verfahren. Eine echte Zufallsauswahl ist darüber definiert, dass jedes Mitglied
der Grundgesamtheit dieselbe Chance hat, in die Stichprobe aufgenommen zu werden
(s. o. 1.2). Wenn sowohl die Grundgesamtheit als auch die Stichprobe groß genug sind,
dann lässt sich von Merkmalen und ihrer Verteilung in der Stichprobe auf diese Merkmale und deren Verteilung in der Grundgesamtheit schließen.

Ein solcher Schluss ist allerdings nicht absolut möglich: Die Stichprobe ist kein
eins-zu-eins Abbild der Grundgesamtheit, sondern kann sich ihr immer nur annähern.


118


5.1 Hintergrund: Verallgemeinerung in der quantitativen Forschung


An dieser Stelle kommt das zweite Hilfsmittel ins Spiel: der _probabilistische Schluss_ .
Mittels inferenzstatistischer Verfahren lässt sich zunächst ein Kennwert in der Stichprobe bestimmen, der dem Wert in der Grundgesamtheit, dem Populationsparameter, möglichst nahe kommt – also beispielsweise der Prozentsatz der Bevölkerung, der
in der nächsten Bundestagswahl für Partei X stimmt. Weiterhin lässt sich ein Bereich
bestimmen, innerhalb dessen der echte Wert in der Bevölkerung mit einer bestimmten Wahrscheinlichkeit liegt, etwa mit einer Wahrscheinlichkeit von 95 Prozent (was
dem konventionellen Signifikanzniveau entspricht). Dieser Bereich wird auch Konfidenzintervall genannt. Dieses Konfidenzintervall hängt mit der Stichprobengröße
zusammen: Je größer die Stichprobe, desto exakter die Schätzung. Wegen der zentralen Rolle der Inferenzstatistik bei dieser Form der Verallgemeinerung ist in der quantitativen Literatur meist nicht einfach von empirischer Verallgemeinerung die Rede,
sondern von _statistischer Verallgemeinerung_ .

Allerdings ist die Repräsentativität der Zufallsstichprobe für die Grundgesamtheit
an eine ganze Reihe von _Voraussetzungen_ gebunden, unter anderem an den hinreichenden Umfang der Stichprobe und der Grundgesamtheit. Hinzu kommt, dass in der Praxis
nicht alle Personen, die per Zufallsstichprobe für eine Untersuchungsteilnahme ausgewählt werden, auch tatsächlich an der Studie teilnehmen. In der Literatur zu Stichprobenziehung und Verallgemeinerung wird jedoch häufig nicht klar zwischen der
Zufallsstichprobe und der Repräsentativität der Stichprobe für die Grundgesamtheit
unterschieden. In der Tat bezeichnet die Zufallsauswahl jedoch ein bestimmtes Verfahren der Gewinnung einer Stichprobe, während Repräsentativität sich auf die Zusammensetzung der Stichprobe bezieht. Das eine (Zufallsstichprobe) ist ein Verfahren, das
andere (Repräsentativität) ein Ergebnis (vgl., auch im Folgenden, Gobo, 2007).


Eine Zufallsstichprobe ist nicht notwendig repräsentativ. Ob das Verfahren der Zufallsauswahl zum
Ergebnis einer repräsentativen Stichprobe führt, ist von mehreren Voraussetzungen abhängig.


Durch die fehlende Unterscheidung wird erstens der Eindruck erweckt, dass eine
Zufallsstichprobe immer auch repräsentativ ist. Zweitens wird mit der Gleichsetzung
von Zufallsstichprobe und Repräsentativität nahegelegt, dass eine Zufallsauswahl
die einzige Möglichkeit darstellt, zum Ergebnis einer repräsentativen Stichprobe zu
gelangen, womit zugleich andere Verfahren der Stichprobengewinnung (s. o. Kap. 2)
als methodisch unzureichend kritisiert werden. Unserer Ansicht nach existieren aber
auch andere Möglichkeiten, zu einer repräsentativen Stichprobe zu gelangen, die
weder eine Zufallsauswahl noch einen probabilistischen Schluss beinhalten (s. u. 5.2).
Außerdem stellt die empirische oder die statistische Verallgemeinerung nicht die einzig mögliche Form der Verallgemeinerung dar, auf die eine empirische Untersuchung
ausgerichtet sein kann.


119


5 Verallgemeinerung


Die Zufallsauswahl ist nicht der einzige Weg, um von einer Stichprobe auf die Grundgesamtheit
zu schließen.


Der Vollständigkeit halber möchten wir erwähnen, dass es auch bei der Arbeit mit qualitativen Daten Situationen geben kann – insbesondere bei der Arbeit mit digitalen
Daten, die in großem Umfang vorliegen – in denen eine Zufallsauswahl durchaus möglich ist (z. B. Cavazos-Rehg et al., 2016, zur Inhaltsanalyse einer Zufallsstichprobe von
2.000 Tweets im Hinblick auf Anzeichen klinischer Symptome einer Depression). Eine
Zufallsauswahl kann auch eine geeignete Strategie darstellen, wenn beispielsweise zu
viele Daten erhoben wurden (das sogenannte Oversampling) und die erhobenen Daten
weitgehend äquivalent sind. Allerdings gewährleistet die Zufallsauswahl, wie wir oben
ausgeführt haben, nicht auch eine repräsentative Stichprobe. Dafür ist im konkreten
Fall zu prüfen, ob die jeweiligen Voraussetzungen erfüllt sind.


5.2 Die empirische Verallgemeinerung in der qualitativen Forschung


Zwar wird in der Literatur des Öfteren betont, dass das Ziel qualitativer Forschung
nicht darin besteht, von einer Stichprobe auf eine Grundgesamtheit zu verallgemeinern. Sicher ist eine solche empirische Verallgemeinerung nicht das alleinige Ziel qualitativer Forschung; hier spielen auch die anderen Formen der Verallgemeinerung eine
Rolle, auf die wir in den folgenden Abschnitten noch eingehen. Aber es gibt durchaus Untersuchungen, in denen eine empirische Verallgemeinerung zumindest implizit
angestrebt und oft auch vorgenommen wird – obwohl das manchmal gar nicht gerechtfertigt ist. Onwuegbuzie und Leech (2010) identifizierten sogar in etwa 30 Prozent
aller Studien aus der Zeitschrift _The Qualitative Report_ (vom Erscheinen bis zum Zeitpunkt ihrer Untersuchung) solche fehlerhaften Verallgemeinerungen. Hier ein neueres
Beispiel aus derselben Zeitschrift, in dem ebenfalls problematische Schlussfolgerungen gezogen werden.


**Untersuchungsbeispiel: Das Erleben junger Erwachsener im ersten Jahr der Covid-Pandemie**


Šnele et al. (2025) untersuchten, wie junge Erwachsene in Serbien das erste Jahr der Covid-Pandemie erlebten und wie sich dieses Erleben auf ihre psychische Gesundheit auswirkte. Die Datenerhebung erfolgte durch Antworten auf offene Fragen in einem Online-Fragebogen; die Antworten
wurden mittels reflexiver thematischer Analyse ausgewertet. Teilnehmer:innen waren Studierende
aus den Lehrveranstaltungen der Forschenden; von 90 Studierenden nahmen 51 (im Alter von 19


120


5.2 Die empirische Verallgemeinerung in der qualitativen Forschung


bis 28 Jahren) an der Studie teil. Die Studierenden berichteten u. a. von Stimmungsschwankungen, Einsamkeit und Depression; in Bezug auf Covid schrieben sie von Überlegungen dazu, wie
sie sich am besten vor einer Erkrankung schützen können. Bei anderen Studierenden waren auch
deutliche Zeichen von Resilienz und Ausrichtung auf eine bessere Zukunft sichtbar. Aus diesen
Befunden leiten die Autor:innen Empfehlungen für die Konzeptualisierung von Programmen für
junge Erwachsene in Krisensituationen ab. Sie weisen zwar darauf hin, dass es sich bei den Teilnehmenden um Studierende aus ihren eigenen Lehrveranstaltungen handelt und dass die Dynamik zwischen Lehrenden und Studierenden die Antworten beeinflusst haben kann; darüber hinausgehende Einschränkungen der Verallgemeinerbarkeit nehmen sie jedoch nicht vor. Es werden
hier also an Hand der Antworten von 51 serbischen Studierenden Aussagen über das Erleben junger Erwachsener im ersten Jahr der Covid-Pandemie getroffen.


Diese Studie ist ein Beispiel dafür, dass auch in der qualitativen Forschung durchaus
empirische Verallgemeinerungen von einer Stichprobe (hier 51 Studierende aus Serbien im Alter zwischen 18 und 28 Jahren aus Lehrveranstaltungen der Forscherinnen)
auf eine Grundgesamtheit (hier: junge Erwachsene) von Interesse sein kann – wobei
die Voraussetzungen für eine solche Verallgemeinerung in der obigen Studie jedoch
nicht gegeben sind. Es gibt aber durchaus Formen der empirischen Verallgemeinerung, die unter bestimmten Voraussetzungen auch in der qualitativen Sozialforschung
zulässig sind. Im Folgenden beschreiben wir drei solche Formen der empirischen Verallgemeinerung: Verallgemeinerungen auf der Grundlage einer typischen Stichprobe;
Verallgemeinerungen auf Existenzsätze; und Moderatum-Verallgemeinerungen.


5.2.1 Verallgemeinerung auf der Grundlage einer typischen Stichprobe


Wie wir in Abschnitt 5.1 erläutert haben, sind die Repräsentativität der Stichprobe und
die Auswahl einer Zufallsstichprobe nicht gleichzusetzen. Vielmehr stellt die Zufallsauswahl _eine_ Möglichkeit dar, zu einer repräsentativen Stichprobe zu gelangen – eine
Möglichkeit, die in der qualitativen Forschung in der Regel nicht gegeben ist. Eine
andere Möglichkeit besteht darin, mit _typischen Fällen_ zu arbeiten.

Auf die Rolle der Typizität bei der Stichprobenziehung sind wir bereits im Zusammenhang mit der Auswahl von typischen Fällen eingegangen (s. o. 2.4): In dem Maß,
in dem man davon ausgehen kann, dass die Stichprobe für die Grundgesamtheit in
relevanten Aspekten als typisch gelten kann, ist die Stichprobe auch für die Grundgesamtheit repräsentativ; und dann ist auch eine Verallgemeinerung von der Stichprobe
auf die Grundgesamtheit möglich.


121


5 Verallgemeinerung


Typische Fälle können als repräsentativ für die Grundgesamtheit gelten. Man kann daher von den
Eigenschaften typischer Fälle auf die Eigenschaften der Grundgesamtheit schließen.


Allerdings ist die Typizität einer Stichprobe immer vor dem Hintergrund der _Variabi-_
_lität im Gegenstandsbereich_ zu sehen. Wenn die Variabilität in der Grundgesamtheit
niedrig ist, wenn die Grundgesamtheit also homogen ist, dann ist es auch leicht, einen
Fall auszuwählen, der für diese Grundgesamtheit typisch ist. Giampietro Gobo (2007)
führt hier als Beispiel die Bissprobe an, die wir durchführen, um festzustellen, ob die
Nudeln im Kochtopf gar sind. Die Grundgesamtheit der Nudeln ist in jeder Hinsicht
homogen, und so reicht es auch, eine Nudel herauszufischen und zu probieren, um zu
entscheiden, ob alle Nudeln im Topf gar sind oder nicht. Wenn man sich dagegen beispielsweise für das Erleben von Meditation interessiert, dann lassen sich mindestens
sieben verschiedene Arten von Meditation identifizieren, die möglicherweise auch
unterschiedlich erlebt werden (Matko & Sedlmeier, 2019), ganz abgesehen von möglichen anderen Faktoren wie etwa der Länge der eigenen Meditationspraxis, die ebenfalls mit dem Erleben in Zusammenhang stehen können. Hier ist die Grundgesamtheit
also heterogen, die Variabilität ist hoch. Dieser Vielfalt würde man nicht gerecht, wenn
man das Erleben von Meditation nur an einer dieser sieben Formen von Meditation
untersuchen würde. Eine typische Meditation existiert nicht.

Im Zusammenhang mit dem Beispiel von Gobo stellt sich die Frage, ob wir es in den
Sozialwissenschaften jemals mit solchen vergleichsweise homogenen Grundgesamtheiten zu tun haben, in denen eigentlich jeder Fall einen typischen Fall darstellt. In
der Tat gibt es Gegenstandsbereiche, in denen man von einer solchen Homogenität
ausgehen kann – und zwar immer dann, wenn es um die Untersuchung universeller
Strukturen und Prozesse geht. Dazu zählen beispielsweise konversationsanalytische
Untersuchungen der Organisation von Gesprächsabläufen, wie etwa die Schlussfolgerungen von Schegloff und Sacks zu den Möglichkeiten, die Sprecher:innen zur Verfügung stehen, um ein Gespräch zu beenden (1973). Zwar haben Schegloff und Sacks
in ihren Studien teilweise Hunderte von Äußerungen in die Analyse einbezogen, was
aber angesichts der Grundgesamtheit einer unendlichen Anzahl von Äußerungen
immer noch eine recht kleine Stichprobe darstellt. Auch waren diese Äußerungen in
keiner Weise gezielt ausgewählt. Denn wenn man davon ausgeht, dass die Organisation von Gesprächen nach bestimmten (impliziten) Regeln verläuft, dann manifestieren sich diese Regeln auch in sämtlichen Äußerungen eines kompetenten Sprechers.
Jede Äußerung stellt somit auch ein typisches Beispiel dar. Andere Gegenstandsbereiche, in denen von einer homogenen Grundgesamtheit ausgegangen wurde, finden sich
etwa in der Allgemeinen Psychologie und auch der Entwicklungspsychologie. Jean Piaget erarbeitete sein Stufenmodell der kognitiven Entwicklung beispielsweise an Hand
der Beobachtungen seiner eigenen Kinder (Piaget, 2016). Dahinter steht die Annahme,


122


5.2 Die empirische Verallgemeinerung in der qualitativen Forschung


dass universelle kognitive Entwicklungsprozesse sich in jedem Kind gleichermaßen
manifestieren und sich folglich auch in den Beobachtungen beliebiger Kinder identifizieren lassen. Ob die Annahme einer homogenen Grundgesamtheit in der Tat gerechtfertigt ist, ist allerdings sorgfältig zu prüfen. So wurde beispielsweise gegen Piaget kritisch angemerkt, dass seine Annahme einer universellen Entwicklungsabfolge in erster
Linie für westliche Kulturen gültig ist.


In einer homogenen Grundgesamtheit ist jeder Fall auch ein typischer Fall. In den Sozialwissenschaften sind homogene Grundgesamtheiten zwar selten. Es gibt sie aber durchaus, wenn es um
die Untersuchung universeller Strukturen und Prozesse geht.


Insgesamt dürften homogene Grundgesamtheiten in der qualitativen Sozialforschung
eher die Ausnahme sein. Aber auch bei weniger homogenen Grundgesamtheiten gibt
es die Möglichkeit, von der Stichprobe auf die Grundgesamtheit zu verallgemeinern,
wenn man gezielt einen typischen Fall auswählt, oder besser noch mehrere typische
Fälle (s. o. 2.4). Als Beispiel hatten wir die Untersuchung von Lynd und Lynd (1929)
zum Leben in einer amerikanischen Kleinstadt zu Beginn der Industrialisierung angeführt. Ob und inwieweit ein Fall als typisch gelten kann, setzt allerdings voraus, dass
man über Informationen zu relevanten Merkmalen in der Grundgesamtheit und die
Verteilung dieser Merkmale verfügt. Entsprechend haben Lynd und Lynd die Gemeinde
Middletown, in der sie ihre Untersuchung durchgeführt haben, auf der Grundlage von
Vorwissen über Merkmale wie Einwohnerzahl, Lage, kulturelles Leben usw. ausgewählt: Sie haben ermittelt, welche Ausprägungen dieser Merkmale im Amerika der
1920er Jahre als typisch gelten können und eine Gemeinde gewählt, die auf all diesen
Merkmalsdimensionen im typischen Bereich lag.

Je höher die Variabilität im Gegenstandsbereich, desto schwieriger wird es allerdings, Aussagen darüber zu treffen, was genau als typisch gelten kann. Statt des einen
typischen Falls finden sich dann eher verschiedene Konstellationen von Merkmalen
und Merkmalsausprägungen, die sich ggf. zu _Typen_ zusammenfassen lassen. Auch hier
braucht es allerdings wieder Vorwissen darüber, welche Typen es in dem interessierenden Gegenstandsbereich gibt. Sofern man über das entsprechende Wissen verfügt,
lässt sich jeder Typus wiederum als eigene homogene Grundgesamtheit betrachten,
aus der man jeweils einen typischen Fall auswählen kann. In ihrer Untersuchung von
Bürgerwehren im Zusammenhang mit dem Sicherheitsempfinden in der Gesellschaft
identifizierte Nina Bust-Bartels (2021) beispielsweise in einem ersten Schritt auf theoretischer Grundlage drei Typen von Bürgerwehren: institutionalisierte, aktivistische
und autonome. Für jeden der drei Typen wählte sie je eine Bürgerwehr für ihre ethnografische Untersuchung aus.


123


5 Verallgemeinerung


Bei heterogenen Grundgesamtheiten gibt es manchmal die Möglichkeit, die unterschiedlichen
Ausprägungen des interessierenden Phänomens zu Typen zusammenzufassen, die in sich homogen sind. Wenn man über entsprechendes Vorwissen verfügt, kann man dann pro Typus einen
oder mehrere Fälle auswählen, die als typisch gelten können.


Bei vielen Fragestellungen und in vielen Gegenstandsbereichen ist die Variabilität jedoch
so hoch oder verfügt man nicht über hinreichendes Vorwissen, um eine Vorstrukturierung in Typen vornehmen zu können. In solchen Situationen sind eine Auswahl typischer Fälle und eine entsprechende empirische Verallgemeinerung nicht möglich.


5.2.2 Verallgemeinerung auf Existenzsätze


In Studien mit einer heterogenen Grundgesamtheit eignen sich bei der Fallauswahl
besonders solche Strategien, die auf eine heterogene Zusammensetzung der Stichprobe ausgelegt sind, wie etwa der qualitative Stichprobenplan oder das MaximumVariation-Sampling (s. o. 2.2). Während die Auswahl typischer Fälle darauf abzielt,
das zu identifizieren, was die Fälle in einem Gegenstandsbereich gemeinsam haben,
geht es bei diesen Strategien darum, _Unterschiedlichkeit_ einzubeziehen und abzubilden. Eine ähnliche Forschungslogik findet sich auch in der quantitativen Survey-Forschung. Dort besteht das Ziel meist darin, etwas über die Verteilung eines Merkmals
in der Grundgesamtheit auszusagen – bei der Wahlforschung also etwa Aussagen darüber zu machen, welcher Prozentsatz der Bevölkerung bei der nächsten Bundestagswahl für welche Partei stimmen würde. Eine solche empirische Verallgemeinerung
von der Stichprobe auf die Grundgesamtheit ist auf der Grundlage einer Stichprobe,
die mittels Maximum-Variation-Sampling gewonnen wurde, zwar nicht möglich.
Möglich sind aber Aussagen im Sinne von Existenzsätzen, sognannte Es-gibt-Sätze.
Angewandt auf das Beispiel der Wahlforschung könnte man also auf der Grundlage
einer Maximum-Variation-Stichprobe schließen: Es gibt in der Bevölkerung Personen,
die für die Parteien X, Y und Z stimmen – ohne allerdings Aussagen darüber machen
zu können, für welchen Prozentsatz in der Grundgesamtheit dies jeweils der Fall ist.


Bei Stichprobenverfahren, die auf die Abbildung von Unterschiedlichkeit ausgerichtet sind, sind
Verallgemeinerungen auf Existenzsätze möglich. Man kann also auf der Grundlage der Daten die
Aussage treffen, dass ein bestimmtes Phänomen in der Grundgesamtheit existiert.


124


5.2 Die empirische Verallgemeinerung in der qualitativen Forschung


Die oben beschriebene und hinsichtlich der Verallgemeinerungen kritisierte Studie
von Šnele et al. (2025) lässt sich für eine Verallgemeinerung auf Existenzaussagen heranziehen. Die Autorinnen weisen bei der Diskussion ihrer Ergebnisse darauf hin, dass
in den Antworten der Studierenden zum Erleben der Covid-Pandemie nicht nur negative Erfahrungen wie Ängste und Einsamkeit sichtbar werden, sondern auch positive
Gedanken, die sich als Hinweis darauf interpretieren lassen, dass manche der Studierenden an der Krise wachsen und sich persönlich weiter entwickeln. Die Aussage, dass
es unter den Studierenden auch solche gibt, die von positiven Gedanken und Erfahrungen berichten, ist durchaus zulässig, selbst auf der Basis der hier zugrunde gelegten
anfallenden Stichprobe. Die Aussage kann ihrerseits den Ausgangspunkt für weitere
Untersuchungen zu der Frage darstellen, bei welchen Studierenden das insbesondere
der Fall ist und wie sich solche positiven Verarbeitungsformen fördern lassen. Dieses
Beispiel zeigt, dass Verallgemeinerungen auf Existenzaussagen selbst auf der Grundlage von anfallenden Stichproben möglich sind.


5.2.3 Moderatum-Verallgemeinerung


Eine weitere Form der empirischen Verallgemeinerung in der qualitativen Forschung
ist die Moderatum-Verallgemeinerung (Williams, 2000). Darunter versteht man Formen der Verallgemeinerung, die – wie der Name schon sagt – moderater bzw. _einge-_
_schränkter_ sind als die statistische Variante in der quantitativen Forschung. Erstens
erheben Forschende mit Moderatum-Verallgemeinerungen keinen absoluten, sondern lediglich einen vorläufigen Geltungsanspruch; Moderatum-Verallgemeinerungen haben _hypothetischen Charakter_ . Zweitens sind sie in Bezug auf ihren Geltungsbereich beschränkt (Payne & Williams, 2005): Die Ergebnisse einer qualitativen Studie
mit Moderatum-Verallgemeinerung lassen sich möglicherweise nur auf bestimmte
Settings oder Zeiträume übertragen. Auch sind die Ergebnisse möglicherweise im
Hinblick auf ihre Genauigkeit eingeschränkt: Sie gelten vielleicht auch in anderen
Settings, aber nicht in genau derselben Form. Denkbar ist auch, dass eine qualitative
Studie Hinweise auf einen Prozess ergibt, der in einem anderen Kontext zwar auch
wirksam wird, im Rahmen der jeweiligen Kontextfaktoren jedoch zu unterschiedlichen Ergebnissen führt.


Moderatum-Verallgemeinerungen sind empirische Verallgemeinerungen, mit denen keine absolute
Gültigkeit erhoben wird. Die angenommene Gültigkeit ist vorläufig und hinsichtlich Eigenschaften
der Stichprobe eingeschränkt.


125


5 Verallgemeinerung


Letztlich läuft der Gedanke der Moderatum-Verallgemeinerung darauf hinaus, dass
empirische Verallgemeinerungen auch in der qualitativen Forschung möglich sind.
Dabei sollten Forschende aber immer auch den Untersuchungskontext, die untersuchte Personengruppe, den Zeitpunkt und die Art der Fallauswahl im Blick behalten und mit Schlussfolgerungen vorsichtig sein, die über diesen Kontext hinausgehen.
Insofern trägt das Konzept der Moderatum-Verallgemeinerung auch der eigentlichen
Stärke der qualitativen Forschung Rechnung, nämlich ihrer Kontextspezifik.


**Untersuchungsbeispiel: Gefängniskulturen**


Ein Beispiel dafür, wie ein Prozess in unterschiedlichen Kontexten auf unterschiedliche Weise wirksam werden kann, aber von seiner Grundstruktur her dennoch übertragbar ist, findet sich in einer
Abfolge zweier ethnografischer Studien zur Kultur in Gefängnissen.
Die erste Studie wurde von Sykes (1958; zit. n. Becker, 2009) durchgeführt. Hier zeigte sich, dass
die Insassen in einem Gefängnis für Männer eine Art Regierung etabliert hatten, die im Gefängnis quasi für Recht und Ordnung sorgte und einen Schwarzmarkt für Zigaretten, Kleidung und
auch sexuelle Begegnungen organisierte. Die Autoren interpretierten ihre Ergebnisse dahingehend, dass die Männer im Gefängnis bemüht waren, das wiederherzustellen, was sie dort am
meisten vermissten: ein Gefühl von Autonomie. Die Regierung versetzte sie in die Lage, auf geregelte Weise Zugang zu Gütern zu erhalten, die ihnen im Gefängnis fehlten.
Ward und Kassebaum wollten diese Schlussfolgerung auf ein Gefängnis für Frauen übertragen
(1965; zit. n. Becker, 2009). Allerdings fanden sie dort keine der zuvor im Männergefängnis identifizierten Strukturen: Es gab keine Form der Regierung und auch keinen Schwarzmarkt. Stattdessen
hatten die Frauen familienähnliche Strukturen ausgebildet.
Becker interpretiert diese Ergebnisse so, dass im Frauengefängnis in der Tat ein vergleichbarer
Prozess wirksam wird wie im Männergefängnis, nur auf je kontextspezifische Weise. Frauen stand
in den 1950er und frühen 1960er Jahren in den USA nicht sonderlich viel Autonomie zu, so dass
sie, anders als die Männer, Autonomie auch nicht weiter vermissten. Wichtiger für die Frauen war
Schutz, sowohl außerhalb als auch innerhalb des Gefängnisses. Folglich schufen sie familienähnliche Strukturen, die ihnen genau diesen Schutz gewährten.


Die Abfolge dieser zwei Untersuchungen verdeutlicht, wie sich Befunde einer qualitativen Studie zwar nicht im Hinblick auf die Inhalte verallgemeinern lassen (also hier
im Hinblick auf die Schaffung regierungsähnlicher Strukturen), wohl aber im Hinblick
auf den Prozess (hier: im Gefängnis Reproduktion dessen, was am meisten vermisst
wird), und zwar in je kontextspezifischer Form. Der identifizierte Prozess lässt sich
somit von dem einen auf das andere Setting übertragen. Damit ist zugleich die Brücke
geschlagen zwischen der Moderatum-Verallgemeinerung als einer Form der Verallgemeinerung in qualitativen Studien hin zum Konzept der Übertragbarkeit.


126


5.3 Übertragbarkeit als Alternative zur empirischen Verallgemeinerung


5.3 Übertragbarkeit als Alternative zur empirischen Verallgemeinerung


Während die Moderatum-Verallgemeinerung als Form der empirischen Verallgemeinerung gedacht ist, haben Yvonne Lincoln und Egon Guba das Konzept der Übertragbarkeit von vornherein als Alternative zur (empirischen) Verallgemeinerung gedacht
(2009). Dabei gehen sie – ebenso wie Williams im Zusammenhang mit der Moderatum-Verallgemeinerung – davon aus, dass die Schlussfolgerungen aus einer qualitativen Studie erst einmal nur eine Hypothese darstellen und somit vorläufigen Charakter haben. Inwieweit eine solche Hypothese aus dem einen Kontext A (wie im obigen
Beispiel: von einem Männergefängnis) auf einen anderen Kontext B (im obigen Beispiel: auf ein Frauengefängnis) übertragbar ist, hängt nach ihrer Auffassung davon ab,
wie ähnlich oder verschieden die beiden Kontexte sind. Diesen Grad der Ähnlichkeit
bezeichnen sie auch als _Fittingness_, d. h. als Passung zwischen den beiden Kontexten
A und B: In dem Maß, in dem die beiden Kontexte einander ähnlich sind, ist die Hypothese aus Kontext A auch auf Kontext B übertragbar.


Die Übertragbarkeit der Ergebnisse einer Studie auf einen anderen Kontext hängt von der Ähnlichkeit der beiden Kontexte ab. Je größer die Ähnlichkeit, desto höher die Übertragbarkeit.


Um den Grad der Ähnlichkeit zu bestimmen und eine Entscheidung über die Übertragbarkeit einer Arbeitshypothese auf einen zweiten Kontext zu treffen, müssen sowohl die
Forschenden (aus Kontext A) als auch die Rezipient:innen der Studie (die eine Übertragbarkeit auf Kontext B anstreben) bestimmte Leistungen erbringen. Denn eine Entscheidung über die Übertragbarkeit setzt voraus, dass Informationen über beide Kontexte
vorliegen. Aber nur die Forschenden kennen den Kontext A, und nur die Rezipient:innen
kennen den Kontext B. Um überhaupt die Möglichkeit dafür zu schaffen, die Passung
zwischen verschiedenen Kontexten zu beurteilen, liegt es zunächst in der Verantwortung der Forschenden, den Kontext A detailliert zu beschreiben. Lincoln und Guba greifen hier auf das Konzept der _dichten Beschreibung_ im Sinne von Clifford Geertz zurück
(2003). Die Forschenden sollen den Kontext ihrer Studie also detailliert beschreiben,
und die Beschreibungen sollen interpretativ sein und Bedeutungen der Handelnden in
dem untersuchten Setting erschließen. Es geht bei der dichten Beschreibung also nicht
um eine Beschreibung von außen, sondern um Beschreibungen unter Berücksichtigung
der Intentionen und Sinnhorizonte der Handelnden. Dies versetzt die Rezipient:innen in
die Lage, auf der Grundlage ihrer Kenntnis von Kontext B eine Entscheidung darüber zu
treffen, inwieweit die hypothetischen Schlussfolgerungen aus Kontext A auf Kontext B
übertragbar sind. Eine solche dichte Beschreibung findet sich am ehesten in ethnografischen Studien, in Fallstudien und in Evaluationsstudien, so dass die Voraussetzungen für
eine Übertragbarkeit in diesen Studien auch am ehesten gegeben ist.


127


5 Verallgemeinerung


Während bei den verschiedenen Formen der empirischen Verallgemeinerung stets
die Forschenden darüber entscheiden, inwieweit ihre Schlussfolgerungen verallgemeinerbar und somit auf andere Personengruppen, Settings oder andere Kontexte übertragbar sind, liegt die Entscheidung über die Übertragbarkeit im Sinne von Lincoln
und Guba letztlich bei den Rezipient:innen. Dies ist zugleich auch der zentrale Unterschied zwischen der empirischen Verallgemeinerung und dem Konzept der Übertragbarkeit. Es ist auch der Grund, weshalb wir für die Übertragbarkeit – zusätzlich zu der
obigen Abfolge der beiden Gefängnisstudien – hier kein Untersuchungsbeispiel anführen. Denn in einer empirischen Studie können nie die Forschenden auf eine Übertragbarkeit schließen; sie können nur mittels dichter Beschreibung die Voraussetzung für
eine entsprechende Entscheidung schaffen.


Die Entscheidung darüber, ob Untersuchungsergebnisse auf einen anderen Kontext übertragbar
sind, liegt bei den Rezipient:innen der Studie, nicht bei den Forschenden. Voraussetzung für diese
Entscheidung ist eine dichte Beschreibung des Untersuchungskontextes durch die Forschenden.


5.4 Analytische Verallgemeinerung


Sowohl die verschiedenen Formen der empirischen Verallgemeinerung als auch die
Übertragbarkeit beziehen sich auf den Schluss von einer Stichprobe auf eine Grundgesamtheit (empirische Verallgemeinerung) oder auf eine andere Stichprobe oder einen
anderen Kontext (Übertragbarkeit). Daneben spielt in der qualitativen Forschung aber
auch eine andere Form der Verallgemeinerung eine wichtige Rolle, nämlich die _Verall-_
_gemeinerung auf eine Theorie_ . Diese Form der Verallgemeinerung wird als analytische
oder theoretische Verallgemeinerung bezeichnet (s. auch den Begriff der konzeptuellen Repräsentativität bei Strübing, 2014, S. 31; s. o. 2.3). Wir verwenden hier die analytische Verallgemeinerung als Oberbegriff und betrachten die theoretische Verallgemeinerung in der GTM als eine Form der analytischen Verallgemeinerung (s. u.).

Anders als in der quantitativen Forschung, wo häufig Theorien mit (quasi)universellem Geltungsanspruch angestrebt werden, geht es in der qualitativen Forschung eher
um die Generierung von Theorien oder theoretischen Aussagen _mittlerer Reichweite_ .
Darunter sind Theorien zu verstehen, die ausgehend von empirischen Beobachtungen generiert werden. Sie zielen darauf ab, die Mechanismen und Prozesse zu identifizieren, die die beobachteten Phänomene und deren Variation im Gegenstandsbereich
hervorbringen. Ein Beispiel für eine Theorie mittlerer Reichweite aus der Psychologie ist die von Norbert Groeben und Brigitte Scheele vorgelegte Theorie über Ironie
(1984). Auf der Grundlage von 20 Subjektiven Theorien unterscheiden sie zwischen
vier verschiedenen Formen von Ironie und identifizieren sowohl sprachliche Signale,


128


5.4 Analytische Verallgemeinerung


die auf die Verwendung von Ironie hinweisen, als auch Persönlichkeitsmerkmale, die
mit der Verwendung von Ironie in Zusammenhang stehen.


Die analytische Verallgemeinerung hat zum Ziel, auf der Grundlage des Datenmaterials Theorien
mittlerer Reichweite zu erstellen.


Eine frühe Form der analytischen Verallgemeinerung, die allerdings heute nur noch
selten in dieser Form Verwendung findet, ist die _analytische Induktion_ (Znaniecki,
1934). Znaniecki verfolgte damit das Ziel, universelle Kausalerklärungen zu generieren. Dabei wird zunächst auf der Grundlage der Beobachtung einiger erster Fälle eine
Hypothese über essenzielle Merkmale in einem Phänomenbereich aufgestellt. Diese
Hypothese wird in darauf folgenden Schritten sukzessive an weiteren Fällen überprüft,
wobei der Beobachtung abweichender Fälle eine besondere Bedeutung zukommt. Bei
jedem Fall, der durch die Hypothese nicht angemessen abgedeckt ist, wird die Hypothese modifiziert (oder auch der interessierende Phänomenbereich eingeschränkt).
Diese Vorgehensweise wird so lange fortgeführt, bis eine Kausalhypothese für einen
definierten Phänomenbereich vorliegt, die alle untersuchten Fälle dieses Phänomens
abdeckt. Die Methode wurde im Folgenden u. a. von Lindesmith (1937) und Cressey
(1953) weiterentwickelt, findet jedoch wegen der ursprünglichen Ausrichtung auf die
Identifikation universeller Kausalerklärungen in der heutigen qualitativen Sozialforschung nur wenig Verwendung.


Ursprüngliches Ziel der analytischen Induktion war es, universelle Kausalerklärungen zu erstellen.


Die bekannteste Variante der analytischen Verallgemeinerung ist die, wie sie im Kontext der Grounded-Theory-Methodologie (GTM) ausgearbeitet wurde (3.1): die _theo-_
_retische Verallgemeinerung_ . Ziel der GTM ist die datenbasierte Entwicklung einer Theorie mittlerer Reichweite auf der Grundlage eines stetigen kontrastiven Vorgehens
bzw. permanenten Vergleichs (s. o. 3.1). Ausgehend von einer Analyse erster, informationshaltiger Fälle wird in einem ersten Schritt eine Anfangshypothese über den
untersuchten Gegenstandsbereich erstellt; dies beinhaltet auch die Identifikation von
Merkmalen, die mit den Ausprägungen des untersuchten Phänomens in Zusammenhang stehen. Diese Hypothese wird dann abgesichert, indem weitere Fälle in die Analyse einbezogen werden; diese sollten den ersten Fällen hinsichtlich ihrer Ausprägung auf potenziell relevanten Merkmalen möglichst ähnlich sein. Die Fallauswahl
erfolgt in diesem Schritt also nach dem Prinzip einer _Minimierung der Kontraste_ zwischen den Fällen. Wenn die Anfangshypothese anhand dieser ähnlichen Fälle bestä

129


5 Verallgemeinerung


tigt werden kann, schließt sich weiterhin die Analyse von Fällen an, die sich von den
bisher untersuchten Fällen hinsichtlich ihrer Ausprägungen auf relevanten Merkmalen gerade unterscheiden; die zugrunde gelegte Hypothese ist hier entsprechend eine
Unterschieds­hypothese, und die Auswahl erfolgt nach dem Prinzip einer _Maximie-_
_rung von Kontrasten_ . Wann immer eine Ähnlichkeits- oder eine Unterschiedshypothese
nicht bestätigt werden kann, wird die entsprechende Hypothese modifiziert. Die verschiedenen Schritte greifen in der Forschungspraxis also iterativ ineinander.

Dieses Vorgehen wird so lange fortgeführt, bis eine _Theoretische Sättigung_ erzielt
ist, bis die Einbeziehung weiterer Fälle also keine weitere Modifikation der Theorie
erforderlich macht. Wie in Kap. 3.1 ausführlich beschrieben, ist die Theoretische Sätti­
gung jedoch kein absolutes Abbruchkriterium (s. auch 4.1 zur Sättigung allgemein).
Konzepte in einer Theorie lassen sich prinzipiell unendlich weiter ausdifferenzieren.
Letztlich liegt es bei den Forschenden zu entscheiden, wann eine Theorie hinreichend
ausdifferenziert ist und wann die Einbeziehung weiterer Fälle keine relevanten neuen
Erkenntnisse mehr erbringt.


Die theoretische Verallgemeinerung wurde innerhalb der GTM entwickelt. Ziel ist es, auf der Grund
lage der Daten durch sukzessive Vergleiche eine Theorie mittlerer Reichweite zu entwickeln. Der

Fallvergleich wird beendet, wenn eine Theoretische Sättigung erreicht ist, d. h. wenn die Konzepte

innerhalb der Theorie hinreichend ausgearbeitet sind.


Das Prinzip des Fallvergleichs mit dem Ziel der analytischen Verallgemeinerung findet
sich auch in der _explanativen Fallstudie_ . Allerdings unterscheidet sich die analytische
Verallgemeinerung mittels Fallstudie in einem zentralen Punkt von der analytischen
Verallgemeinerung mittels analytischer Induktion oder in der GTM. Bei den letzteren
beiden Untersuchungsdesigns erfolgt die Fallauswahl induktiv, ausgehend von den
Daten: Die ausgewählten Fälle werden einander gegenüber gestellt, und in Abhängigkeit von den Ergebnissen werden weitere Fälle ausgewählt. Bei der Anwendung der
Fallstudie erfolgt die Fallauswahl dagegen konzeptgesteuert. Die Fälle werden, auf der
Grundlage von Vorwissen, vor Untersuchungsbeginn bestimmt.

Unter den Einzelfallstudien ist die Untersuchung eines _kritischen Falls_ besonders
einschlägig für explanative Zwecke. Kritische Fälle sind solche, die besonders gut für
die Hypothesentestung geeignet sind: Entweder sind die Bedingungen, die in der Theorie spezifiziert sind, hier in besonderem Maß gegeben – und wenn die theoretisch zu
erwartenden Konsequenzen in diesem Fall nicht eintreten, dann ist ihr Eintreten in
weniger offensichtlichen Fällen noch weniger zu erwarten, und die Hypothese kann
als (vorläufig) falsifiziert gelten ( _Most Likely Case_ ). Oder aber die in der Theorie spezifizierten Bedingungen sind in dem Fall nur schwach ausgeprägt ( _Least Likely Case_ ).
Wenn die in der Theorie postulierten Konsequenzen aber trotz dieser nur schwachen


130


5.4 Analytische Verallgemeinerung


Ausprägung der Bedingungen eintreten, dann ist in anderen Fällen mit stärker ausgeprägten Bedingungen umso eher zu erwarten, dass sie dort ebenfalls zu finden sind,
und die Hypothese kann als vorläufig bestätigt gelten.


Die explanative Fallstudie zielt ebenfalls auf analytische Verallgemeinerung ab. Dafür eignen sich
besonders kritische Fälle.


**Untersuchungsbeispiel: Betriebliches Arbeits- und Gesundheitsmanagement in Dänemark**


Pernille Hohnen und Peter Hasle führten eine Studie mit einem kritischen Fall zum Thema Arbeitsund Gesundheitsschutz durch (2011). In Dänemark existierten zum Zeitpunkt der Untersuchung
entsprechende Zertifizierungen, die eine Optimierung des Arbeits- und Gesundheitsschutzes in
Betrieben gewährleisten sollten. Die Autor:innen gingen in ihrer Studie der Frage nach, inwieweit
eine entsprechende Zertifizierung in der Tat die Arbeitssicherheit erhöhte. Für die Untersuchung
wählten sie gezielt einen multinationalen metallverarbeitenden Betrieb in Dänemark als kritischen
Fall aus. Als kritisch stuften sie ihn ein, weil der Betrieb in Dänemark als eine Art Modellbetrieb
für die Umsetzung relevanter Sicherheits- und Arbeitsschutzvorschriften galt. Wenn in diesem
vorbildlichen Betrieb, so die Autor:innen, Probleme bei der Umsetzung der Vorschriften und der
Sicherstellung des Arbeits- und Gesundheitsschutzes auftreten sollten, dann sind solche Probleme in anderen, weniger vorbildlichen Betrieben umso wahrscheinlicher. In ihrer Studie zeigen
sie, wie paradoxerweise gerade die Umsetzung der Vorschriften dazu führt, dass Maßnahmen sich
auf solche Bereiche der Arbeitssicherheit und des Gesundheitsschutzes konzentrieren, die sich
besonders gut für eine Dokumentation eignen und somit auch gut nachvollziehbar sind. Damit
bleiben aber zugleich andere dringende Bereiche der Arbeitssicherheit ausgespart; die Arbeitssicherheit insgesamt wird nicht notwendig erhöht.


Die obige Studie verdeutlicht das Prinzip der analytischen Verallgemeinerung anhand
eines _Most Likely Case_ . Die dabei überprüfte Hypothese betrifft die Annahme, dass die
Umsetzung der geltenden Arbeits- und Gesundheitsschutzmaßnahmen eine Verbesserung des Arbeitsschutzes gewährleistet. In dem untersuchten Betrieb, der die Maßnahmen modellhaft umsetzt, bleiben dennoch wichtige Bereiche der Arbeitssicherheit ausgespart. Dies zeigt, dass die Umsetzung der gesetzlichen Maßnahmen alleine noch nicht
ausreicht, um den Arbeitsschutz zu gewährleisten – denn wenn dies in dem modellhaft
geführten Betrieb nicht gelingt, gelingt es aller Wahrscheinlichkeit nach in anderen
Betrieben umso schlechter, die weniger für die Umsetzung der Maßnahmen tun.

Auch die _multiple Fallstudie_ lässt sich für die analytische Verallgemeinerung nutzbar machen, und zwar mittels der _gezielten Kontrastierung von Fällen_ . Die Minimalform


131


5 Verallgemeinerung


eines solchen explanativen Fallstudiendesigns beinhaltet zwei Fälle, die einander in vielen relevanten Hinsichten möglichst ähnlich sind, sich in einem Merkmal jedoch unterscheiden. Auf diese Weise lässt sich eine Hypothese über die Auswirkungen dieses einen
Merkmals im interessierenden Gegenstandsbereich überprüfen. Wenn man sich auf
zwei kontrastierende Fälle beschränkt, dann kann man allerdings nicht ausschließen,
dass weitere Merkmale dieser meist komplexen Fälle sich auf das Untersuchungsergebnis auswirken. Um eine höhere Aussagekraft zu erzielen, ist es besser, mit (mindestens) vier Fällen zu arbeiten, von denen jeweils zwei sich in möglichst vielen Punkten
möglichst ähnlich sind und zugleich von den anderen beiden unterscheiden. Damit die
Hypothese als bestätigt gelten kann, sollten die Ergebnisse für die jeweils ähnlichen
Fälle ebenfalls ähnlich ausfallen, für die unterschiedlichen Fälle dagegen jeweils unterschiedlich. Die Ergebnisse solcher Fallstudien – gleich, ob es sich dabei um Einzelfallstudien oder multiple Fallstudien handelt – gelten dabei stets als vorläufig.


Auch multiple Fallstudien können auf analytische Verallgemeinerung ausgerichtet sein. Am besten
eignen sich hierfür Designs mit je zwei ähnlichen und zwei unterschiedlichen Fällen.


Sämtliche Formen der analytischen Verallgemeinerung – analytische Induktion, theoretische Verallgemeinerung und Verallgemeinerung auf der Grundlage explanativer
Fallstudien – basieren auf den Prinzipien des Fallvergleichs und der _Kontrastierung_
_von Fällen_ . Diese Prinzipien entsprechen der Vorgehensweise der literalen und theoretischen Replikation (nach Yin, 2017, S. 54ff.). Wenn man eine _literale Replikation_
durchführt, wählt man die Fälle so aus, dass – entsprechend der zugrunde liegenden
Hypothese – ähnliche Ergebnisse resultieren; dies entspricht dem Prinzip der Minimierung von Kontrasten bzw. der Auswahl maximal ähnlicher Fälle. Bei einer _theoretischen_
_Replikation_ werden die Fälle dagegen so ausgewählt, dass – wiederum entsprechend
der zugrunde liegenden Hypothese – unterschiedliche Ergebnisse resultieren; dies entspricht dem Prinzip der Maximierung von Kontrasten bzw. der Auswahl minimal ähnlicher Fälle.


Qualitative Studien mit dem Ziel der analytischen Verallgemeinerung basieren auf den Prinzipien
des Fallvergleichs und der Kontrastierung von Fällen. Fälle werden so ausgewählt, dass sie sich
entweder möglichst ähnlich sind (literale Replikation bzw. Minimierung von Kontrasten) oder dass
sie sich gerade unterscheiden (theoretische Replikation bzw. Maximierung von Kontrasten).


132


5.5 Interne Verallgemeinerung


5.5 Interne Verallgemeinerung


In den bisherigen Abschnitten dieses Kapitels ging es stets um die sogenannte _externe_
_Verallgemeinerung_ : Inwieweit können die Befunde einer Studie auf etwas anderes
übertragen werden, das außerhalb ihrer selbst liegt – auf andere Personen, Settings
oder Zeitpunkte bei der empirischen Verallgemeinerung oder auf eine Theorie bei der
analytischen Verallgemeinerung. Diese externe Form der Verallgemeinerung, auch als
externe Validität bezeichnet, dürfte meist gemeint sein, wenn wir an Verallgemeinerung im Kontext empirischer Forschung denken. Maxwell und Chmiel (2014) unterscheiden jedoch noch eine weitere Form der Verallgemeinerung, die besonders im Kontext qualitativer Forschung von Bedeutung ist: die _interne Verallgemeinerung_ . Darunter
verstehen sie die Verallgemeinerbarkeit innerhalb des untersuchten Falles: Inwieweit
repräsentieren die Beobachtungseinheiten in der Studie tatsächlich alle relevanten
Beobachtungseinheiten des Falls – inwieweit ist es gelungen, Daten zu erheben, die
den Fall tatsächlich in seiner gesamten Bandbreite abdecken?

Diese Überlegungen liegen besonders nahe bei Fällen, die in sich eine Mehrebenenstruktur aufweisen, wie dies etwa auf Fallstudien oder ethnografische Studien zutrifft.
Wenn beispielsweise eine Schule als Fall untersucht wird, dann findet immer auch
eine Auswahl innerhalb des Falles statt, die letztlich die interne Verallgemeinerbarkeit sicherstellen soll: Welche Stakeholder werden einbezogen (Lehrer:innen, Schüler:innen, Eltern, Schulleitung, etc.), welche Klassenstufen, welche Lehrer:innen und
welche Schüler:innen, und welche Teile des Schuljahres werden in der Untersuchung
abgedeckt (s. o. 3.2)? Wenn in einer ethnografischen Studie eine Online-Gemeinschaft
Untersuchungsgegenstand ist, dann stellt sich beispielsweise die Frage, in welchem
Stadium der Gemeinschaft die Studie erfolgt (zu Beginn oder wenn die Gemeinschaft
schon länger besteht), welche Mitglieder repräsentiert sein sollten, welche OnlineBeiträge, nur die Beiträge selbst oder auch Reaktionen darauf, nur Online- oder auch
eventuell statt findende offline-Begegnungen (s. o. 3.3)? Die interne Verallgemeinerbarkeit wird auch bei bestimmten Erhebungsmethoden und Datenarten mitgedacht:
So ist bei Beobachtungsstudien nicht nur zu entscheiden, wo beobachtet werden soll,
sondern auch wer und über welche Zeiträume zu welchen Zeitpunkten (s. o. 4.3). Bei
der Nutzung von vorliegenden Daten wie beispielsweise Filmen oder Blogs haben wir
ebenfalls darauf hingewiesen, dass sowohl eine Auswahl der Fälle selbst als auch eine
Auswahl innerhalb der Fälle stattfindet. Beispielsweise ist bei einer Filmanalyse zu entscheiden, welche Szenen Gegenstand einer vertieften Analyse sein sollen (s. o. 4.4.1).

Bei anderen Methoden der Datenerhebung findet die Frage der internen Verallgemeinerbarkeit dagegen deutlich weniger Beachtung, obwohl sie hier ebenso relevant
ist. So machen wir uns bei einem Interview meist keine Gedanken darüber, ob wir Erfahrungen, Gedanken oder Meinungen der interviewten Personen in ihrem vollen Umfang
erfasst haben. Vielleicht hatte die Teilnehmer:in am Morgen einen Streit mit ihrem Partner oder ihrer Partnerin, oder ein Teilnehmer hat in der Nacht zuvor schlecht geschla

133


5 Verallgemeinerung


fen – und die Grundstimmung färbt nun sozusagen auf alle Äußerungen im Interview
ab. Im Fall der Gruppendiskussion ist es noch offensichtlicher, dass die jeweilige Gruppendynamik und die Äußerungen der Teilnehmer:innen im Kontext dieser Dynamik nur
einen Ausschnitt aus vielen potenziell möglichen Gesprächskonstellationen darstellen.


Die interne Verallgemeinerung bezieht sich auf die Frage, ob die erhobenen Daten den jeweiligen
Fall tatsächlich in seiner gesamten Bandbreite abdecken. Diese Form der Verallgemeinerung findet vor allem bei Fallstudien, in der Ethnografie und allgemein bei Beobachtungstudien Beachtung,
obwohl sie bei allen Datenerhebungsmethoden von Bedeutung ist.


Maxwell und Chmiel (2014) schlagen verschiedene Strategien vor, um in qualitativen
Untersuchungen auch die interne Validität zu gewährleisten. An erster Stelle stehen
dabei Strategien der Auswahl von Untersuchungseinheiten, die auf Heterogenität und
Erfassung von Vielfalt im Gegenstandsbereich ausgerichtet sind, also beispielsweise, aus
konzeptgesteuerter Perspektive, das Maximum-Variation-Sampling, oder, aus induktiver Perspektive, das Theoretical Sampling. Dabei beziehen sich diese Strategien hier
nicht auf die Fälle bzw. die Analyseeinheiten, sondern auf die Untersuchungseinheiten
innerhalb der Analyseeinheiten. Auch sind die Strategien auf den Ebenen der Analyseund der Untersuchungseinheiten voneinander unabhängig. So ist es beispielsweise
denkbar, eine Fallstudie mit zwei einander ähnlichen Fällen durchzuführen (homogene
Stichprobe), bei der Auswahl der Untersuchungseinheiten innerhalb der Fälle dagegen
eine Maximum-Variation-Strategie anzuwenden (heterogene Stichprobe).


Weiterführende Literatur


Gobo, Giampietro (2007). Sampling, representativeness and generalizability. In Clive

Seale, Giampietro Gobo, Jaber F. Gubrium, & David Silverman (Hrsg.), _Qualitative_
_research practice_ (S. 405–426). Sage.
Hammersley, Martyn (1992). _What’s wrong with ethnography? Methodological explora-_

_tions._ Routledge.
Lincoln, Yvonne, & Guba, Egon (2009). The only generalization is: there is no gene
ralization. In Roger Gomm, Martyn Hammersley, & Peter Foster (Hrsg.) _Case study_
_method_ (S. 27–44). Sage.
Maxwell, Joseph A., & Chmiel, Margaret (2014). Generalization in and from qualita
tive analysis. In Uwe Flick (Hrsg.), _The Sage handbook of qualitative data analysis_
(S. 540–553). Sage.
Schreier, Margrit (2018). Sampling and generalization. In Uwe Flick (Hrsg.), _The Sage_

_handbook of qualitative data collection_ (S. 84–98). Sage.


134


#### **Schluss**

Künstler:innen verbringen oft Jahre an einer Akademie. Sie eignen sich Grundbegriffe
und Wissen über Perspektive, Farblehre und Bildkomposition an. Sie lernen die verschiedenen Stilrichtungen kennen und die Eigenschaften verschiedener Medien wie
Öl oder Kreide. All dieses Wissen stellt aber nur eine Grundlage dar, einen Fundus,
auf den sie im Laufe ihrer Arbeiten immer wieder zurückgreifen können. Mindestens
ebenso wichtig wie das Grundwissen ist die Praxis, die permanente Anwendung und
Umsetzung des Gelernten.

Und auch dies gilt für die qualitative Forschung: Das Wissen über die verschiedenen
Aspekte der Fallauswahl, das wir in diesem Band dargestellt haben – von den Grundbegriffen über die Strategien, die Traditionen, die Datenarten und Methoden zu ihrer
Erhebung, bis hin zu den Möglichkeiten der Verallgemeinerung – ist nichts anderes als
eine Grundlage. Der Band ist als Leitfaden gedacht, an dem man sich im Forschungsprozess orientieren, in dem man immer wieder etwas nachschlagen kann. Ausschlaggebend sind aber letztlich die Praxis und die Umsetzung.

Wie wir in unserer Einleitung beschrieben haben, ist qualitative Forschung eine
ergebnisoffene, flexible Forschung. Das wiederum bedeutet, dass ein Leitfaden für die
Fallauswahl in der Forschungspraxis meist nicht eins-zu-eins umsetzbar ist. Bei der
Durchführung einer konkreten Studie werden sich immer wieder Situationen und Fragestellungen ergeben, die eine etwas andere Vorgehensweise erfordern, als wir sie hier
beschrieben haben. In solchen Situationen ist es nicht wichtig, genauso vorzugehen,
wie wir es hier dargestellt haben. Wichtig ist vielmehr, sich die eigenen Entscheidungen bewusst zu machen, sie zu reflektieren und zu begründen.

Nutzen Sie für Ihre Studie das Wissen und die Erfahrungen, die andere schon vor
Ihnen gemacht haben – es ist nicht nötig, das Rad neu zu erfinden. Aber wenn dieses
Wissen Ihnen nicht weiterhilft, dann improvisieren Sie (begründet, natürlich). Und wer
weiß: Vielleicht entsteht daraus ein ganz neuer Stil, eine neue Technik, eine neue Strategie der Fallauswahl, die wiederum andere Forschende nach Ihnen inspirieren kann.


135


#### **Literaturverzeichnis**

Akremi, Leila (2019a). Stichprobenziehung in der qualitativen Sozialforschung. In

Nina Baur, & Jörg Blasius (Hrsg.), _Handbuch Methoden in der empirischen Sozialfor-_
_schung_ (2. Aufl., Bd. 1, S. 313–332). SpringerVS.
Akremi, Leila (2019b). Filme. In Nina Baur, & Jörg Blasius (Hrsg.), _Handbuch Metho-_

_den in der empirischen Sozialforschung_ (2. Aufl., Bd. 2, S. 1203–1215). SpringerVS.
Albrecht-Ross, Bessy, Leitner, Susanne, Putz-Erath, Lea, et al. (2016). „Falls meine

Kleine weint, muss ich mal kurz weg“. Möglichkeiten und Herausforderungen einer
Online-Arbeitsgruppe mit Grounded-Theory-Projekten. In Claudia Equit, & Christoph Hohage (Hrsg.) _Handbuch Grounded Theory: Von der Methodologie zur For-_
_schungspraxis_ (S. 409–426). Beltz Juventa.
Avery, Rosemary J., Kalaji, Motasem, Niederdeppe, Jeff, et al. (2023). Perceived threat

and fear responses to e-cigarette warning label messages: Results from 16 focus
groups with U.S. youth and adults. _PLOS ONE_, _18_ [(6), e0286806. https://doi.](https://doi.org/10.1371/journal.pone.0286806)
[org/10.1371/journal.pone.0286806](https://doi.org/10.1371/journal.pone.0286806)
Barbieri, Guiseppina G., Barbieri, Rosa, & Capone, Roberto (2021). Serious games in

high school mathematics lessons: An embedded case study in Europe. _Eurasia Jour-_
_nal of Mathematics, Science and Technology Education, 17_ [(5), em1963. https://doi.](https://doi.org/10.29333/ejmste/10857)
[org/10.29333/ejmste/10857](https://doi.org/10.29333/ejmste/10857)
Becker, Howard (2009). Cases, causes, conjunctions, stories and imagery. In Roger

Gomm, Martyn Hammersley, & Peter Foster (Hrsg.), _Case study method_ (S. 234–
258). Sage.
Betlej, Alina (2023). Social networks, new technologies, and wellbeing—an interview

study on factors influencing older adults’ successful ageing. _International Journal of_
_Environmental Research and Public Health_, _20_ [(7), 5279. https://doi.org/10.3390/](https://doi.org/10.3390/ijerph20075279)
[ijerph20075279](https://doi.org/10.3390/ijerph20075279)
Bibeau, Marc, Dionne, Frédéric, Riera, Anais, & Leblanc, Jeannette (2020). The influ
ence of compassion meditation on the psychotherapist’s empathy and clinical practice: A phenomenological analysis. _Journal of Humanistic Psychology_, _65_ (1), 114–
[138. https://doi.org/10.1177/0022167820953258](https://doi.org/10.1177/0022167820953258)
Bogner, Alexander, Littig, Beate, & Menz, Wolfgang (Hrsg.) (2009). _Experteninter-_

_views: Theorien, Methoden, Anwendungsfelder_ (3. Aufl.). SpringerVS.
Braun, Virginia, & Clarke, Victoria (2019). To saturate or not to saturate? Questioning

data saturation as a useful concept for thematic analysis and sample-size rationales. _Qualitative Research in Sport, Exercise, and Health, 13_ [(2), 201–216. https://](https://doi.org/10.1080/2159676X.2019.1704846)
[doi.org/10.1080/2159676X.2019.1704846](https://doi.org/10.1080/2159676X.2019.1704846)


136


Literaturverzeichnis


Breuer, Franz, Muckel, Petra, & Dieris, Barbara (2017). _Reflexive Grounded Theory._

_Eine Einführung für die Forschungspraxis_ . Springer.
Bust-Bartels, Nina Marie (2021). _Bürgerwehren in Deutschland. Zwischen Nachbar-_

_schaftshilfe und rechtsextremer Raumergreifung_ . Transcript.
Butler, Ashleigh E., Hall, Helen, & Copnell, Beverley (2018). The changing nature

of the relationships between parents and healthcare providers when a child dies
in the paediatric intensive care unit. _Journal of Advanced Nursing, 74_ (1), 89–99.
[http://dx.doi.org/10.1111/jan.13401](http://dx.doi.org/10.1111/jan.13401)
Cavazos-Rehg, Patricia A., Krauss, Melissa J., Sowles, Shaina, et al. (2016). A content

analysis of depression-related Tweets. _Computers in Human Behavior_, _54_, 351–357.
[https://doi.org/10.1016/j.chb.2015.08.023](https://doi.org/10.1016/j.chb.2015.08.023)
Charmaz, Cathleen (2006): _Constructing grounded theory. A practical guide through_

_qualitative analysis_ (3. Aufl.). Sage.
Cressey, Donald (1953). _Other people’s money._ Free Press.
Creswell, John W., & Poth, Cheryl N. (2024). _Qualitative inquiry and research design:_

_Choosing among five approaches_ (5. Aufl.). Sage.
Declercq, Anja (2000). Participant observation in nursing home wards for people suf
fering from dementia: The problems of trust and emotional involvement. _Forum_
_Qualitative Sozialforschung Forum: Qualitative Social Research_, _1_ [(1). https://doi.](https://doi.org/10.17169/fqs-1.1.1135)
[org/10.17169/fqs-1.1.1135](https://doi.org/10.17169/fqs-1.1.1135)
Döring, Nicola (2023). _Forschungsmethoden und Evaluation in den Sozial- und Human-_

_wissenschaften_ (6. Aufl.). Springer.
Francis, Jill J., Johnston, Marie, Robertson, Claire, et al. (2010). What is an adequate

sample size? Operationalising data saturation for theory-based interview studies. _Psychology & Health_, _25_ [(10), 1229–1245. https://doi.org/10.1080/ 0887044](https://doi.org/10.1080/08870440903194015)
[0903194015](https://doi.org/10.1080/08870440903194015)
Franken, Lina (2022). _Digitale Methoden für qualitative Forschung: Computationelle_

_Daten und Verfahren_ . UTB.
Gatling, Margaret, Mills, Jane, & Lindsay, David (2014). Representations of middle age

in comedy film: A critical discourse analysis. _The Qualitative Report, 19_ (12), 1–15.
Geertz, Clifford (2003). _Dichte Beschreibung. Beiträge zum Verstehen kultureller Systeme_

(2. Aufl.). Suhrkamp.
Giné-Garriga, Maria, Sandlund, Marlene, Dall, Philippa M., et al. (2019). A novel

approach to reduce sedentary behaviour in care home residents: The GET READY
study utilising service-learning and co-creation. _International Journal of Environ-_
_mental Research and Public Health_, _16_ [(3), 418. https://doi.org/10.3390/ijerph](https://doi.org/10.3390/ijerph16030418)
[16030418](https://doi.org/10.3390/ijerph16030418)
Glaser, Barney, & Strauss, Anselm (1967). _The discovery of grounded theory. Strategies_

_for qualitative research._ Aldine Publications.


137


Literaturverzeichnis


Gobo, Giampietro (2007). Sampling, representativeness, and generalizability. In Clive

Seale, Giampietro Gobo, Jaber F. Gubrium, & David Silverman (Hrsg.), _Qualitative_
_research practice_ (S. 405–426). Sage.
Grant, Aimée (2019). _Doing excellent social research with documents_ . Routledge.
Greschke, Heike M. (2007). Bin ich drin? – Methodologische Reflektionen zur ethnogra
fischen Forschung in einem plurilokalen, computervermittelten Feld [45 Absätze].
_Forum Qualitative Sozialforschung / Forum Qualitative Social Research, 8_ (3), Art. 32.
[https://doi.org/10.17169/fqs-8.3.279](https://doi.org/10.17169/fqs-8.3.279)
Groeben, Norbert, & Scheele, Brigitte (1984). _Produktion und Rezeption von Ironie._

Gunter Narr.
Guest, Greg, Bunce, Arwen, & Johnson, Laura (2006). How many interviews are

enough? An experiment with data saturation and variability. _Field Methods, 18_ (1),
[59–82. https://doi.org/10.1177/1525822X05279903](https://doi.org/10.1177/1525822X05279903)
Guest, Greg, Namey, Emily, & McKenna, Kevin (2016). How many focus groups are

enough? Building an evidence base for nonprobability sample sizes. _Field Methods,_
_29_ [(1), 3–22. https://doi.org/10.1177/1525822X16639015](https://doi.org/10.1177/1525822X16639015 )
Guest, Greg, Name, Emily, & Chen, Mario (2020). A simple method to assess and report

thematic saturation in qualitative research. _PLoS ONE 15_ [(5). e0232076. https://](https://doi.org/10.1371/journal.pone.0232076)
[doi.org/10.1371/journal.pone.0232076](https://doi.org/10.1371/journal.pone.0232076)
Guetterman, Timothy (2015). Descriptions of sampling practices within five approaches

to qualitative research in education and the health sciences. _Forum Forum Quali-_
_tative Sozialforschung / Forum Qualitative Social Research_, _16_ [(2). https://doi.org/](https://doi.org/10.17169/fqs-16.2.2290)
[10.17169/fqs-16.2.2290](https://doi.org/10.17169/fqs-16.2.2290)
Helm, Max, Malikova, Alexa, & Kembro, Joakim (2024). Rooting out the root causes

of order fulfilment errors: A multiple case study. _International Journal of Produc-_
_tion Research_, _62_ [(11), 3853–3871. https://doi.org/10.1080/00207543.2023.225](https://doi.org/10.1080/00207543.2023.2251060)
[1060](https://doi.org/10.1080/00207543.2023.2251060)
Hennink, Monique, & Kaiser, Bonnie N. (2022). Sample sizes for saturation in qualita
tive research: A systematic review of empirical tests. _Social Science & Medicine_, _292_,
[114523. https://doi.org/10.1016/j.socscimed.2021.114523](https://doi.org/10.1016/j.socscimed.2021.114523)
Hennink, Monique, Kaiser, Bonnie N., & Marconi, Vincent C. (2017). Code saturation

versus meaning saturation: How many interviews are enough? _Qualitative Health_
_Research_, _27_ [(4), 591–608. https://doi.org/10.1177/1049732316665344](https://doi.org/10.1177/1049732316665344)
Hennink, Monique, Kaiser, Bonnie N., & Weber, Mary B. (2019). What influences

saturation? Estimating sample sizes in focus group research. _Qualitative Health_
_Research, 29_ [(10), 1483–1496. https://doi.org/10.1177/1049732318821692](https://doi.org/10.1177/1049732318821692)
Hohnen, Pernille, & Hasle, Peter (2011). Making work environment auditable – A

‚critical case‘ study of certified occupational health and safety management systems in Denmark. _Safety Science_, _49_ [(7), 1022–1029. https://doi.org/10.1016/j.](https://doi.org/10.1016/j.ssci.2010.12.005)
[ssci.2010.12.005](https://doi.org/10.1016/j.ssci.2010.12.005)


138


Literaturverzeichnis


Jansen, Harrie (2010). The logic of qualitative survey research and its position in the

field of social research methods. _Forum Qualitative Sozialforschung / Forum Qual-_
_itative Social Research_, _11_ [(2), Article 2. https://doi.org/10.17169/fqs-11.2.1450](https://doi.org/10.17169/fqs-11.2.1450)
Keles, Betul, Grealish, Annmarie, & Leamy, Mary (2024). The beauty and the beast of

social media: An interpretative phenomenological analysis of the impact of adolescents’ social media experiences on their mental health during the Covid-19 pandemic. _Current Psychology_, _43_ (1), 96–112.
Kelle, Udo (2005). „Emergence“ vs. „forcing“ of empirical data? A crucial problem of

„grounded theory“ reconsidered. _Forum Qualitative Sozialforschung / Forum Quali-_
_tative Social Research, 6_ [(2). Art. 27. https://doi.org/10.17169/fqs-6.2.467](https://doi.org/10.17169/fqs-6.2.467 )
Keller, Rainer (2011). _Diskursforschung. Eine Einführung für SozialwissenschaftlerInnen_

(4. Aufl.). Springer VS.
Lincoln, Yvonne, & Guba, Egon (2009). The only generalization is: there is no gener
alization. In Roger Gomm, Martyn Hammersley, & Peter Foster (Hrsg.), _Case study_
_method_ (S. 27–44). Sage.
Lindahl, Jared R., Fisher, Nathan E., et al. (2017). The varieties of contemplative experi
ence: A mixed-methods study of meditation-related challenges in Western Buddhists.
_PloS one_, _12_ [(5), e0176239. https://doi.org/10.1371/journal.pone.0176239](https://doi.org/10.1371/journal.pone.0176239)
Lindesmith, Alfred (1937). _The nature of opiate addiction_ . University of Chicago Librar
ies.
Lynd, Robert, & Lynd, Helen M. (1929). _Middletown_ . _A study in contemporary American_

_culture._ Harcourt, Brace & Company.
Malterud, Kirsti, Siersma, Volkert D., & Guassora, Ann D. (2016). Sample size in quali
tative interview studies: Guided by information power. _Qualitative Health Research_,
_26_ [(13), 1753–1760. https://doi.org/10.1177/1049732315617444](https://doi.org/10.1177/1049732315617444)
Mandla, Anika, Billings, Jo, & Moncrieff, Joanna (2017). „Being bipolar“: A qualitative

analysis of the experience of bipolar disorder as described in Internet blogs. _Issues_
_in Mental Health Nursing, 38_, 858–864.
Markham, Annette N., & Buchanan, Elizabeth (2015). Internet research: Ethical con
cerns. In James D. Wright (Hrsg.), _Encyclopedia of the social & behavioural sciences_
(2. Aufl., Bd. 12., S. 606–613). Elsevier.
Marshall, Martin (1996). Sampling for qualitative research. _Family Practice, 13_ (6),

522–525.
Matko, Karin, & Sedlmeier, Peter (2019). What is meditation? Proposing an empiri
cally derived classification system. _Frontiers in Psychology_, _10_ [, 2276. https://doi.](https://doi.org/10.3389/fpsyg.2019.02276)
[org/10.3389/fpsyg.2019.02276](https://doi.org/10.3389/fpsyg.2019.02276)
Maxwell, Joseph A. (2022). Generalization as an issue for qualitative research design.

In Uwe Flick (Hrsg.), _The Sage handbook of qualitative research design_ (S. 327-338).
Sage.


139


Literaturverzeichnis


Maxwell, Joseph A., & Chmiel, Margaret (2014). Generalization in and from qualita
tive analysis. In Uwe Flick (Hrsg.), _The Sage handbook of qualitative data analysis_
(S. 540–553). Sage.
McKay-Peet, Lauri, & Quan-Haase, Anabel (2017). What is social media and what ques
tions can social media research help us answer? In dies. (Hrsg.), _The Sage handbook_
_of social media research methods_ (S. 13–26). Sage.
Merkens, Hans (2010). Auswahlverfahren, Sampling, Fallkonstruktion. In Uwe Flick,

Ernst von Kardorff, & Ines Steinke (Hrsg.), _Qualitative Forschung_ (S. 286–298).
Rowohlt.
Mey, Günter, & Mruck, Katja (2009). Methodologie und Methodik der Grounded

Theory. In Wilhelm Kempf, & Markus Kiefer (Hrsg.), _Forschungsmethoden der Psy-_
_chologie (Band 3: Natur und Kultur,_ S.100-152). Regener.
Meyer, Michael, & Mayrhofer, Wolfgang (2022). Selecting a sample. In Uwe Flick

(Hrsg.), _The Sage handbook of qualitative research design_ (S. 273–289). Sage.
Morgan, David L. (1997). _Focus groups as qualitative research_ (2. Aufl.). Sage.
Morse, Janet (1991). Strategies for sampling. In dies. (Hrsg.), _Qualitative nursing_

_research: A contemporary dialogue_ (2. Aufl., S. 127–145). Sage.
Morse, Janet (2009). Tussles, tensions, and resolutions. In Janet Morse, Phyllis Stern,

Juliet Corbin, et al. (Hrsg.), _Developing grounded theory. The second generation_
(S. 13–22). Routledge.
Morse, Janet (2015). Data were saturated. _Qualitative Health Research, 25_, 587–588.

doi:10.1177/1049732315576699
O’Donnell, Rachel, Eadie, Douglas, Stead, Martine, Dobson, Ruaraidh, & Semple,

Sean (2021). ‘I was smoking a lot more during Lockdown because I can’: A qualitative study of how UK smokers responded to the Covid-19 Lockdown. _Interna-_
_tional Journal of Environmental Research and Public Health_, _18_ [(11), 5816. https://](https://doi.org/10.3390/ijerph18115816)
[doi.org/10.3390/ijerph18115816](https://doi.org/10.3390/ijerph18115816)
O’Reilly, Michelle, & Parker, Nicola (2012). ‘Unsatisfactory saturation’: A critical explo
ration of the notion of saturated sample sizes in qualitative research. _Qualitative_
_Research, 13_ [(2), 190-197. https://doi.org/10.1177/1468794112446106](https://doi.org)
Onwuegbuzie, Anthony J., & Leech, Nancy L. (2007). A call for qualitative power anal
yses. _Quality & Quantity_, _41_ [, 105–121. https://doi.org/10.1007/s11135-005-](https://doi.org/10.1007/s11135-005-1098-1)
[1098-1](https://doi.org/10.1007/s11135-005-1098-1)
Onwuegbuzie, Anthony J., & Leech, Nancy L. (2010). Generalization practices in qual
itative research: A mixed methods case study. _Quality & Quantity_, _44_, 881–892.
[https://doi.org/10.1007/s11135-009-9241-z](https://doi.org/10.1007/s11135-009-9241-z)
Parker, Charlie, Scott, Sam, & Geddes, Alistair (2019). Snowball sampling. In Paul

Atkinson, Sarah Delamont, Alexandru Cernat, Joseph W. Sakshaug, & Richard A.
Williams (Hrsg.), _Sage research methods foundations_ [. https://doi.org/10.4135/](https://doi.org/10.4135/9781526421036831710)
[9781526421036831710](https://doi.org/10.4135/9781526421036831710)


140


Literaturverzeichnis


Patton, Michael Quinn (2015). _Qualitative research & evaluation methods_ (4. Aufl.).

Sage.
Payne, Geoff, & Williams, Malcolm (2005). Generalization in qualitative research.

_Sociology_, _39_ [(2), 295–314. https://doi.org/10.1177/0038038505050540](https://doi.org/10.1177/0038038505050540)
Piaget, Jean (2016) (Hrsg. Reinhard Fatke). _Meine Theorie der geistigen Entwicklung_ .

Beltz.
Posada-Abadía, Clara Isabel, Marín-Martín, Carolina, Oter-Quintana, Cristina, &

González-Gil, Maria T. (2021). Women in a situation of homelessness and violence: A single-case study using the photo-elicitation technique. _BMC Women’s_
_Health_, _21_ [(1), 216. https://doi.org/10.1186/s12905-021-01353-x](https://doi.org/10.1186/s12905-021-01353-x)
Przyborski, Aglaja, & Wohlrab-Sahr, Monika (2008). _Qualitative Sozialforschung. Ein_

_Arbeitsbuch_ (3. Aufl.). Oldenbourg.
Purdam, Kingsley, & Elliott, Mark J. (2015). The changing social science data land
scape. In Peter Halfpenny, & Robert Procter (Hrsg.), _Innovations in digital research_
_methods_ (S. 25–58). Sage.
Rapley, Tim, & Reese, Gethin (2018). Collecting documents as data. In Uwe Flick

(Hrsg.), _The Sage handbook of qualitative data collection_ (S. 378-391). Sage.
Reniers, Peter W. A., Leontjevas, Ruslan, Declercq, Ine J. N., et al. (2022). The sig
nificance of pets for vulnerable older adults during the COVID-19 pandemic: An
explorative qualitative study. _Animals: An open access journal from MDPI_, _12_ (20),
[2752. https://doi.org/10.3390/ani12202752](https://doi.org/10.3390/ani12202752)
Ritchie, Jane, Lewis, Jane, Elam, Gilliam, Tennant, Rosalind, & Rahim, Nilufer (2014).

Designing and selecting samples. In Jane Ritchie, Jane Lewis, Carol McNaughton
Nicholls, & Rachel Ormston (Hrsg.), _Qualitative research practice_ (2. Aufl., S. 111–
146). Sage.
Roth, Marc, Gubler, Danièle A., Janelt, Tobias T., Kolioutsis, Banous, & Troche, Ste
fan J. (2023). On the feeling of being different – an interview study with people
who define themselves as highly sensitive. _PLoS ONE 18_ [(3): e0283311. https://](https://doi.org/10.1371/journal.pone.0283311)
[doi.org/10.1371/journal.pone.0283311](https://doi.org/10.1371/journal.pone.0283311)
Sandelowski, Margaret (1995). Sample size in qualitative research. _Research in Nurs-_

_ing & Health, 18_, 179-183.
Saunders, Benjamin et al. (2018). Saturation in qualitative research: Exploring its con
ceptualization and operationalization. _Quality & Quantity: International Journal of_
_Methodology_, _52_ (4), 1893–1907.
Schegloff, Egon A., & Sacks, Harvey (1973). Opening up closings. _Semiotica, 8,_ 289–

327.
Schmidt, Jan-Hinrik (2019). Blogs. In Nina Baur, & Jörg Blasius (Hrsg.), _Handbuch_

_Methoden der Empirischen Sozialforschung_ (2. Aufl., Bd. 2, S. 1015–1026). Springer VS.


141


Literaturverzeichnis


Schrape, Jan-Felix, & Siri, Jasmin (2019). Facebook und andere soziale Medien. In

Nina Baur, & Jörg Blasius (Hrsg.), _Handbuch Methoden der Empirischen Sozialfor-_
_schung_ (2. Aufl., Bd. 2, S. 1001–1014). Springer VS.
Schreier, Margrit (2020). Fallauswahl. In Günter Mey, & Katja Mruck (Hrsg.), _Hand-_

_buch Qualitative Forschung in der Psychologie_ (2. Aufl., Bd. 2, S. 19–40). Springer
VS.
Schreier, Margrit (2023). Qualitative Forschungsansätze. In Margrit Schreier, Gerald

Echterhoff, Jana Bauer, Nicole Weydmann, & Walter Hussy, _Forschungsmethoden in_
_Psychologie und Sozialwissenschaften für Bachelor_ (S. 205-246). Springer.
Schünzel, Anja, & Traue, Boris (2019). Websites. In Nina Baur, & Jörg Blasius (Hrsg.),

_Handbuch Methoden der Empirischen Sozialforschung_ (2. Aufl., Bd. 2, S. 1001–
1014). Springer VS.
Schuster, Nina (2024). _Grüne Öffentlichkeiten. Soziales Miteinander in städtischen_

_Kleingärten_ . Transcript.
Semle, Rosa, & Raab, Marius (2021). „Da kann doch kein Mensch gesund bleiben“.

Gesundheitsbezogene Verschwörungstheorien in subjektiven Theorien über
Gesundheit und Krankheit – eine Untersuchung mit der Heidelberger Struktur-­
Lege-Technik [79 Absätze]. _Forum Qualitative Sozialforschung / Forum Qualitative_
_Social Research, 22_ [(1), Art. 4. http://dx.doi.org/10.17169/fqs-22.1.3534](http://dx.doi.org/10.17169/fqs-22.1.3534)
Sim, Julius, Saunders, Benjamin, Waterfield, Jackie, & Kingstone, Tom (2018). Can

sample size in qualitative research be determined a priori? _International Journal of_
_Social Research Methodology: Theory & Practice, 21_ [(5), 619–634. https://doi.org/1](https://psycnet.apa.org/doi/10.1080/13645579.2018.1454643)
[0.1080/13645579.2018.1454643](https://psycnet.apa.org/doi/10.1080/13645579.2018.1454643)
Skilbeck, Lilian, Spanton, Christopher, & Patton, Michael (2023). Patients’ lived expe
rience and reflections on long COVID: An interpretive phenomenological analysis within an integrated adult primary care psychology NHS service. _Journal_
_of Patient-Reported Outcomes_, _7_ [(1), 30. https://doi.org/10.1186/s41687-023-](https://doi.org/10.1186/s41687-023-00570-2)
[00570-2](https://doi.org/10.1186/s41687-023-00570-2)
Smith, Jonathan, & Osborn, Mike (2015). Interpretive phenomenological analysis.

In Jonathan A. Smith (Hrsg.), _Qualitative psychology. A guide to research methods_
(3. Aufl., S. 25–52). Sage.
Smith, Jonathan, Flowers, Paul, & Larkin, Michael (2022). _Interpretive phenomenolog-_

_ical analysis_ (2. Aufl.). Sage.
Šnele, Milena Spasić, Janković, Ivana, & Todorović, Jelisaveta (2025). Experiencing

the first year of COVID-19 pandemic: Feelings and thoughts of emerging adults.
_The Qualitative Report, 30(_ [1), 3043-3061. https://doi.org/10.46743/2160-3715/](https://doi.org/10.46743/2160-3715/2025.7151)
[2025.7151](https://doi.org/10.46743/2160-3715/2025.7151)
Sowden, Ryann, Borgstrom, Erica, & Selman, Lucy E. (2021) ‚It’s like being in a war

with an invisible enemy‘: A document analysis of bereavement due to COVID-19
in UK newspapers. _PLoS ONE 16_ [(3): e0247904. https://doi.org/10.1371/journal.](https://doi.org/10.1371/journal.pone.0247904)
[pone.0247904](https://doi.org/10.1371/journal.pone.0247904)


142


Literaturverzeichnis


Strauss, Anselm, & Corbin, Juliet (1998). _Basics of qualitative research. Techniques and_

_procedures for developing grounded theory._ Sage.
Strübing, Jörg (2014). _Grounded Theory. Zur sozialtheoretischen und epistemologischen_

_Fundierung eines pragmatistischen Forschungsstils_ (3. Aufl.). SpringerVS.
Swartz, Anna (2019). „Being Bipolar“: A cautionary tale in bad digital research ethics.

[https://annaswartz.com/2019/09/being-bipolar-a-cautionary-tale-in-bad-digi-](https://annaswartz.com/2019/09/being-bipolar-a-cautionary-tale-in-bad-digital-research-ethics/)
[tal-research-ethics/](https://annaswartz.com/2019/09/being-bipolar-a-cautionary-tale-in-bad-digital-research-ethics/)
Thompson, Carl (1999). Qualitative research into nurse decision making: Factors for

consideration in theoretical sampling. _Qualitative Health Research,_ _9_ (6), 815–828.
[https://doi.org/10.1177/104973239900900609](https://doi.org/10.1177/104973239900900609)
Thornberg, Robert, & Charmaz, Kathy (2014). Grounded theory and theoretical cod
ing. In Uwe Flick (Hrsg.), _The Sage handbook of qualitative data analysis_ (S. 153–
69). Sage.
Traue, Boris, & Schünzel, Anja (2019). YouTube und andere Web-Videos. In Nina

Baur, & Jörg Blasius (Hrsg.), _Handbuch Methoden der Empirischen Sozialforschung_
(2. Aufl., Bd. 2, S. 1065-1078). SpringerVS.
Traue, Boris, Pfahl, Lisa, & Schürmann, Lena (2019). Diskursanalyse. In Nina Baur, &

Jörg Blasius (Hrsg.), _Handbuch Methoden der Empirischen Sozialforschung_ (2. Aufl.,
S. 565–584). SpringerVS.
Tuma, René, & Schnettler, Berntt (2019). Videographie. In Nina Baur, & Jörg Blasius

(Hrsg.), _Handbuch Methoden der Empirischen Sozialforschung_ (2. Aufl., S. 1191–
1202). SpringerVS.
Umel, Audris (2024). Facebook and social representations of Filipino migrant life in

Germany: A reflexive computational approach. _Frontiers in Human Dynamics_, _5_ .
[https://doi.org/10.3389/fhumd.2023.1284711](https://doi.org/10.3389/fhumd.2023.1284711)
Van den Berk, Bernadette (2024). ‘Agency’ von Kindern auf der Flucht. Eine ethnogra
fische Studie im Child Friendly Place eines griechischen Auffanglagers für Geflüchtete. In Charlotte Röhner, Jessica Schwittek, & Antoanneta Potsi (Hrsg.), _Transmi-_
_gration und Place-Making junger Geflüchteter_ (S. 53–72). Verlag Barbara Budrich.
Ware, Norma C., Idoko, John, Kaaya, Silvia, et al. (2009). Explaining adherence suc
cess in Sub-Saharan Africa: An ethnographic study. _PLOS Medicine_, _6_ (1), e1000011.
[https://doi.org/10.1371/journal.pmed.1000011](https://doi.org/10.1371/journal.pmed.1000011)
Weydmann, Nicole (2019). „ _Healing is not just dealing with your body“: A reflexive_

_grounded theory study exploring women’s concepts and approaches underlying the use_
_of traditional and complementary medicine in Indonesia_ . Regiospectra.
Weydmann, Nicole (2024). Reflexive Forschungsperspektiven zwischen Erwartung,

Selbsterkenntnis und der Angst vor der eigenen Verletzlichkeit. In Stefanie Kessler, &
Karsten König (Hrsg.), _Scheitern in Praxis und Wissenschaft der Sozialen Arbeit: Refle-_
_xions- und Bewältigungspraktiken von Fehlern und Krisen_ (S. 244–262). Beltz Juventa.
Whyte, William (1943). _Street corner society. The social structure of an Italian slum._ Uni
versity of Chicago Press.


143


Literaturverzeichnis


Williams, Malcolm (2000) Interpretivism and generalization. _Sociology,_ _34_ (2), 209–224.
Woodley, Xetura, & Lockard, Megan (2016). Womanism and snowball sampling:

Engaging marginalized populations in holistic research. _The Qualitative Report_,
_21_ [(2), 321–329. https://doi.org/10.46743/2160-3715/2016.2198](https://doi.org/10.46743/2160-3715/2016.2198)
Woods-Giscombé, Cheryl L. (2010). Superwoman schema: African American women’s

views on stress, strength, and health. _Qualitative health research_, _20_ (5), 668–683.
[https://doi.org/10.1177/1049732310361892](https://doi.org/10.1177/1049732310361892)
Yin, Robert (2017). _Case study research and applications: Design and methods_ (6. Aufl.).

Sage.
Znaniecki, Florian (1934). _The method of sociology._ Farrar and Rinehart.
Žuljević, Marija F., Hren, Darko, Storman, Dawid, Kaliterna, Mariano, & Duplančić,

Darko (2024). Attitudes of European psychiatrists on psychedelics: A cross-sectional survey study. _Scientific Reports_, _14_ [(1), 18716. https://doi.org/10.1038/](https://doi.org/10.1038/s41598-024-69688-7)
[s415 98-024-69688-7](https://doi.org/10.1038/s41598-024-69688-7)


144


##### Soziologie

Die Fallauswahl in der qualitativen Forschung erfolgt
in der Regel absichtsvoll und unterscheidet sich
grundlegend von quantitativen Stichprobenverfahren.
Dieser kompakte Leitfaden stellt zentrale Prinzipien
und Strategien vor und zeigt ihre Anwendung in
verschiedenen Forschungsdesigns. Zahlreiche Untersuchungsbeispiele verdeutlichen, wie sich Fallauswahl
gezielt und methodisch reflektiert gestalten lässt.
Studierende und Forschende aller Fachbereiche, die
mit qualitativer Forschung arbeiten, erhalten wichtige
Werkzeuge für die eigene Forschung.


Dies ist ein utb-Band aus dem Verlag Barbara Budrich.
utb ist eine Kooperation von Verlagen mit einem
gemeinsamen Ziel: Lehr- und Lernmedien für das
erfolgreiche Studium zu veröffentlichen.





QR-Code für mehr Infos und
Bewertungen zu diesem Titel


utb.de


